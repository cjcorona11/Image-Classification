{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c9fa6e",
   "metadata": {},
   "source": [
    "In this lab, we will build a convolutional neural network using the PyTorch library for image classification on the Extended MNIST dataset. MNIST is a widely known dataset of handwritten digits (0-9) that was originally used by Yann LeCun in their 1998 paper on document recognition. It quickly became a “toy” dataset because of the ease of obtaining high accuracy with various models. As a result, Gregory Cohen published a more challenging version known as the Extended MNIST (EMNIST) dataset in 2017. This dataset comes from the same NIST source except that it also includes letters in addition to all the digits. So there are 47 classes: digits 0-9, uppercase letters A-Z, and lowercase letters a, b, d, e, f, g, h, n, q, r, t. They omitted any lowercase letters that closely resembled their uppercase counterparts (or likely just grouped them into their respective uppercase class). We chose to use Cohen’s EMNIST Balanced dataset because it had a reasonable size of 131,600 images with balanced classes. This way it wouldn’t require excessive computing power to train, and we wouldn’t have to deal with issues of imbalance. Each image is 28 x 28 pixels in grayscale and is fully pre-processed, meaning they are size-normalized, centered, and fixed-size. This allows for immediate deployment in the machine learning model; no data wrangling necessary. The details of the dataset are shown in\n",
    "Figure 1 and a sample of the dataset is shown in Figure 2. Cohen’s purpose was to release a more challenging dataset than the original MNIST which had become almost trivial with modern techniques. Figure 3 shows the accuracy of neural nets with various numbers of hidden nodes on the EMNIST and original MNIST datasets (using the exact same network). In the following sections, we demonstrate how much more challenging the EMNIST dataset actually is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6ec9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a4018b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 90240, Val size: 22560\n"
     ]
    }
   ],
   "source": [
    "# split train set from test set\n",
    "train_set = datasets.EMNIST(\n",
    "    root='data',\n",
    "    split='balanced',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_set = datasets.EMNIST(\n",
    "    root='data',\n",
    "    split='balanced',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "full_train_set = DataLoader(\n",
    "    train_set,\n",
    "    shuffle=True)\n",
    "\n",
    "# make validation split\n",
    "train_split = int(0.8*len(full_train_set))\n",
    "val_split = len(full_train_set) - train_split\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(full_train_set.dataset, [train_split, val_split])\n",
    "print(f'Train size: {train_split}, Val size: {val_split}')\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "# train loader and val_loader\n",
    "train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3afbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a small sample of the training set\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "    img, label = train_set[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.mT.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f484fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train loop and test loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ed1687e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all model architectures to train/test\n",
    "# INT = Conv2d(in_channels=INT, out_channels=2*INT, kernel_size=3, stride=1, padding='same')\n",
    "# R = ReLU activation function\n",
    "# B = Batch normalization\n",
    "# D = Dropout(0.2)\n",
    "# M = Max pooling(kernel_size=2, stride=1)\n",
    "model_code = {\n",
    "    'm1': [8, 'R', 'M'],\n",
    "    'm2': [8, 'B', 'R', 'M'],\n",
    "    'm3': [8, 'R', 'M', 16, 'R', 'M'],\n",
    "    'm4': [8, 'B', 'R', 'M', 16, 'B', 'R', 'M'],\n",
    "    'm5': [8, 'R', 'M', 'D', 16, 'R', 'M'],\n",
    "    'm6': [8, 'B', 'R', 'M', 'D', 16, 'B', 'R', 'M'],\n",
    "    'm7': [8, 'R', 'M', 16, 'R', 'M', 32, 'R', 'M'],\n",
    "    'm8': [8, 'B', 'R', 'M', 16, 'B', 'R', 'M', 32, 'B', 'R', 'M'],\n",
    "    'm9': [8, 'R', 'M', 'D', 16, 'R', 'M', 'D', 32, 'R', 'M'],\n",
    "    'm10':[8, 'B', 'R', 'M', 'D', 16, 'B', 'R', 'M', 'D', 32, 'R', 'M'],\n",
    "}\n",
    "\n",
    "#models = ['m1', 'm3', 'm5', 'm7', 'm9', 'm11', 'm13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d8bbe039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural net class with easily tunable architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, m, model_code, fc):\n",
    "        super(CNN, self).__init__()\n",
    "        # 3 convolutional layers\n",
    "        # input shape = 28x28\n",
    "        size_in = 1\n",
    "        size_shape = 28\n",
    "        self.layers, size_in, size_shape = self.make_layers(m, model_code, size_in, size_shape)\n",
    "        if fc == 1:\n",
    "            self.classifier = nn.Linear(in_features=size_in*size_shape*size_shape, out_features=47)\n",
    "        elif fc == 2:\n",
    "            self.classifier = nn.Sequential(nn.Linear(in_features=size_in*size_shape*size_shape, out_features=256),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(in_features=256, out_features=47))\n",
    "        elif fc == 3:\n",
    "            self.classifier = nn.Sequential(nn.Linear(in_features=size_in*size_shape*size_shape, out_features=256),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(in_features=256, out_features=128),\n",
    "                                            nn.ReLU(),\n",
    "                                            nn.Linear(in_features=128, out_features=47))\n",
    "                             \n",
    "    def make_layers(self, m, model_code, size_in, size_shape):\n",
    "        layers = []\n",
    "        size_out = 8\n",
    "        for code in model_code[m]:\n",
    "            if code == 'R':\n",
    "                layers += [nn.ReLU()]\n",
    "            elif code == 'S':\n",
    "                layers += [nn.Sigmoid()]\n",
    "            elif code == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=1)]\n",
    "                size_shape -= 1\n",
    "            elif code == 'B':\n",
    "                layers += [nn.BatchNorm2d(size_in)]\n",
    "            elif code == 'D':\n",
    "                layers += [nn.Dropout(0.2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels=size_in, out_channels=size_out, kernel_size=3, stride=1, padding='same')]\n",
    "                size_in = size_out\n",
    "                size_out *= 2\n",
    "                             \n",
    "        return (nn.Sequential(*layers), size_in, size_shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9f229296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : m1\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=5832, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.852516  [   64/90240]\n",
      "loss: 3.699468  [ 6464/90240]\n",
      "loss: 3.198439  [12864/90240]\n",
      "loss: 2.301800  [19264/90240]\n",
      "loss: 2.070692  [25664/90240]\n",
      "loss: 1.760049  [32064/90240]\n",
      "loss: 1.286707  [38464/90240]\n",
      "loss: 1.297068  [44864/90240]\n",
      "loss: 1.563649  [51264/90240]\n",
      "loss: 1.529283  [57664/90240]\n",
      "loss: 1.505383  [64064/90240]\n",
      "loss: 1.702161  [70464/90240]\n",
      "loss: 1.387828  [76864/90240]\n",
      "loss: 0.914402  [83264/90240]\n",
      "loss: 1.180451  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.255971 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.970064  [   64/90240]\n",
      "loss: 1.369787  [ 6464/90240]\n",
      "loss: 1.513060  [12864/90240]\n",
      "loss: 1.330332  [19264/90240]\n",
      "loss: 1.171601  [25664/90240]\n",
      "loss: 1.610522  [32064/90240]\n",
      "loss: 1.102889  [38464/90240]\n",
      "loss: 1.473480  [44864/90240]\n",
      "loss: 1.286753  [51264/90240]\n",
      "loss: 0.923579  [57664/90240]\n",
      "loss: 1.119259  [64064/90240]\n",
      "loss: 1.079804  [70464/90240]\n",
      "loss: 1.245230  [76864/90240]\n",
      "loss: 1.038611  [83264/90240]\n",
      "loss: 1.339491  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 1.173060 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.237869  [   64/90240]\n",
      "loss: 0.969746  [ 6464/90240]\n",
      "loss: 1.134072  [12864/90240]\n",
      "loss: 1.137412  [19264/90240]\n",
      "loss: 1.383083  [25664/90240]\n",
      "loss: 1.224960  [32064/90240]\n",
      "loss: 0.883870  [38464/90240]\n",
      "loss: 1.156512  [44864/90240]\n",
      "loss: 1.020206  [51264/90240]\n",
      "loss: 1.336042  [57664/90240]\n",
      "loss: 0.977520  [64064/90240]\n",
      "loss: 0.910573  [70464/90240]\n",
      "loss: 1.186497  [76864/90240]\n",
      "loss: 1.432784  [83264/90240]\n",
      "loss: 1.440714  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 1.151481 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.306170  [   64/90240]\n",
      "loss: 1.173502  [ 6464/90240]\n",
      "loss: 0.977642  [12864/90240]\n",
      "loss: 1.341457  [19264/90240]\n",
      "loss: 1.236426  [25664/90240]\n",
      "loss: 1.048035  [32064/90240]\n",
      "loss: 1.009008  [38464/90240]\n",
      "loss: 1.480030  [44864/90240]\n",
      "loss: 0.954403  [51264/90240]\n",
      "loss: 1.191149  [57664/90240]\n",
      "loss: 0.879121  [64064/90240]\n",
      "loss: 1.379994  [70464/90240]\n",
      "loss: 0.924303  [76864/90240]\n",
      "loss: 0.981685  [83264/90240]\n",
      "loss: 1.353939  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.132632 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.094751  [   64/90240]\n",
      "loss: 1.231040  [ 6464/90240]\n",
      "loss: 1.106424  [12864/90240]\n",
      "loss: 1.392583  [19264/90240]\n",
      "loss: 1.699130  [25664/90240]\n",
      "loss: 1.041769  [32064/90240]\n",
      "loss: 1.679839  [38464/90240]\n",
      "loss: 0.918152  [44864/90240]\n",
      "loss: 1.070259  [51264/90240]\n",
      "loss: 1.248817  [57664/90240]\n",
      "loss: 1.185894  [64064/90240]\n",
      "loss: 0.659579  [70464/90240]\n",
      "loss: 1.241272  [76864/90240]\n",
      "loss: 1.216752  [83264/90240]\n",
      "loss: 1.051719  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 1.108050 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.777562  [   64/90240]\n",
      "loss: 1.136619  [ 6464/90240]\n",
      "loss: 1.311260  [12864/90240]\n",
      "loss: 0.809088  [19264/90240]\n",
      "loss: 0.743536  [25664/90240]\n",
      "loss: 1.067006  [32064/90240]\n",
      "loss: 1.013892  [38464/90240]\n",
      "loss: 1.047110  [44864/90240]\n",
      "loss: 1.129480  [51264/90240]\n",
      "loss: 0.746677  [57664/90240]\n",
      "loss: 0.950197  [64064/90240]\n",
      "loss: 0.819909  [70464/90240]\n",
      "loss: 1.009197  [76864/90240]\n",
      "loss: 1.269364  [83264/90240]\n",
      "loss: 0.970351  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 1.093794 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.917166  [   64/90240]\n",
      "loss: 0.806186  [ 6464/90240]\n",
      "loss: 0.927169  [12864/90240]\n",
      "loss: 0.831995  [19264/90240]\n",
      "loss: 0.897225  [25664/90240]\n",
      "loss: 1.284093  [32064/90240]\n",
      "loss: 0.832529  [38464/90240]\n",
      "loss: 0.951675  [44864/90240]\n",
      "loss: 0.845180  [51264/90240]\n",
      "loss: 0.875397  [57664/90240]\n",
      "loss: 0.934256  [64064/90240]\n",
      "loss: 0.891035  [70464/90240]\n",
      "loss: 1.054129  [76864/90240]\n",
      "loss: 0.909918  [83264/90240]\n",
      "loss: 0.907121  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.051869 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.724097  [   64/90240]\n",
      "loss: 1.179119  [ 6464/90240]\n",
      "loss: 1.041756  [12864/90240]\n",
      "loss: 0.876711  [19264/90240]\n",
      "loss: 1.320506  [25664/90240]\n",
      "loss: 0.849277  [32064/90240]\n",
      "loss: 1.027473  [38464/90240]\n",
      "loss: 0.646672  [44864/90240]\n",
      "loss: 1.080673  [51264/90240]\n",
      "loss: 0.994268  [57664/90240]\n",
      "loss: 1.095919  [64064/90240]\n",
      "loss: 0.901237  [70464/90240]\n",
      "loss: 1.141886  [76864/90240]\n",
      "loss: 1.063781  [83264/90240]\n",
      "loss: 1.343905  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 1.014350 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.927331  [   64/90240]\n",
      "loss: 0.798274  [ 6464/90240]\n",
      "loss: 1.156193  [12864/90240]\n",
      "loss: 0.721882  [19264/90240]\n",
      "loss: 0.783130  [25664/90240]\n",
      "loss: 1.407446  [32064/90240]\n",
      "loss: 1.061787  [38464/90240]\n",
      "loss: 0.746274  [44864/90240]\n",
      "loss: 1.257923  [51264/90240]\n",
      "loss: 0.799150  [57664/90240]\n",
      "loss: 1.002487  [64064/90240]\n",
      "loss: 0.978370  [70464/90240]\n",
      "loss: 0.746053  [76864/90240]\n",
      "loss: 1.059740  [83264/90240]\n",
      "loss: 0.658556  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.971404 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.043883  [   64/90240]\n",
      "loss: 0.966067  [ 6464/90240]\n",
      "loss: 0.848347  [12864/90240]\n",
      "loss: 1.240578  [19264/90240]\n",
      "loss: 0.715884  [25664/90240]\n",
      "loss: 0.793324  [32064/90240]\n",
      "loss: 0.772218  [38464/90240]\n",
      "loss: 0.760456  [44864/90240]\n",
      "loss: 1.079848  [51264/90240]\n",
      "loss: 0.960821  [57664/90240]\n",
      "loss: 1.139715  [64064/90240]\n",
      "loss: 0.693242  [70464/90240]\n",
      "loss: 0.967680  [76864/90240]\n",
      "loss: 0.728157  [83264/90240]\n",
      "loss: 0.573894  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.916273 \n",
      "\n",
      "Done!\n",
      "model : m1\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=5832, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.865006  [   64/90240]\n",
      "loss: 3.776688  [ 6464/90240]\n",
      "loss: 3.606417  [12864/90240]\n",
      "loss: 3.378421  [19264/90240]\n",
      "loss: 2.816770  [25664/90240]\n",
      "loss: 2.356665  [32064/90240]\n",
      "loss: 1.697242  [38464/90240]\n",
      "loss: 1.599756  [44864/90240]\n",
      "loss: 1.847946  [51264/90240]\n",
      "loss: 1.510634  [57664/90240]\n",
      "loss: 1.436968  [64064/90240]\n",
      "loss: 1.384287  [70464/90240]\n",
      "loss: 1.154456  [76864/90240]\n",
      "loss: 1.238206  [83264/90240]\n",
      "loss: 1.403378  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.282131 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.591433  [   64/90240]\n",
      "loss: 1.256010  [ 6464/90240]\n",
      "loss: 1.244131  [12864/90240]\n",
      "loss: 1.469027  [19264/90240]\n",
      "loss: 1.368632  [25664/90240]\n",
      "loss: 1.162672  [32064/90240]\n",
      "loss: 0.955567  [38464/90240]\n",
      "loss: 1.062173  [44864/90240]\n",
      "loss: 1.432704  [51264/90240]\n",
      "loss: 0.836140  [57664/90240]\n",
      "loss: 1.250473  [64064/90240]\n",
      "loss: 1.328133  [70464/90240]\n",
      "loss: 1.040179  [76864/90240]\n",
      "loss: 1.103293  [83264/90240]\n",
      "loss: 1.103697  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 1.064369 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.027338  [   64/90240]\n",
      "loss: 0.888472  [ 6464/90240]\n",
      "loss: 0.735360  [12864/90240]\n",
      "loss: 1.005392  [19264/90240]\n",
      "loss: 0.921078  [25664/90240]\n",
      "loss: 0.910773  [32064/90240]\n",
      "loss: 1.112510  [38464/90240]\n",
      "loss: 0.811310  [44864/90240]\n",
      "loss: 0.838099  [51264/90240]\n",
      "loss: 1.092536  [57664/90240]\n",
      "loss: 1.146787  [64064/90240]\n",
      "loss: 1.159494  [70464/90240]\n",
      "loss: 1.050279  [76864/90240]\n",
      "loss: 1.263119  [83264/90240]\n",
      "loss: 1.231659  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.922934 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.767025  [   64/90240]\n",
      "loss: 0.772196  [ 6464/90240]\n",
      "loss: 1.271546  [12864/90240]\n",
      "loss: 0.920184  [19264/90240]\n",
      "loss: 0.778097  [25664/90240]\n",
      "loss: 1.093086  [32064/90240]\n",
      "loss: 0.540893  [38464/90240]\n",
      "loss: 0.986153  [44864/90240]\n",
      "loss: 1.206057  [51264/90240]\n",
      "loss: 0.736952  [57664/90240]\n",
      "loss: 0.656546  [64064/90240]\n",
      "loss: 0.616595  [70464/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.006916  [76864/90240]\n",
      "loss: 0.763061  [83264/90240]\n",
      "loss: 0.735848  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.813237 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.088934  [   64/90240]\n",
      "loss: 0.860491  [ 6464/90240]\n",
      "loss: 0.805281  [12864/90240]\n",
      "loss: 0.690706  [19264/90240]\n",
      "loss: 0.757035  [25664/90240]\n",
      "loss: 0.838654  [32064/90240]\n",
      "loss: 0.904359  [38464/90240]\n",
      "loss: 0.987184  [44864/90240]\n",
      "loss: 0.837855  [51264/90240]\n",
      "loss: 0.767939  [57664/90240]\n",
      "loss: 0.641701  [64064/90240]\n",
      "loss: 0.573381  [70464/90240]\n",
      "loss: 0.565674  [76864/90240]\n",
      "loss: 0.537932  [83264/90240]\n",
      "loss: 0.615629  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.753590 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.582809  [   64/90240]\n",
      "loss: 0.538325  [ 6464/90240]\n",
      "loss: 0.430316  [12864/90240]\n",
      "loss: 0.941138  [19264/90240]\n",
      "loss: 0.594501  [25664/90240]\n",
      "loss: 0.770869  [32064/90240]\n",
      "loss: 0.492913  [38464/90240]\n",
      "loss: 0.550328  [44864/90240]\n",
      "loss: 0.774260  [51264/90240]\n",
      "loss: 0.683237  [57664/90240]\n",
      "loss: 0.763912  [64064/90240]\n",
      "loss: 0.572392  [70464/90240]\n",
      "loss: 0.650830  [76864/90240]\n",
      "loss: 0.501028  [83264/90240]\n",
      "loss: 0.524709  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.695586 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.738277  [   64/90240]\n",
      "loss: 0.742482  [ 6464/90240]\n",
      "loss: 0.541770  [12864/90240]\n",
      "loss: 0.509795  [19264/90240]\n",
      "loss: 0.596495  [25664/90240]\n",
      "loss: 0.587974  [32064/90240]\n",
      "loss: 0.861831  [38464/90240]\n",
      "loss: 0.708839  [44864/90240]\n",
      "loss: 0.596437  [51264/90240]\n",
      "loss: 0.614517  [57664/90240]\n",
      "loss: 0.684078  [64064/90240]\n",
      "loss: 0.486795  [70464/90240]\n",
      "loss: 0.661969  [76864/90240]\n",
      "loss: 0.826729  [83264/90240]\n",
      "loss: 0.348852  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.674273 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.513026  [   64/90240]\n",
      "loss: 0.617288  [ 6464/90240]\n",
      "loss: 0.376845  [12864/90240]\n",
      "loss: 0.377507  [19264/90240]\n",
      "loss: 0.586629  [25664/90240]\n",
      "loss: 1.048167  [32064/90240]\n",
      "loss: 0.494487  [38464/90240]\n",
      "loss: 0.812641  [44864/90240]\n",
      "loss: 0.289248  [51264/90240]\n",
      "loss: 0.769880  [57664/90240]\n",
      "loss: 0.797897  [64064/90240]\n",
      "loss: 0.551112  [70464/90240]\n",
      "loss: 1.005669  [76864/90240]\n",
      "loss: 0.710205  [83264/90240]\n",
      "loss: 0.490598  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.634574 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.569818  [   64/90240]\n",
      "loss: 0.411954  [ 6464/90240]\n",
      "loss: 0.626466  [12864/90240]\n",
      "loss: 0.552334  [19264/90240]\n",
      "loss: 0.492541  [25664/90240]\n",
      "loss: 0.490014  [32064/90240]\n",
      "loss: 0.615861  [38464/90240]\n",
      "loss: 0.653161  [44864/90240]\n",
      "loss: 0.597116  [51264/90240]\n",
      "loss: 0.659982  [57664/90240]\n",
      "loss: 0.579901  [64064/90240]\n",
      "loss: 0.485766  [70464/90240]\n",
      "loss: 0.518788  [76864/90240]\n",
      "loss: 0.445627  [83264/90240]\n",
      "loss: 0.346044  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.609248 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.469065  [   64/90240]\n",
      "loss: 0.623649  [ 6464/90240]\n",
      "loss: 0.316980  [12864/90240]\n",
      "loss: 0.468005  [19264/90240]\n",
      "loss: 0.437470  [25664/90240]\n",
      "loss: 0.899971  [32064/90240]\n",
      "loss: 0.533179  [38464/90240]\n",
      "loss: 0.267934  [44864/90240]\n",
      "loss: 0.315708  [51264/90240]\n",
      "loss: 0.690100  [57664/90240]\n",
      "loss: 0.530277  [64064/90240]\n",
      "loss: 0.476688  [70464/90240]\n",
      "loss: 0.543618  [76864/90240]\n",
      "loss: 0.380592  [83264/90240]\n",
      "loss: 0.617830  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.589307 \n",
      "\n",
      "Done!\n",
      "model : m1\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=5832, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.858221  [   64/90240]\n",
      "loss: 3.828389  [ 6464/90240]\n",
      "loss: 3.807814  [12864/90240]\n",
      "loss: 3.783634  [19264/90240]\n",
      "loss: 3.756514  [25664/90240]\n",
      "loss: 3.654449  [32064/90240]\n",
      "loss: 3.572077  [38464/90240]\n",
      "loss: 3.460938  [44864/90240]\n",
      "loss: 3.227418  [51264/90240]\n",
      "loss: 2.828240  [57664/90240]\n",
      "loss: 2.300695  [64064/90240]\n",
      "loss: 2.165523  [70464/90240]\n",
      "loss: 1.796891  [76864/90240]\n",
      "loss: 1.847712  [83264/90240]\n",
      "loss: 1.750187  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 1.607742 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.646951  [   64/90240]\n",
      "loss: 1.405846  [ 6464/90240]\n",
      "loss: 1.528003  [12864/90240]\n",
      "loss: 1.913881  [19264/90240]\n",
      "loss: 1.649794  [25664/90240]\n",
      "loss: 1.261136  [32064/90240]\n",
      "loss: 1.136923  [38464/90240]\n",
      "loss: 1.742915  [44864/90240]\n",
      "loss: 1.449795  [51264/90240]\n",
      "loss: 1.376824  [57664/90240]\n",
      "loss: 0.838281  [64064/90240]\n",
      "loss: 1.438598  [70464/90240]\n",
      "loss: 1.158673  [76864/90240]\n",
      "loss: 1.271785  [83264/90240]\n",
      "loss: 1.338142  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.226195 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.136501  [   64/90240]\n",
      "loss: 1.358633  [ 6464/90240]\n",
      "loss: 1.569939  [12864/90240]\n",
      "loss: 1.146311  [19264/90240]\n",
      "loss: 0.941041  [25664/90240]\n",
      "loss: 1.275953  [32064/90240]\n",
      "loss: 0.896242  [38464/90240]\n",
      "loss: 1.467113  [44864/90240]\n",
      "loss: 1.240327  [51264/90240]\n",
      "loss: 0.838327  [57664/90240]\n",
      "loss: 1.312075  [64064/90240]\n",
      "loss: 0.889638  [70464/90240]\n",
      "loss: 1.195935  [76864/90240]\n",
      "loss: 1.104270  [83264/90240]\n",
      "loss: 1.054867  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.037198 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.956285  [   64/90240]\n",
      "loss: 0.698819  [ 6464/90240]\n",
      "loss: 0.961658  [12864/90240]\n",
      "loss: 0.904587  [19264/90240]\n",
      "loss: 0.811316  [25664/90240]\n",
      "loss: 1.296532  [32064/90240]\n",
      "loss: 0.978048  [38464/90240]\n",
      "loss: 0.873569  [44864/90240]\n",
      "loss: 1.008870  [51264/90240]\n",
      "loss: 1.204851  [57664/90240]\n",
      "loss: 0.978455  [64064/90240]\n",
      "loss: 0.910251  [70464/90240]\n",
      "loss: 0.568986  [76864/90240]\n",
      "loss: 1.095977  [83264/90240]\n",
      "loss: 0.753910  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.903687 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.010730  [   64/90240]\n",
      "loss: 1.123198  [ 6464/90240]\n",
      "loss: 0.887182  [12864/90240]\n",
      "loss: 0.764786  [19264/90240]\n",
      "loss: 0.836654  [25664/90240]\n",
      "loss: 0.569981  [32064/90240]\n",
      "loss: 0.920262  [38464/90240]\n",
      "loss: 1.005493  [44864/90240]\n",
      "loss: 0.658140  [51264/90240]\n",
      "loss: 0.868319  [57664/90240]\n",
      "loss: 0.742017  [64064/90240]\n",
      "loss: 0.800915  [70464/90240]\n",
      "loss: 0.787407  [76864/90240]\n",
      "loss: 0.853663  [83264/90240]\n",
      "loss: 0.799499  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.806504 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.018453  [   64/90240]\n",
      "loss: 0.853613  [ 6464/90240]\n",
      "loss: 0.773455  [12864/90240]\n",
      "loss: 0.646037  [19264/90240]\n",
      "loss: 0.743949  [25664/90240]\n",
      "loss: 0.892948  [32064/90240]\n",
      "loss: 0.838538  [38464/90240]\n",
      "loss: 0.628014  [44864/90240]\n",
      "loss: 0.774952  [51264/90240]\n",
      "loss: 0.965691  [57664/90240]\n",
      "loss: 1.025831  [64064/90240]\n",
      "loss: 0.780498  [70464/90240]\n",
      "loss: 0.669388  [76864/90240]\n",
      "loss: 0.806056  [83264/90240]\n",
      "loss: 0.685879  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.748552 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.700468  [   64/90240]\n",
      "loss: 0.804451  [ 6464/90240]\n",
      "loss: 0.580929  [12864/90240]\n",
      "loss: 0.794788  [19264/90240]\n",
      "loss: 0.661276  [25664/90240]\n",
      "loss: 0.658613  [32064/90240]\n",
      "loss: 0.536655  [38464/90240]\n",
      "loss: 0.877694  [44864/90240]\n",
      "loss: 0.489517  [51264/90240]\n",
      "loss: 0.643993  [57664/90240]\n",
      "loss: 0.400294  [64064/90240]\n",
      "loss: 0.629271  [70464/90240]\n",
      "loss: 0.761471  [76864/90240]\n",
      "loss: 0.826966  [83264/90240]\n",
      "loss: 0.427850  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.698697 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.437654  [   64/90240]\n",
      "loss: 0.886684  [ 6464/90240]\n",
      "loss: 0.801699  [12864/90240]\n",
      "loss: 0.781509  [19264/90240]\n",
      "loss: 0.630670  [25664/90240]\n",
      "loss: 0.422052  [32064/90240]\n",
      "loss: 0.723140  [38464/90240]\n",
      "loss: 0.593911  [44864/90240]\n",
      "loss: 0.790421  [51264/90240]\n",
      "loss: 0.594898  [57664/90240]\n",
      "loss: 0.917157  [64064/90240]\n",
      "loss: 0.585119  [70464/90240]\n",
      "loss: 0.560749  [76864/90240]\n",
      "loss: 0.310749  [83264/90240]\n",
      "loss: 0.897081  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.680507 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.531327  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.495610  [ 6464/90240]\n",
      "loss: 0.639496  [12864/90240]\n",
      "loss: 0.671753  [19264/90240]\n",
      "loss: 0.709865  [25664/90240]\n",
      "loss: 0.724021  [32064/90240]\n",
      "loss: 0.694370  [38464/90240]\n",
      "loss: 0.408715  [44864/90240]\n",
      "loss: 0.625244  [51264/90240]\n",
      "loss: 0.649616  [57664/90240]\n",
      "loss: 0.859535  [64064/90240]\n",
      "loss: 0.696848  [70464/90240]\n",
      "loss: 0.675903  [76864/90240]\n",
      "loss: 0.348705  [83264/90240]\n",
      "loss: 0.626831  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.633089 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.394720  [   64/90240]\n",
      "loss: 0.727558  [ 6464/90240]\n",
      "loss: 0.444979  [12864/90240]\n",
      "loss: 0.605202  [19264/90240]\n",
      "loss: 0.746426  [25664/90240]\n",
      "loss: 0.799333  [32064/90240]\n",
      "loss: 0.593351  [38464/90240]\n",
      "loss: 0.411760  [44864/90240]\n",
      "loss: 0.543101  [51264/90240]\n",
      "loss: 0.409789  [57664/90240]\n",
      "loss: 0.484013  [64064/90240]\n",
      "loss: 0.894021  [70464/90240]\n",
      "loss: 0.600550  [76864/90240]\n",
      "loss: 0.735617  [83264/90240]\n",
      "loss: 0.709375  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.603431 \n",
      "\n",
      "Done!\n",
      "model : m2\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=5832, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.906974  [   64/90240]\n",
      "loss: 3.893855  [ 6464/90240]\n",
      "loss: 3.829141  [12864/90240]\n",
      "loss: 3.798301  [19264/90240]\n",
      "loss: 3.850478  [25664/90240]\n",
      "loss: 3.831377  [32064/90240]\n",
      "loss: 3.767686  [38464/90240]\n",
      "loss: 3.803342  [44864/90240]\n",
      "loss: 3.673485  [51264/90240]\n",
      "loss: 3.700434  [57664/90240]\n",
      "loss: 3.637802  [64064/90240]\n",
      "loss: 3.464477  [70464/90240]\n",
      "loss: 3.474580  [76864/90240]\n",
      "loss: 3.293550  [83264/90240]\n",
      "loss: 3.269331  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 3.247362 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.193257  [   64/90240]\n",
      "loss: 3.180182  [ 6464/90240]\n",
      "loss: 3.041015  [12864/90240]\n",
      "loss: 2.882138  [19264/90240]\n",
      "loss: 2.800174  [25664/90240]\n",
      "loss: 2.499028  [32064/90240]\n",
      "loss: 2.598006  [38464/90240]\n",
      "loss: 2.381727  [44864/90240]\n",
      "loss: 2.324264  [51264/90240]\n",
      "loss: 2.186188  [57664/90240]\n",
      "loss: 2.122790  [64064/90240]\n",
      "loss: 2.016607  [70464/90240]\n",
      "loss: 1.933491  [76864/90240]\n",
      "loss: 1.902646  [83264/90240]\n",
      "loss: 1.788471  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 56.3%, Avg loss: 1.859966 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.737521  [   64/90240]\n",
      "loss: 2.026818  [ 6464/90240]\n",
      "loss: 1.710112  [12864/90240]\n",
      "loss: 1.783298  [19264/90240]\n",
      "loss: 1.382979  [25664/90240]\n",
      "loss: 1.715474  [32064/90240]\n",
      "loss: 1.563928  [38464/90240]\n",
      "loss: 1.595673  [44864/90240]\n",
      "loss: 1.574137  [51264/90240]\n",
      "loss: 1.605310  [57664/90240]\n",
      "loss: 1.667161  [64064/90240]\n",
      "loss: 1.657518  [70464/90240]\n",
      "loss: 1.467376  [76864/90240]\n",
      "loss: 1.639397  [83264/90240]\n",
      "loss: 1.489867  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.485070 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.493826  [   64/90240]\n",
      "loss: 1.378186  [ 6464/90240]\n",
      "loss: 1.626865  [12864/90240]\n",
      "loss: 1.461337  [19264/90240]\n",
      "loss: 1.362077  [25664/90240]\n",
      "loss: 1.488529  [32064/90240]\n",
      "loss: 1.040134  [38464/90240]\n",
      "loss: 1.745724  [44864/90240]\n",
      "loss: 1.436478  [51264/90240]\n",
      "loss: 1.640893  [57664/90240]\n",
      "loss: 1.315826  [64064/90240]\n",
      "loss: 1.129995  [70464/90240]\n",
      "loss: 1.807672  [76864/90240]\n",
      "loss: 1.514172  [83264/90240]\n",
      "loss: 1.226199  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.358170 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.190921  [   64/90240]\n",
      "loss: 1.424389  [ 6464/90240]\n",
      "loss: 1.272338  [12864/90240]\n",
      "loss: 1.438397  [19264/90240]\n",
      "loss: 1.295807  [25664/90240]\n",
      "loss: 1.524702  [32064/90240]\n",
      "loss: 1.186878  [38464/90240]\n",
      "loss: 1.305087  [44864/90240]\n",
      "loss: 0.971960  [51264/90240]\n",
      "loss: 1.092189  [57664/90240]\n",
      "loss: 1.135181  [64064/90240]\n",
      "loss: 1.495666  [70464/90240]\n",
      "loss: 1.156199  [76864/90240]\n",
      "loss: 1.480034  [83264/90240]\n",
      "loss: 1.193496  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 1.284588 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.237890  [   64/90240]\n",
      "loss: 1.352729  [ 6464/90240]\n",
      "loss: 1.466740  [12864/90240]\n",
      "loss: 1.186266  [19264/90240]\n",
      "loss: 1.033675  [25664/90240]\n",
      "loss: 1.106711  [32064/90240]\n",
      "loss: 1.711199  [38464/90240]\n",
      "loss: 1.322870  [44864/90240]\n",
      "loss: 1.162513  [51264/90240]\n",
      "loss: 1.088968  [57664/90240]\n",
      "loss: 1.097816  [64064/90240]\n",
      "loss: 1.063573  [70464/90240]\n",
      "loss: 1.066576  [76864/90240]\n",
      "loss: 1.138232  [83264/90240]\n",
      "loss: 1.715142  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.239854 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.191929  [   64/90240]\n",
      "loss: 1.229841  [ 6464/90240]\n",
      "loss: 1.186405  [12864/90240]\n",
      "loss: 1.440680  [19264/90240]\n",
      "loss: 1.130889  [25664/90240]\n",
      "loss: 1.121071  [32064/90240]\n",
      "loss: 1.239531  [38464/90240]\n",
      "loss: 1.569235  [44864/90240]\n",
      "loss: 1.207301  [51264/90240]\n",
      "loss: 1.221693  [57664/90240]\n",
      "loss: 0.960656  [64064/90240]\n",
      "loss: 0.947534  [70464/90240]\n",
      "loss: 1.302524  [76864/90240]\n",
      "loss: 1.234406  [83264/90240]\n",
      "loss: 1.129145  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 1.208450 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.374703  [   64/90240]\n",
      "loss: 1.408768  [ 6464/90240]\n",
      "loss: 1.166493  [12864/90240]\n",
      "loss: 1.270619  [19264/90240]\n",
      "loss: 0.881595  [25664/90240]\n",
      "loss: 1.284392  [32064/90240]\n",
      "loss: 1.067106  [38464/90240]\n",
      "loss: 1.230651  [44864/90240]\n",
      "loss: 1.185031  [51264/90240]\n",
      "loss: 1.260058  [57664/90240]\n",
      "loss: 1.287872  [64064/90240]\n",
      "loss: 1.430447  [70464/90240]\n",
      "loss: 1.415367  [76864/90240]\n",
      "loss: 1.105723  [83264/90240]\n",
      "loss: 1.445486  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 1.181596 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.930544  [   64/90240]\n",
      "loss: 1.303783  [ 6464/90240]\n",
      "loss: 1.037223  [12864/90240]\n",
      "loss: 1.083315  [19264/90240]\n",
      "loss: 1.306001  [25664/90240]\n",
      "loss: 1.063588  [32064/90240]\n",
      "loss: 1.597819  [38464/90240]\n",
      "loss: 1.259992  [44864/90240]\n",
      "loss: 1.316522  [51264/90240]\n",
      "loss: 1.445874  [57664/90240]\n",
      "loss: 1.031198  [64064/90240]\n",
      "loss: 1.193432  [70464/90240]\n",
      "loss: 1.075438  [76864/90240]\n",
      "loss: 1.162528  [83264/90240]\n",
      "loss: 1.047997  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 1.164779 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.934892  [   64/90240]\n",
      "loss: 1.567199  [ 6464/90240]\n",
      "loss: 1.012359  [12864/90240]\n",
      "loss: 1.081281  [19264/90240]\n",
      "loss: 1.307655  [25664/90240]\n",
      "loss: 0.980487  [32064/90240]\n",
      "loss: 1.106249  [38464/90240]\n",
      "loss: 1.117499  [44864/90240]\n",
      "loss: 1.119074  [51264/90240]\n",
      "loss: 1.380788  [57664/90240]\n",
      "loss: 0.849285  [64064/90240]\n",
      "loss: 1.228292  [70464/90240]\n",
      "loss: 0.926370  [76864/90240]\n",
      "loss: 1.184336  [83264/90240]\n",
      "loss: 1.124274  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.141884 \n",
      "\n",
      "Done!\n",
      "model : m2\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=5832, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.866157  [   64/90240]\n",
      "loss: 3.854405  [ 6464/90240]\n",
      "loss: 3.844743  [12864/90240]\n",
      "loss: 3.841419  [19264/90240]\n",
      "loss: 3.857301  [25664/90240]\n",
      "loss: 3.825118  [32064/90240]\n",
      "loss: 3.839349  [38464/90240]\n",
      "loss: 3.825361  [44864/90240]\n",
      "loss: 3.824599  [51264/90240]\n",
      "loss: 3.809731  [57664/90240]\n",
      "loss: 3.818668  [64064/90240]\n",
      "loss: 3.792267  [70464/90240]\n",
      "loss: 3.780249  [76864/90240]\n",
      "loss: 3.776395  [83264/90240]\n",
      "loss: 3.773779  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 17.3%, Avg loss: 3.758438 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.759831  [   64/90240]\n",
      "loss: 3.757487  [ 6464/90240]\n",
      "loss: 3.719242  [12864/90240]\n",
      "loss: 3.689179  [19264/90240]\n",
      "loss: 3.663880  [25664/90240]\n",
      "loss: 3.635761  [32064/90240]\n",
      "loss: 3.589022  [38464/90240]\n",
      "loss: 3.542265  [44864/90240]\n",
      "loss: 3.473772  [51264/90240]\n",
      "loss: 3.433012  [57664/90240]\n",
      "loss: 3.268308  [64064/90240]\n",
      "loss: 3.233107  [70464/90240]\n",
      "loss: 3.017434  [76864/90240]\n",
      "loss: 3.063475  [83264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.932811  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 38.2%, Avg loss: 2.832513 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.675854  [   64/90240]\n",
      "loss: 2.769250  [ 6464/90240]\n",
      "loss: 2.570743  [12864/90240]\n",
      "loss: 2.497970  [19264/90240]\n",
      "loss: 2.394085  [25664/90240]\n",
      "loss: 2.239528  [32064/90240]\n",
      "loss: 2.244998  [38464/90240]\n",
      "loss: 1.967606  [44864/90240]\n",
      "loss: 1.902959  [51264/90240]\n",
      "loss: 2.147106  [57664/90240]\n",
      "loss: 1.970632  [64064/90240]\n",
      "loss: 2.125830  [70464/90240]\n",
      "loss: 2.205099  [76864/90240]\n",
      "loss: 1.910123  [83264/90240]\n",
      "loss: 1.826229  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 1.699529 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.745895  [   64/90240]\n",
      "loss: 1.837903  [ 6464/90240]\n",
      "loss: 1.574419  [12864/90240]\n",
      "loss: 1.460827  [19264/90240]\n",
      "loss: 1.412774  [25664/90240]\n",
      "loss: 1.736470  [32064/90240]\n",
      "loss: 1.524203  [38464/90240]\n",
      "loss: 1.580355  [44864/90240]\n",
      "loss: 1.169003  [51264/90240]\n",
      "loss: 1.716056  [57664/90240]\n",
      "loss: 1.596002  [64064/90240]\n",
      "loss: 1.402915  [70464/90240]\n",
      "loss: 1.610790  [76864/90240]\n",
      "loss: 1.664986  [83264/90240]\n",
      "loss: 1.196723  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 1.418916 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.601940  [   64/90240]\n",
      "loss: 1.440761  [ 6464/90240]\n",
      "loss: 1.468409  [12864/90240]\n",
      "loss: 1.310209  [19264/90240]\n",
      "loss: 1.436552  [25664/90240]\n",
      "loss: 1.580839  [32064/90240]\n",
      "loss: 1.302922  [38464/90240]\n",
      "loss: 1.539007  [44864/90240]\n",
      "loss: 1.278005  [51264/90240]\n",
      "loss: 1.470365  [57664/90240]\n",
      "loss: 1.428948  [64064/90240]\n",
      "loss: 1.165952  [70464/90240]\n",
      "loss: 1.234666  [76864/90240]\n",
      "loss: 1.395437  [83264/90240]\n",
      "loss: 1.408023  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.314749 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.367714  [   64/90240]\n",
      "loss: 1.183100  [ 6464/90240]\n",
      "loss: 1.013679  [12864/90240]\n",
      "loss: 1.476061  [19264/90240]\n",
      "loss: 1.342797  [25664/90240]\n",
      "loss: 1.187459  [32064/90240]\n",
      "loss: 1.151273  [38464/90240]\n",
      "loss: 1.072288  [44864/90240]\n",
      "loss: 1.083680  [51264/90240]\n",
      "loss: 1.383769  [57664/90240]\n",
      "loss: 1.080890  [64064/90240]\n",
      "loss: 1.522247  [70464/90240]\n",
      "loss: 1.353676  [76864/90240]\n",
      "loss: 1.082070  [83264/90240]\n",
      "loss: 1.125396  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.260705 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.359865  [   64/90240]\n",
      "loss: 1.171287  [ 6464/90240]\n",
      "loss: 1.495764  [12864/90240]\n",
      "loss: 1.337299  [19264/90240]\n",
      "loss: 0.760249  [25664/90240]\n",
      "loss: 1.467207  [32064/90240]\n",
      "loss: 1.248345  [38464/90240]\n",
      "loss: 1.150796  [44864/90240]\n",
      "loss: 1.337582  [51264/90240]\n",
      "loss: 1.247558  [57664/90240]\n",
      "loss: 1.137971  [64064/90240]\n",
      "loss: 1.133082  [70464/90240]\n",
      "loss: 0.929465  [76864/90240]\n",
      "loss: 1.224157  [83264/90240]\n",
      "loss: 0.931748  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.211034 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.930428  [   64/90240]\n",
      "loss: 0.812120  [ 6464/90240]\n",
      "loss: 1.169682  [12864/90240]\n",
      "loss: 1.042837  [19264/90240]\n",
      "loss: 1.016550  [25664/90240]\n",
      "loss: 0.921581  [32064/90240]\n",
      "loss: 1.133117  [38464/90240]\n",
      "loss: 1.099034  [44864/90240]\n",
      "loss: 1.504342  [51264/90240]\n",
      "loss: 1.303973  [57664/90240]\n",
      "loss: 1.515997  [64064/90240]\n",
      "loss: 1.413427  [70464/90240]\n",
      "loss: 1.191273  [76864/90240]\n",
      "loss: 1.135862  [83264/90240]\n",
      "loss: 1.135130  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 1.173145 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.338081  [   64/90240]\n",
      "loss: 1.171892  [ 6464/90240]\n",
      "loss: 0.940433  [12864/90240]\n",
      "loss: 1.166115  [19264/90240]\n",
      "loss: 1.017374  [25664/90240]\n",
      "loss: 0.988762  [32064/90240]\n",
      "loss: 1.155944  [38464/90240]\n",
      "loss: 1.013461  [44864/90240]\n",
      "loss: 1.108152  [51264/90240]\n",
      "loss: 0.951616  [57664/90240]\n",
      "loss: 1.219252  [64064/90240]\n",
      "loss: 0.969109  [70464/90240]\n",
      "loss: 1.097208  [76864/90240]\n",
      "loss: 1.114555  [83264/90240]\n",
      "loss: 1.223723  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 1.144746 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.908778  [   64/90240]\n",
      "loss: 1.258042  [ 6464/90240]\n",
      "loss: 1.408341  [12864/90240]\n",
      "loss: 1.092584  [19264/90240]\n",
      "loss: 1.259477  [25664/90240]\n",
      "loss: 1.187938  [32064/90240]\n",
      "loss: 1.147087  [38464/90240]\n",
      "loss: 1.359406  [44864/90240]\n",
      "loss: 0.811878  [51264/90240]\n",
      "loss: 0.960292  [57664/90240]\n",
      "loss: 0.753187  [64064/90240]\n",
      "loss: 1.150564  [70464/90240]\n",
      "loss: 1.079260  [76864/90240]\n",
      "loss: 1.152001  [83264/90240]\n",
      "loss: 1.477925  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.110752 \n",
      "\n",
      "Done!\n",
      "model : m2\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=5832, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.850189  [   64/90240]\n",
      "loss: 3.852679  [ 6464/90240]\n",
      "loss: 3.847621  [12864/90240]\n",
      "loss: 3.845587  [19264/90240]\n",
      "loss: 3.848738  [25664/90240]\n",
      "loss: 3.857955  [32064/90240]\n",
      "loss: 3.843344  [38464/90240]\n",
      "loss: 3.847370  [44864/90240]\n",
      "loss: 3.854199  [51264/90240]\n",
      "loss: 3.844318  [57664/90240]\n",
      "loss: 3.845791  [64064/90240]\n",
      "loss: 3.839602  [70464/90240]\n",
      "loss: 3.834586  [76864/90240]\n",
      "loss: 3.844259  [83264/90240]\n",
      "loss: 3.840268  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.7%, Avg loss: 3.840549 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.839325  [   64/90240]\n",
      "loss: 3.845178  [ 6464/90240]\n",
      "loss: 3.835787  [12864/90240]\n",
      "loss: 3.826295  [19264/90240]\n",
      "loss: 3.828327  [25664/90240]\n",
      "loss: 3.827305  [32064/90240]\n",
      "loss: 3.822454  [38464/90240]\n",
      "loss: 3.823918  [44864/90240]\n",
      "loss: 3.823493  [51264/90240]\n",
      "loss: 3.819967  [57664/90240]\n",
      "loss: 3.829749  [64064/90240]\n",
      "loss: 3.807210  [70464/90240]\n",
      "loss: 3.808759  [76864/90240]\n",
      "loss: 3.808247  [83264/90240]\n",
      "loss: 3.810308  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 11.7%, Avg loss: 3.807186 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.802021  [   64/90240]\n",
      "loss: 3.791534  [ 6464/90240]\n",
      "loss: 3.795531  [12864/90240]\n",
      "loss: 3.795105  [19264/90240]\n",
      "loss: 3.788039  [25664/90240]\n",
      "loss: 3.766294  [32064/90240]\n",
      "loss: 3.754225  [38464/90240]\n",
      "loss: 3.761028  [44864/90240]\n",
      "loss: 3.762326  [51264/90240]\n",
      "loss: 3.689276  [57664/90240]\n",
      "loss: 3.697258  [64064/90240]\n",
      "loss: 3.635197  [70464/90240]\n",
      "loss: 3.604400  [76864/90240]\n",
      "loss: 3.579394  [83264/90240]\n",
      "loss: 3.475804  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 14.4%, Avg loss: 3.496832 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.556774  [   64/90240]\n",
      "loss: 3.320237  [ 6464/90240]\n",
      "loss: 3.345048  [12864/90240]\n",
      "loss: 3.312793  [19264/90240]\n",
      "loss: 3.242570  [25664/90240]\n",
      "loss: 3.087942  [32064/90240]\n",
      "loss: 3.082669  [38464/90240]\n",
      "loss: 2.851483  [44864/90240]\n",
      "loss: 2.759440  [51264/90240]\n",
      "loss: 2.839178  [57664/90240]\n",
      "loss: 2.684278  [64064/90240]\n",
      "loss: 2.582793  [70464/90240]\n",
      "loss: 2.531888  [76864/90240]\n",
      "loss: 2.468708  [83264/90240]\n",
      "loss: 2.368114  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 39.9%, Avg loss: 2.326295 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.234703  [   64/90240]\n",
      "loss: 2.215885  [ 6464/90240]\n",
      "loss: 2.047469  [12864/90240]\n",
      "loss: 2.264024  [19264/90240]\n",
      "loss: 2.036984  [25664/90240]\n",
      "loss: 2.130004  [32064/90240]\n",
      "loss: 2.328926  [38464/90240]\n",
      "loss: 1.721081  [44864/90240]\n",
      "loss: 1.913385  [51264/90240]\n",
      "loss: 1.904105  [57664/90240]\n",
      "loss: 1.661771  [64064/90240]\n",
      "loss: 1.778600  [70464/90240]\n",
      "loss: 1.835113  [76864/90240]\n",
      "loss: 1.648195  [83264/90240]\n",
      "loss: 1.562936  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.682592 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.839007  [   64/90240]\n",
      "loss: 1.623314  [ 6464/90240]\n",
      "loss: 1.643256  [12864/90240]\n",
      "loss: 1.717774  [19264/90240]\n",
      "loss: 1.533681  [25664/90240]\n",
      "loss: 1.370135  [32064/90240]\n",
      "loss: 1.523128  [38464/90240]\n",
      "loss: 1.436539  [44864/90240]\n",
      "loss: 1.362947  [51264/90240]\n",
      "loss: 1.509152  [57664/90240]\n",
      "loss: 1.323889  [64064/90240]\n",
      "loss: 1.222077  [70464/90240]\n",
      "loss: 1.037802  [76864/90240]\n",
      "loss: 1.261076  [83264/90240]\n",
      "loss: 1.165030  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.453862 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.475682  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.628355  [ 6464/90240]\n",
      "loss: 1.423312  [12864/90240]\n",
      "loss: 1.665065  [19264/90240]\n",
      "loss: 1.220224  [25664/90240]\n",
      "loss: 1.133638  [32064/90240]\n",
      "loss: 1.583960  [38464/90240]\n",
      "loss: 1.410623  [44864/90240]\n",
      "loss: 1.203074  [51264/90240]\n",
      "loss: 1.313967  [57664/90240]\n",
      "loss: 1.446555  [64064/90240]\n",
      "loss: 1.400237  [70464/90240]\n",
      "loss: 1.014809  [76864/90240]\n",
      "loss: 1.398735  [83264/90240]\n",
      "loss: 1.883815  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 1.339090 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.426862  [   64/90240]\n",
      "loss: 0.993838  [ 6464/90240]\n",
      "loss: 1.177962  [12864/90240]\n",
      "loss: 1.648221  [19264/90240]\n",
      "loss: 0.949641  [25664/90240]\n",
      "loss: 1.215923  [32064/90240]\n",
      "loss: 1.288725  [38464/90240]\n",
      "loss: 1.403495  [44864/90240]\n",
      "loss: 1.277868  [51264/90240]\n",
      "loss: 1.418809  [57664/90240]\n",
      "loss: 1.639472  [64064/90240]\n",
      "loss: 1.323968  [70464/90240]\n",
      "loss: 1.363939  [76864/90240]\n",
      "loss: 1.254811  [83264/90240]\n",
      "loss: 1.135253  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.257836 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.163356  [   64/90240]\n",
      "loss: 1.644871  [ 6464/90240]\n",
      "loss: 1.162973  [12864/90240]\n",
      "loss: 1.068453  [19264/90240]\n",
      "loss: 1.225917  [25664/90240]\n",
      "loss: 0.901031  [32064/90240]\n",
      "loss: 1.333528  [38464/90240]\n",
      "loss: 1.273033  [44864/90240]\n",
      "loss: 1.010779  [51264/90240]\n",
      "loss: 1.229775  [57664/90240]\n",
      "loss: 1.066794  [64064/90240]\n",
      "loss: 0.799155  [70464/90240]\n",
      "loss: 1.110347  [76864/90240]\n",
      "loss: 1.201394  [83264/90240]\n",
      "loss: 1.090968  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.205113 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.682013  [   64/90240]\n",
      "loss: 1.195713  [ 6464/90240]\n",
      "loss: 1.364271  [12864/90240]\n",
      "loss: 0.826333  [19264/90240]\n",
      "loss: 1.271613  [25664/90240]\n",
      "loss: 1.086397  [32064/90240]\n",
      "loss: 1.158502  [38464/90240]\n",
      "loss: 0.903636  [44864/90240]\n",
      "loss: 1.309438  [51264/90240]\n",
      "loss: 1.564589  [57664/90240]\n",
      "loss: 1.232039  [64064/90240]\n",
      "loss: 1.386301  [70464/90240]\n",
      "loss: 0.801584  [76864/90240]\n",
      "loss: 1.464494  [83264/90240]\n",
      "loss: 1.000021  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 1.161017 \n",
      "\n",
      "Done!\n",
      "model : m3\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=5832, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.934370  [   64/90240]\n",
      "loss: 1.934114  [ 6464/90240]\n",
      "loss: 1.411352  [12864/90240]\n",
      "loss: 1.039591  [19264/90240]\n",
      "loss: 1.097524  [25664/90240]\n",
      "loss: 1.158273  [32064/90240]\n",
      "loss: 1.213142  [38464/90240]\n",
      "loss: 1.101215  [44864/90240]\n",
      "loss: 0.922950  [51264/90240]\n",
      "loss: 0.850346  [57664/90240]\n",
      "loss: 1.142052  [64064/90240]\n",
      "loss: 0.738584  [70464/90240]\n",
      "loss: 0.868221  [76864/90240]\n",
      "loss: 0.824549  [83264/90240]\n",
      "loss: 0.801529  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.792885 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.670793  [   64/90240]\n",
      "loss: 0.738480  [ 6464/90240]\n",
      "loss: 0.550056  [12864/90240]\n",
      "loss: 0.822733  [19264/90240]\n",
      "loss: 0.523530  [25664/90240]\n",
      "loss: 0.766742  [32064/90240]\n",
      "loss: 0.697770  [38464/90240]\n",
      "loss: 0.795984  [44864/90240]\n",
      "loss: 0.649858  [51264/90240]\n",
      "loss: 0.554280  [57664/90240]\n",
      "loss: 0.754049  [64064/90240]\n",
      "loss: 0.583424  [70464/90240]\n",
      "loss: 0.797474  [76864/90240]\n",
      "loss: 0.511226  [83264/90240]\n",
      "loss: 0.677046  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.657860 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.677321  [   64/90240]\n",
      "loss: 0.616338  [ 6464/90240]\n",
      "loss: 0.670102  [12864/90240]\n",
      "loss: 0.559809  [19264/90240]\n",
      "loss: 0.537071  [25664/90240]\n",
      "loss: 0.333087  [32064/90240]\n",
      "loss: 0.582620  [38464/90240]\n",
      "loss: 0.599357  [44864/90240]\n",
      "loss: 0.488689  [51264/90240]\n",
      "loss: 0.522732  [57664/90240]\n",
      "loss: 0.654412  [64064/90240]\n",
      "loss: 0.488595  [70464/90240]\n",
      "loss: 0.601333  [76864/90240]\n",
      "loss: 0.680698  [83264/90240]\n",
      "loss: 0.577542  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.607823 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.416255  [   64/90240]\n",
      "loss: 0.587895  [ 6464/90240]\n",
      "loss: 0.462048  [12864/90240]\n",
      "loss: 0.571558  [19264/90240]\n",
      "loss: 0.476031  [25664/90240]\n",
      "loss: 0.587676  [32064/90240]\n",
      "loss: 0.818013  [38464/90240]\n",
      "loss: 0.559021  [44864/90240]\n",
      "loss: 0.508491  [51264/90240]\n",
      "loss: 0.509974  [57664/90240]\n",
      "loss: 0.877702  [64064/90240]\n",
      "loss: 0.583365  [70464/90240]\n",
      "loss: 0.510528  [76864/90240]\n",
      "loss: 0.470650  [83264/90240]\n",
      "loss: 0.524533  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.583103 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.502851  [   64/90240]\n",
      "loss: 0.407454  [ 6464/90240]\n",
      "loss: 0.453639  [12864/90240]\n",
      "loss: 0.855269  [19264/90240]\n",
      "loss: 0.230121  [25664/90240]\n",
      "loss: 0.613068  [32064/90240]\n",
      "loss: 0.515049  [38464/90240]\n",
      "loss: 0.459937  [44864/90240]\n",
      "loss: 0.432756  [51264/90240]\n",
      "loss: 0.535755  [57664/90240]\n",
      "loss: 0.539401  [64064/90240]\n",
      "loss: 0.510666  [70464/90240]\n",
      "loss: 0.529088  [76864/90240]\n",
      "loss: 0.584441  [83264/90240]\n",
      "loss: 0.518904  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.565529 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.463728  [   64/90240]\n",
      "loss: 0.473864  [ 6464/90240]\n",
      "loss: 0.533633  [12864/90240]\n",
      "loss: 0.434254  [19264/90240]\n",
      "loss: 0.383706  [25664/90240]\n",
      "loss: 0.486092  [32064/90240]\n",
      "loss: 0.691936  [38464/90240]\n",
      "loss: 0.447780  [44864/90240]\n",
      "loss: 0.574058  [51264/90240]\n",
      "loss: 0.509882  [57664/90240]\n",
      "loss: 0.493284  [64064/90240]\n",
      "loss: 0.745054  [70464/90240]\n",
      "loss: 0.273469  [76864/90240]\n",
      "loss: 0.459260  [83264/90240]\n",
      "loss: 0.472515  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.550297 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.359837  [   64/90240]\n",
      "loss: 0.596701  [ 6464/90240]\n",
      "loss: 0.384945  [12864/90240]\n",
      "loss: 0.568214  [19264/90240]\n",
      "loss: 0.521394  [25664/90240]\n",
      "loss: 0.561848  [32064/90240]\n",
      "loss: 0.413547  [38464/90240]\n",
      "loss: 0.740524  [44864/90240]\n",
      "loss: 0.422486  [51264/90240]\n",
      "loss: 0.300385  [57664/90240]\n",
      "loss: 0.495796  [64064/90240]\n",
      "loss: 0.578165  [70464/90240]\n",
      "loss: 0.561227  [76864/90240]\n",
      "loss: 0.452854  [83264/90240]\n",
      "loss: 0.414909  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.546178 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.287752  [   64/90240]\n",
      "loss: 0.313369  [ 6464/90240]\n",
      "loss: 0.512138  [12864/90240]\n",
      "loss: 0.387708  [19264/90240]\n",
      "loss: 0.782426  [25664/90240]\n",
      "loss: 0.312808  [32064/90240]\n",
      "loss: 0.493813  [38464/90240]\n",
      "loss: 0.385154  [44864/90240]\n",
      "loss: 0.504958  [51264/90240]\n",
      "loss: 0.486866  [57664/90240]\n",
      "loss: 0.554931  [64064/90240]\n",
      "loss: 0.354571  [70464/90240]\n",
      "loss: 0.758808  [76864/90240]\n",
      "loss: 0.572625  [83264/90240]\n",
      "loss: 0.360698  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.529367 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.459046  [   64/90240]\n",
      "loss: 0.910344  [ 6464/90240]\n",
      "loss: 0.484113  [12864/90240]\n",
      "loss: 0.354595  [19264/90240]\n",
      "loss: 0.381125  [25664/90240]\n",
      "loss: 0.315162  [32064/90240]\n",
      "loss: 0.310769  [38464/90240]\n",
      "loss: 0.581216  [44864/90240]\n",
      "loss: 0.304376  [51264/90240]\n",
      "loss: 0.304512  [57664/90240]\n",
      "loss: 0.379882  [64064/90240]\n",
      "loss: 0.557465  [70464/90240]\n",
      "loss: 0.431779  [76864/90240]\n",
      "loss: 0.346881  [83264/90240]\n",
      "loss: 0.570574  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.536194 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.347524  [   64/90240]\n",
      "loss: 0.448760  [ 6464/90240]\n",
      "loss: 0.296317  [12864/90240]\n",
      "loss: 0.444063  [19264/90240]\n",
      "loss: 0.333337  [25664/90240]\n",
      "loss: 0.457906  [32064/90240]\n",
      "loss: 0.248824  [38464/90240]\n",
      "loss: 0.465573  [44864/90240]\n",
      "loss: 0.700180  [51264/90240]\n",
      "loss: 0.483305  [57664/90240]\n",
      "loss: 0.283590  [64064/90240]\n",
      "loss: 0.487449  [70464/90240]\n",
      "loss: 0.440669  [76864/90240]\n",
      "loss: 0.387092  [83264/90240]\n",
      "loss: 0.545305  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.537316 \n",
      "\n",
      "Done!\n",
      "model : m3\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=5832, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.869553  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.975516  [ 6464/90240]\n",
      "loss: 2.152772  [12864/90240]\n",
      "loss: 1.720869  [19264/90240]\n",
      "loss: 1.679960  [25664/90240]\n",
      "loss: 1.141195  [32064/90240]\n",
      "loss: 1.043952  [38464/90240]\n",
      "loss: 1.349162  [44864/90240]\n",
      "loss: 1.053683  [51264/90240]\n",
      "loss: 0.805878  [57664/90240]\n",
      "loss: 1.080154  [64064/90240]\n",
      "loss: 0.901209  [70464/90240]\n",
      "loss: 1.064331  [76864/90240]\n",
      "loss: 0.803815  [83264/90240]\n",
      "loss: 1.201345  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.898310 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.989814  [   64/90240]\n",
      "loss: 0.843821  [ 6464/90240]\n",
      "loss: 0.851990  [12864/90240]\n",
      "loss: 0.747637  [19264/90240]\n",
      "loss: 0.670485  [25664/90240]\n",
      "loss: 0.947655  [32064/90240]\n",
      "loss: 0.671073  [38464/90240]\n",
      "loss: 0.775890  [44864/90240]\n",
      "loss: 1.057487  [51264/90240]\n",
      "loss: 0.713559  [57664/90240]\n",
      "loss: 0.678372  [64064/90240]\n",
      "loss: 0.604775  [70464/90240]\n",
      "loss: 1.046188  [76864/90240]\n",
      "loss: 0.469803  [83264/90240]\n",
      "loss: 0.886236  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.688686 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.439055  [   64/90240]\n",
      "loss: 0.488268  [ 6464/90240]\n",
      "loss: 0.445612  [12864/90240]\n",
      "loss: 0.810088  [19264/90240]\n",
      "loss: 0.614481  [25664/90240]\n",
      "loss: 0.828104  [32064/90240]\n",
      "loss: 0.640451  [38464/90240]\n",
      "loss: 0.440713  [44864/90240]\n",
      "loss: 0.625522  [51264/90240]\n",
      "loss: 0.374907  [57664/90240]\n",
      "loss: 0.492885  [64064/90240]\n",
      "loss: 0.494688  [70464/90240]\n",
      "loss: 0.621920  [76864/90240]\n",
      "loss: 0.734407  [83264/90240]\n",
      "loss: 0.703458  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.588202 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.745903  [   64/90240]\n",
      "loss: 0.665675  [ 6464/90240]\n",
      "loss: 1.135937  [12864/90240]\n",
      "loss: 0.382424  [19264/90240]\n",
      "loss: 0.252302  [25664/90240]\n",
      "loss: 0.471153  [32064/90240]\n",
      "loss: 0.568589  [38464/90240]\n",
      "loss: 0.627704  [44864/90240]\n",
      "loss: 0.551567  [51264/90240]\n",
      "loss: 0.488314  [57664/90240]\n",
      "loss: 0.521656  [64064/90240]\n",
      "loss: 0.410318  [70464/90240]\n",
      "loss: 0.611003  [76864/90240]\n",
      "loss: 0.394025  [83264/90240]\n",
      "loss: 0.712411  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.541986 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.271148  [   64/90240]\n",
      "loss: 0.401059  [ 6464/90240]\n",
      "loss: 0.509583  [12864/90240]\n",
      "loss: 0.480912  [19264/90240]\n",
      "loss: 0.397221  [25664/90240]\n",
      "loss: 0.442872  [32064/90240]\n",
      "loss: 0.381341  [38464/90240]\n",
      "loss: 0.617804  [44864/90240]\n",
      "loss: 0.365487  [51264/90240]\n",
      "loss: 0.431399  [57664/90240]\n",
      "loss: 0.526684  [64064/90240]\n",
      "loss: 0.523779  [70464/90240]\n",
      "loss: 0.355204  [76864/90240]\n",
      "loss: 0.532000  [83264/90240]\n",
      "loss: 0.515348  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.498083 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.327764  [   64/90240]\n",
      "loss: 0.286376  [ 6464/90240]\n",
      "loss: 0.451829  [12864/90240]\n",
      "loss: 0.397823  [19264/90240]\n",
      "loss: 0.442624  [25664/90240]\n",
      "loss: 0.237574  [32064/90240]\n",
      "loss: 0.420130  [38464/90240]\n",
      "loss: 0.392317  [44864/90240]\n",
      "loss: 0.564823  [51264/90240]\n",
      "loss: 0.511020  [57664/90240]\n",
      "loss: 0.581360  [64064/90240]\n",
      "loss: 0.240798  [70464/90240]\n",
      "loss: 0.600478  [76864/90240]\n",
      "loss: 0.543038  [83264/90240]\n",
      "loss: 0.383367  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.477042 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.370585  [   64/90240]\n",
      "loss: 0.306765  [ 6464/90240]\n",
      "loss: 0.374786  [12864/90240]\n",
      "loss: 0.418989  [19264/90240]\n",
      "loss: 0.414855  [25664/90240]\n",
      "loss: 0.542627  [32064/90240]\n",
      "loss: 0.301809  [38464/90240]\n",
      "loss: 0.330728  [44864/90240]\n",
      "loss: 0.500943  [51264/90240]\n",
      "loss: 0.401796  [57664/90240]\n",
      "loss: 0.407781  [64064/90240]\n",
      "loss: 0.768880  [70464/90240]\n",
      "loss: 0.381801  [76864/90240]\n",
      "loss: 0.495773  [83264/90240]\n",
      "loss: 0.381607  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.466613 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.488569  [   64/90240]\n",
      "loss: 0.345686  [ 6464/90240]\n",
      "loss: 0.347252  [12864/90240]\n",
      "loss: 0.262018  [19264/90240]\n",
      "loss: 0.337209  [25664/90240]\n",
      "loss: 0.302735  [32064/90240]\n",
      "loss: 0.517101  [38464/90240]\n",
      "loss: 0.562229  [44864/90240]\n",
      "loss: 0.380558  [51264/90240]\n",
      "loss: 0.290004  [57664/90240]\n",
      "loss: 0.394191  [64064/90240]\n",
      "loss: 0.257463  [70464/90240]\n",
      "loss: 0.374003  [76864/90240]\n",
      "loss: 0.410076  [83264/90240]\n",
      "loss: 0.443201  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.444787 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.324785  [   64/90240]\n",
      "loss: 0.373725  [ 6464/90240]\n",
      "loss: 0.318862  [12864/90240]\n",
      "loss: 0.255409  [19264/90240]\n",
      "loss: 0.433016  [25664/90240]\n",
      "loss: 0.367522  [32064/90240]\n",
      "loss: 0.423194  [38464/90240]\n",
      "loss: 0.457310  [44864/90240]\n",
      "loss: 0.877692  [51264/90240]\n",
      "loss: 0.180404  [57664/90240]\n",
      "loss: 0.259417  [64064/90240]\n",
      "loss: 0.438990  [70464/90240]\n",
      "loss: 0.295948  [76864/90240]\n",
      "loss: 0.262539  [83264/90240]\n",
      "loss: 0.527310  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.451068 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.163406  [   64/90240]\n",
      "loss: 0.406835  [ 6464/90240]\n",
      "loss: 0.383789  [12864/90240]\n",
      "loss: 0.295553  [19264/90240]\n",
      "loss: 0.302730  [25664/90240]\n",
      "loss: 0.356916  [32064/90240]\n",
      "loss: 0.500208  [38464/90240]\n",
      "loss: 0.267510  [44864/90240]\n",
      "loss: 0.356031  [51264/90240]\n",
      "loss: 0.293571  [57664/90240]\n",
      "loss: 0.371352  [64064/90240]\n",
      "loss: 0.416795  [70464/90240]\n",
      "loss: 0.381049  [76864/90240]\n",
      "loss: 0.362927  [83264/90240]\n",
      "loss: 0.251592  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.440148 \n",
      "\n",
      "Done!\n",
      "model : m3\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=5832, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.854658  [   64/90240]\n",
      "loss: 3.696591  [ 6464/90240]\n",
      "loss: 3.229896  [12864/90240]\n",
      "loss: 2.701683  [19264/90240]\n",
      "loss: 2.135292  [25664/90240]\n",
      "loss: 1.734425  [32064/90240]\n",
      "loss: 1.474828  [38464/90240]\n",
      "loss: 1.260007  [44864/90240]\n",
      "loss: 1.263125  [51264/90240]\n",
      "loss: 1.146830  [57664/90240]\n",
      "loss: 0.947613  [64064/90240]\n",
      "loss: 1.077822  [70464/90240]\n",
      "loss: 1.175846  [76864/90240]\n",
      "loss: 1.278853  [83264/90240]\n",
      "loss: 1.057201  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 1.117436 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.201511  [   64/90240]\n",
      "loss: 1.119028  [ 6464/90240]\n",
      "loss: 1.138307  [12864/90240]\n",
      "loss: 0.955685  [19264/90240]\n",
      "loss: 0.622546  [25664/90240]\n",
      "loss: 0.788092  [32064/90240]\n",
      "loss: 0.951355  [38464/90240]\n",
      "loss: 1.033231  [44864/90240]\n",
      "loss: 0.894730  [51264/90240]\n",
      "loss: 1.067744  [57664/90240]\n",
      "loss: 0.702858  [64064/90240]\n",
      "loss: 0.881300  [70464/90240]\n",
      "loss: 0.742150  [76864/90240]\n",
      "loss: 0.827267  [83264/90240]\n",
      "loss: 0.967763  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.806884 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.758536  [   64/90240]\n",
      "loss: 0.842541  [ 6464/90240]\n",
      "loss: 0.717492  [12864/90240]\n",
      "loss: 0.719447  [19264/90240]\n",
      "loss: 0.620051  [25664/90240]\n",
      "loss: 0.553233  [32064/90240]\n",
      "loss: 0.402138  [38464/90240]\n",
      "loss: 0.713566  [44864/90240]\n",
      "loss: 0.703888  [51264/90240]\n",
      "loss: 0.531663  [57664/90240]\n",
      "loss: 0.837119  [64064/90240]\n",
      "loss: 0.679965  [70464/90240]\n",
      "loss: 0.495804  [76864/90240]\n",
      "loss: 0.840205  [83264/90240]\n",
      "loss: 0.758634  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.663303 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.510167  [   64/90240]\n",
      "loss: 0.496751  [ 6464/90240]\n",
      "loss: 0.714316  [12864/90240]\n",
      "loss: 0.615947  [19264/90240]\n",
      "loss: 0.622672  [25664/90240]\n",
      "loss: 0.586078  [32064/90240]\n",
      "loss: 0.517908  [38464/90240]\n",
      "loss: 0.539471  [44864/90240]\n",
      "loss: 0.595783  [51264/90240]\n",
      "loss: 0.623661  [57664/90240]\n",
      "loss: 0.733413  [64064/90240]\n",
      "loss: 0.507295  [70464/90240]\n",
      "loss: 0.495986  [76864/90240]\n",
      "loss: 0.685048  [83264/90240]\n",
      "loss: 0.324400  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.575378 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.398839  [   64/90240]\n",
      "loss: 0.462236  [ 6464/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.690875  [12864/90240]\n",
      "loss: 0.383222  [19264/90240]\n",
      "loss: 0.717844  [25664/90240]\n",
      "loss: 0.406538  [32064/90240]\n",
      "loss: 0.316588  [38464/90240]\n",
      "loss: 0.455714  [44864/90240]\n",
      "loss: 0.574165  [51264/90240]\n",
      "loss: 0.410466  [57664/90240]\n",
      "loss: 0.603726  [64064/90240]\n",
      "loss: 0.604300  [70464/90240]\n",
      "loss: 0.599134  [76864/90240]\n",
      "loss: 0.417043  [83264/90240]\n",
      "loss: 0.452953  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.533212 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.469175  [   64/90240]\n",
      "loss: 0.513563  [ 6464/90240]\n",
      "loss: 0.419346  [12864/90240]\n",
      "loss: 0.579355  [19264/90240]\n",
      "loss: 0.387408  [25664/90240]\n",
      "loss: 0.479232  [32064/90240]\n",
      "loss: 0.384981  [38464/90240]\n",
      "loss: 0.581341  [44864/90240]\n",
      "loss: 0.692244  [51264/90240]\n",
      "loss: 0.321343  [57664/90240]\n",
      "loss: 0.683909  [64064/90240]\n",
      "loss: 0.384908  [70464/90240]\n",
      "loss: 0.347885  [76864/90240]\n",
      "loss: 0.405863  [83264/90240]\n",
      "loss: 0.683559  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.496250 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.214117  [   64/90240]\n",
      "loss: 0.346674  [ 6464/90240]\n",
      "loss: 0.417510  [12864/90240]\n",
      "loss: 0.331978  [19264/90240]\n",
      "loss: 0.483417  [25664/90240]\n",
      "loss: 0.457954  [32064/90240]\n",
      "loss: 0.440405  [38464/90240]\n",
      "loss: 0.477745  [44864/90240]\n",
      "loss: 0.352986  [51264/90240]\n",
      "loss: 0.480134  [57664/90240]\n",
      "loss: 0.374120  [64064/90240]\n",
      "loss: 0.613343  [70464/90240]\n",
      "loss: 0.407635  [76864/90240]\n",
      "loss: 0.454619  [83264/90240]\n",
      "loss: 0.535869  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.474241 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.374499  [   64/90240]\n",
      "loss: 0.519380  [ 6464/90240]\n",
      "loss: 0.432104  [12864/90240]\n",
      "loss: 0.418664  [19264/90240]\n",
      "loss: 0.337983  [25664/90240]\n",
      "loss: 0.502269  [32064/90240]\n",
      "loss: 0.363415  [38464/90240]\n",
      "loss: 0.586343  [44864/90240]\n",
      "loss: 0.414030  [51264/90240]\n",
      "loss: 0.339778  [57664/90240]\n",
      "loss: 0.300205  [64064/90240]\n",
      "loss: 0.319797  [70464/90240]\n",
      "loss: 0.751458  [76864/90240]\n",
      "loss: 0.333956  [83264/90240]\n",
      "loss: 0.472410  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.462408 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.408081  [   64/90240]\n",
      "loss: 0.338489  [ 6464/90240]\n",
      "loss: 0.241009  [12864/90240]\n",
      "loss: 0.338852  [19264/90240]\n",
      "loss: 0.241803  [25664/90240]\n",
      "loss: 0.275437  [32064/90240]\n",
      "loss: 0.216409  [38464/90240]\n",
      "loss: 0.377810  [44864/90240]\n",
      "loss: 0.296314  [51264/90240]\n",
      "loss: 0.420101  [57664/90240]\n",
      "loss: 0.293350  [64064/90240]\n",
      "loss: 0.416187  [70464/90240]\n",
      "loss: 0.355822  [76864/90240]\n",
      "loss: 0.486369  [83264/90240]\n",
      "loss: 0.299372  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.450036 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.296565  [   64/90240]\n",
      "loss: 0.474778  [ 6464/90240]\n",
      "loss: 0.294468  [12864/90240]\n",
      "loss: 0.184170  [19264/90240]\n",
      "loss: 0.333450  [25664/90240]\n",
      "loss: 0.374438  [32064/90240]\n",
      "loss: 0.272174  [38464/90240]\n",
      "loss: 0.508755  [44864/90240]\n",
      "loss: 0.393274  [51264/90240]\n",
      "loss: 0.446323  [57664/90240]\n",
      "loss: 0.437313  [64064/90240]\n",
      "loss: 0.390761  [70464/90240]\n",
      "loss: 0.330222  [76864/90240]\n",
      "loss: 0.454747  [83264/90240]\n",
      "loss: 0.582316  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.439318 \n",
      "\n",
      "Done!\n",
      "model : m4\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=5832, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.959627  [   64/90240]\n",
      "loss: 3.619619  [ 6464/90240]\n",
      "loss: 3.358679  [12864/90240]\n",
      "loss: 3.166436  [19264/90240]\n",
      "loss: 2.948620  [25664/90240]\n",
      "loss: 2.726230  [32064/90240]\n",
      "loss: 2.657519  [38464/90240]\n",
      "loss: 2.247475  [44864/90240]\n",
      "loss: 2.135854  [51264/90240]\n",
      "loss: 2.121118  [57664/90240]\n",
      "loss: 2.050893  [64064/90240]\n",
      "loss: 1.880909  [70464/90240]\n",
      "loss: 2.044492  [76864/90240]\n",
      "loss: 1.694112  [83264/90240]\n",
      "loss: 1.635750  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 1.688677 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.786369  [   64/90240]\n",
      "loss: 1.682217  [ 6464/90240]\n",
      "loss: 1.510486  [12864/90240]\n",
      "loss: 1.425769  [19264/90240]\n",
      "loss: 1.632761  [25664/90240]\n",
      "loss: 1.416136  [32064/90240]\n",
      "loss: 1.547167  [38464/90240]\n",
      "loss: 1.516996  [44864/90240]\n",
      "loss: 1.759043  [51264/90240]\n",
      "loss: 1.500423  [57664/90240]\n",
      "loss: 1.415939  [64064/90240]\n",
      "loss: 1.477815  [70464/90240]\n",
      "loss: 1.530966  [76864/90240]\n",
      "loss: 1.449438  [83264/90240]\n",
      "loss: 1.184550  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.358311 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.457603  [   64/90240]\n",
      "loss: 1.170007  [ 6464/90240]\n",
      "loss: 1.295751  [12864/90240]\n",
      "loss: 0.969758  [19264/90240]\n",
      "loss: 1.292992  [25664/90240]\n",
      "loss: 1.361115  [32064/90240]\n",
      "loss: 1.022383  [38464/90240]\n",
      "loss: 1.472988  [44864/90240]\n",
      "loss: 1.528865  [51264/90240]\n",
      "loss: 1.311227  [57664/90240]\n",
      "loss: 1.455679  [64064/90240]\n",
      "loss: 1.608510  [70464/90240]\n",
      "loss: 1.306674  [76864/90240]\n",
      "loss: 1.097175  [83264/90240]\n",
      "loss: 1.269845  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 1.235680 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.310912  [   64/90240]\n",
      "loss: 1.572012  [ 6464/90240]\n",
      "loss: 1.296346  [12864/90240]\n",
      "loss: 1.072453  [19264/90240]\n",
      "loss: 1.207580  [25664/90240]\n",
      "loss: 1.479216  [32064/90240]\n",
      "loss: 1.235979  [38464/90240]\n",
      "loss: 1.260296  [44864/90240]\n",
      "loss: 1.182316  [51264/90240]\n",
      "loss: 1.240360  [57664/90240]\n",
      "loss: 1.300071  [64064/90240]\n",
      "loss: 1.119578  [70464/90240]\n",
      "loss: 1.300162  [76864/90240]\n",
      "loss: 1.337940  [83264/90240]\n",
      "loss: 1.263982  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 1.165103 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.427266  [   64/90240]\n",
      "loss: 0.920980  [ 6464/90240]\n",
      "loss: 0.942793  [12864/90240]\n",
      "loss: 1.326016  [19264/90240]\n",
      "loss: 1.356976  [25664/90240]\n",
      "loss: 1.153769  [32064/90240]\n",
      "loss: 1.408567  [38464/90240]\n",
      "loss: 1.117677  [44864/90240]\n",
      "loss: 1.156540  [51264/90240]\n",
      "loss: 1.282076  [57664/90240]\n",
      "loss: 1.006778  [64064/90240]\n",
      "loss: 1.074148  [70464/90240]\n",
      "loss: 0.888570  [76864/90240]\n",
      "loss: 1.131353  [83264/90240]\n",
      "loss: 0.996111  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 1.118114 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.073057  [   64/90240]\n",
      "loss: 1.120874  [ 6464/90240]\n",
      "loss: 1.161997  [12864/90240]\n",
      "loss: 1.259678  [19264/90240]\n",
      "loss: 1.280602  [25664/90240]\n",
      "loss: 1.139262  [32064/90240]\n",
      "loss: 1.198889  [38464/90240]\n",
      "loss: 1.178564  [44864/90240]\n",
      "loss: 0.830342  [51264/90240]\n",
      "loss: 1.203521  [57664/90240]\n",
      "loss: 1.379808  [64064/90240]\n",
      "loss: 1.160745  [70464/90240]\n",
      "loss: 1.133649  [76864/90240]\n",
      "loss: 0.916751  [83264/90240]\n",
      "loss: 1.018643  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 1.077941 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.352987  [   64/90240]\n",
      "loss: 1.278459  [ 6464/90240]\n",
      "loss: 1.121143  [12864/90240]\n",
      "loss: 1.139236  [19264/90240]\n",
      "loss: 1.038464  [25664/90240]\n",
      "loss: 0.960519  [32064/90240]\n",
      "loss: 0.998216  [38464/90240]\n",
      "loss: 1.184959  [44864/90240]\n",
      "loss: 1.073598  [51264/90240]\n",
      "loss: 0.971884  [57664/90240]\n",
      "loss: 1.121449  [64064/90240]\n",
      "loss: 1.128266  [70464/90240]\n",
      "loss: 0.999288  [76864/90240]\n",
      "loss: 0.862239  [83264/90240]\n",
      "loss: 1.100598  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.032627 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.756498  [   64/90240]\n",
      "loss: 0.947326  [ 6464/90240]\n",
      "loss: 1.132907  [12864/90240]\n",
      "loss: 1.102461  [19264/90240]\n",
      "loss: 1.410914  [25664/90240]\n",
      "loss: 1.201939  [32064/90240]\n",
      "loss: 1.030836  [38464/90240]\n",
      "loss: 1.039549  [44864/90240]\n",
      "loss: 0.968892  [51264/90240]\n",
      "loss: 1.251289  [57664/90240]\n",
      "loss: 1.103287  [64064/90240]\n",
      "loss: 0.845131  [70464/90240]\n",
      "loss: 0.913254  [76864/90240]\n",
      "loss: 1.056255  [83264/90240]\n",
      "loss: 0.901599  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.995329 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.246091  [   64/90240]\n",
      "loss: 0.854410  [ 6464/90240]\n",
      "loss: 0.869828  [12864/90240]\n",
      "loss: 1.012846  [19264/90240]\n",
      "loss: 1.226754  [25664/90240]\n",
      "loss: 1.033171  [32064/90240]\n",
      "loss: 1.106196  [38464/90240]\n",
      "loss: 0.745095  [44864/90240]\n",
      "loss: 1.124457  [51264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.638417  [57664/90240]\n",
      "loss: 0.832367  [64064/90240]\n",
      "loss: 0.818945  [70464/90240]\n",
      "loss: 0.806632  [76864/90240]\n",
      "loss: 0.952895  [83264/90240]\n",
      "loss: 0.820922  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.976718 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.073632  [   64/90240]\n",
      "loss: 0.994372  [ 6464/90240]\n",
      "loss: 0.959553  [12864/90240]\n",
      "loss: 1.075355  [19264/90240]\n",
      "loss: 1.025903  [25664/90240]\n",
      "loss: 1.192362  [32064/90240]\n",
      "loss: 0.855102  [38464/90240]\n",
      "loss: 0.865798  [44864/90240]\n",
      "loss: 0.842476  [51264/90240]\n",
      "loss: 0.806570  [57664/90240]\n",
      "loss: 1.089511  [64064/90240]\n",
      "loss: 0.853811  [70464/90240]\n",
      "loss: 0.748860  [76864/90240]\n",
      "loss: 0.719050  [83264/90240]\n",
      "loss: 0.737119  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.940347 \n",
      "\n",
      "Done!\n",
      "model : m4\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=5832, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.856241  [   64/90240]\n",
      "loss: 3.777363  [ 6464/90240]\n",
      "loss: 3.735100  [12864/90240]\n",
      "loss: 3.629780  [19264/90240]\n",
      "loss: 3.501403  [25664/90240]\n",
      "loss: 3.401532  [32064/90240]\n",
      "loss: 3.217283  [38464/90240]\n",
      "loss: 3.073139  [44864/90240]\n",
      "loss: 2.878354  [51264/90240]\n",
      "loss: 2.740726  [57664/90240]\n",
      "loss: 2.407432  [64064/90240]\n",
      "loss: 2.396254  [70464/90240]\n",
      "loss: 2.079638  [76864/90240]\n",
      "loss: 2.101489  [83264/90240]\n",
      "loss: 1.986547  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.943806 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.889578  [   64/90240]\n",
      "loss: 1.976177  [ 6464/90240]\n",
      "loss: 1.696298  [12864/90240]\n",
      "loss: 1.705110  [19264/90240]\n",
      "loss: 1.582501  [25664/90240]\n",
      "loss: 1.567585  [32064/90240]\n",
      "loss: 1.607634  [38464/90240]\n",
      "loss: 1.590555  [44864/90240]\n",
      "loss: 1.522613  [51264/90240]\n",
      "loss: 1.428200  [57664/90240]\n",
      "loss: 1.423477  [64064/90240]\n",
      "loss: 1.668999  [70464/90240]\n",
      "loss: 1.607411  [76864/90240]\n",
      "loss: 1.288424  [83264/90240]\n",
      "loss: 1.457927  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 1.387831 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.236205  [   64/90240]\n",
      "loss: 1.204082  [ 6464/90240]\n",
      "loss: 1.285347  [12864/90240]\n",
      "loss: 1.384930  [19264/90240]\n",
      "loss: 1.367093  [25664/90240]\n",
      "loss: 1.190656  [32064/90240]\n",
      "loss: 1.758038  [38464/90240]\n",
      "loss: 1.065165  [44864/90240]\n",
      "loss: 0.905743  [51264/90240]\n",
      "loss: 1.540706  [57664/90240]\n",
      "loss: 1.435515  [64064/90240]\n",
      "loss: 1.674970  [70464/90240]\n",
      "loss: 0.916419  [76864/90240]\n",
      "loss: 0.915973  [83264/90240]\n",
      "loss: 1.398177  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.263059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.329974  [   64/90240]\n",
      "loss: 1.084634  [ 6464/90240]\n",
      "loss: 0.858870  [12864/90240]\n",
      "loss: 1.144143  [19264/90240]\n",
      "loss: 0.978597  [25664/90240]\n",
      "loss: 1.325750  [32064/90240]\n",
      "loss: 1.268248  [38464/90240]\n",
      "loss: 1.214476  [44864/90240]\n",
      "loss: 1.349979  [51264/90240]\n",
      "loss: 1.427920  [57664/90240]\n",
      "loss: 1.377656  [64064/90240]\n",
      "loss: 1.716539  [70464/90240]\n",
      "loss: 1.396625  [76864/90240]\n",
      "loss: 1.251131  [83264/90240]\n",
      "loss: 1.452052  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 1.180880 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.105151  [   64/90240]\n",
      "loss: 1.227055  [ 6464/90240]\n",
      "loss: 1.045170  [12864/90240]\n",
      "loss: 1.180932  [19264/90240]\n",
      "loss: 1.212435  [25664/90240]\n",
      "loss: 1.161720  [32064/90240]\n",
      "loss: 1.207991  [38464/90240]\n",
      "loss: 1.095405  [44864/90240]\n",
      "loss: 0.999121  [51264/90240]\n",
      "loss: 1.325364  [57664/90240]\n",
      "loss: 1.199523  [64064/90240]\n",
      "loss: 1.597177  [70464/90240]\n",
      "loss: 1.068448  [76864/90240]\n",
      "loss: 1.329179  [83264/90240]\n",
      "loss: 1.257262  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.123208 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.049867  [   64/90240]\n",
      "loss: 1.221587  [ 6464/90240]\n",
      "loss: 0.915439  [12864/90240]\n",
      "loss: 1.250194  [19264/90240]\n",
      "loss: 0.851302  [25664/90240]\n",
      "loss: 1.335514  [32064/90240]\n",
      "loss: 1.242326  [38464/90240]\n",
      "loss: 0.727475  [44864/90240]\n",
      "loss: 1.124625  [51264/90240]\n",
      "loss: 1.185189  [57664/90240]\n",
      "loss: 1.135443  [64064/90240]\n",
      "loss: 1.074249  [70464/90240]\n",
      "loss: 0.944192  [76864/90240]\n",
      "loss: 0.877365  [83264/90240]\n",
      "loss: 1.236182  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.073998 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.006753  [   64/90240]\n",
      "loss: 0.829708  [ 6464/90240]\n",
      "loss: 1.422123  [12864/90240]\n",
      "loss: 1.129834  [19264/90240]\n",
      "loss: 0.907365  [25664/90240]\n",
      "loss: 0.915803  [32064/90240]\n",
      "loss: 1.045220  [38464/90240]\n",
      "loss: 0.869813  [44864/90240]\n",
      "loss: 0.862899  [51264/90240]\n",
      "loss: 1.150517  [57664/90240]\n",
      "loss: 0.930218  [64064/90240]\n",
      "loss: 0.929387  [70464/90240]\n",
      "loss: 1.112752  [76864/90240]\n",
      "loss: 1.043360  [83264/90240]\n",
      "loss: 1.097803  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.034198 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.019980  [   64/90240]\n",
      "loss: 1.074750  [ 6464/90240]\n",
      "loss: 1.243229  [12864/90240]\n",
      "loss: 0.955424  [19264/90240]\n",
      "loss: 1.217795  [25664/90240]\n",
      "loss: 1.110785  [32064/90240]\n",
      "loss: 0.734450  [38464/90240]\n",
      "loss: 1.047506  [44864/90240]\n",
      "loss: 1.057387  [51264/90240]\n",
      "loss: 0.990444  [57664/90240]\n",
      "loss: 1.024886  [64064/90240]\n",
      "loss: 0.773633  [70464/90240]\n",
      "loss: 0.816567  [76864/90240]\n",
      "loss: 0.716437  [83264/90240]\n",
      "loss: 0.936527  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.985925 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.145377  [   64/90240]\n",
      "loss: 0.807829  [ 6464/90240]\n",
      "loss: 0.832812  [12864/90240]\n",
      "loss: 1.219901  [19264/90240]\n",
      "loss: 0.915002  [25664/90240]\n",
      "loss: 0.759482  [32064/90240]\n",
      "loss: 0.949707  [38464/90240]\n",
      "loss: 1.020878  [44864/90240]\n",
      "loss: 1.152682  [51264/90240]\n",
      "loss: 0.814137  [57664/90240]\n",
      "loss: 0.759045  [64064/90240]\n",
      "loss: 0.869107  [70464/90240]\n",
      "loss: 0.896899  [76864/90240]\n",
      "loss: 1.106456  [83264/90240]\n",
      "loss: 0.753844  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.947384 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.026243  [   64/90240]\n",
      "loss: 0.758708  [ 6464/90240]\n",
      "loss: 0.712888  [12864/90240]\n",
      "loss: 1.190829  [19264/90240]\n",
      "loss: 0.981383  [25664/90240]\n",
      "loss: 1.012083  [32064/90240]\n",
      "loss: 0.795289  [38464/90240]\n",
      "loss: 0.892013  [44864/90240]\n",
      "loss: 0.606379  [51264/90240]\n",
      "loss: 0.594761  [57664/90240]\n",
      "loss: 0.896858  [64064/90240]\n",
      "loss: 1.099889  [70464/90240]\n",
      "loss: 1.071936  [76864/90240]\n",
      "loss: 0.956066  [83264/90240]\n",
      "loss: 0.836828  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.908150 \n",
      "\n",
      "Done!\n",
      "model : m4\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=5832, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.850539  [   64/90240]\n",
      "loss: 3.856779  [ 6464/90240]\n",
      "loss: 3.831818  [12864/90240]\n",
      "loss: 3.831582  [19264/90240]\n",
      "loss: 3.809625  [25664/90240]\n",
      "loss: 3.791269  [32064/90240]\n",
      "loss: 3.777223  [38464/90240]\n",
      "loss: 3.736319  [44864/90240]\n",
      "loss: 3.741883  [51264/90240]\n",
      "loss: 3.674827  [57664/90240]\n",
      "loss: 3.664121  [64064/90240]\n",
      "loss: 3.598340  [70464/90240]\n",
      "loss: 3.545833  [76864/90240]\n",
      "loss: 3.456728  [83264/90240]\n",
      "loss: 3.356539  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 22.2%, Avg loss: 3.378968 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.416146  [   64/90240]\n",
      "loss: 3.260189  [ 6464/90240]\n",
      "loss: 3.151340  [12864/90240]\n",
      "loss: 2.997131  [19264/90240]\n",
      "loss: 2.970509  [25664/90240]\n",
      "loss: 2.835438  [32064/90240]\n",
      "loss: 2.999355  [38464/90240]\n",
      "loss: 2.621969  [44864/90240]\n",
      "loss: 2.868386  [51264/90240]\n",
      "loss: 2.378371  [57664/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.481536  [64064/90240]\n",
      "loss: 2.138793  [70464/90240]\n",
      "loss: 2.125553  [76864/90240]\n",
      "loss: 2.386909  [83264/90240]\n",
      "loss: 2.124543  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 1.983588 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.846808  [   64/90240]\n",
      "loss: 2.017469  [ 6464/90240]\n",
      "loss: 1.794121  [12864/90240]\n",
      "loss: 1.649011  [19264/90240]\n",
      "loss: 1.809404  [25664/90240]\n",
      "loss: 1.379981  [32064/90240]\n",
      "loss: 1.899470  [38464/90240]\n",
      "loss: 1.653295  [44864/90240]\n",
      "loss: 1.305855  [51264/90240]\n",
      "loss: 1.695848  [57664/90240]\n",
      "loss: 1.657432  [64064/90240]\n",
      "loss: 1.341579  [70464/90240]\n",
      "loss: 1.535619  [76864/90240]\n",
      "loss: 1.660773  [83264/90240]\n",
      "loss: 1.096082  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 1.444530 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.405871  [   64/90240]\n",
      "loss: 1.320311  [ 6464/90240]\n",
      "loss: 1.290499  [12864/90240]\n",
      "loss: 1.313969  [19264/90240]\n",
      "loss: 1.368845  [25664/90240]\n",
      "loss: 1.166479  [32064/90240]\n",
      "loss: 1.372347  [38464/90240]\n",
      "loss: 1.603279  [44864/90240]\n",
      "loss: 1.673308  [51264/90240]\n",
      "loss: 1.326513  [57664/90240]\n",
      "loss: 1.255865  [64064/90240]\n",
      "loss: 1.488794  [70464/90240]\n",
      "loss: 1.322118  [76864/90240]\n",
      "loss: 1.025283  [83264/90240]\n",
      "loss: 1.169728  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.261437 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.127456  [   64/90240]\n",
      "loss: 1.284108  [ 6464/90240]\n",
      "loss: 1.074574  [12864/90240]\n",
      "loss: 0.976251  [19264/90240]\n",
      "loss: 1.280690  [25664/90240]\n",
      "loss: 1.121537  [32064/90240]\n",
      "loss: 1.289118  [38464/90240]\n",
      "loss: 1.251860  [44864/90240]\n",
      "loss: 1.332494  [51264/90240]\n",
      "loss: 1.182515  [57664/90240]\n",
      "loss: 1.305150  [64064/90240]\n",
      "loss: 1.191669  [70464/90240]\n",
      "loss: 1.051480  [76864/90240]\n",
      "loss: 1.365074  [83264/90240]\n",
      "loss: 1.061675  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 1.139398 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.992468  [   64/90240]\n",
      "loss: 1.172425  [ 6464/90240]\n",
      "loss: 1.223510  [12864/90240]\n",
      "loss: 1.175198  [19264/90240]\n",
      "loss: 1.267035  [25664/90240]\n",
      "loss: 0.946962  [32064/90240]\n",
      "loss: 1.138206  [38464/90240]\n",
      "loss: 0.928348  [44864/90240]\n",
      "loss: 1.275417  [51264/90240]\n",
      "loss: 0.716287  [57664/90240]\n",
      "loss: 1.300164  [64064/90240]\n",
      "loss: 1.188570  [70464/90240]\n",
      "loss: 1.176363  [76864/90240]\n",
      "loss: 1.154170  [83264/90240]\n",
      "loss: 0.928631  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.046971 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.966225  [   64/90240]\n",
      "loss: 0.833333  [ 6464/90240]\n",
      "loss: 0.943049  [12864/90240]\n",
      "loss: 0.772831  [19264/90240]\n",
      "loss: 0.710339  [25664/90240]\n",
      "loss: 0.852482  [32064/90240]\n",
      "loss: 0.963479  [38464/90240]\n",
      "loss: 0.857556  [44864/90240]\n",
      "loss: 1.361290  [51264/90240]\n",
      "loss: 1.103460  [57664/90240]\n",
      "loss: 1.095308  [64064/90240]\n",
      "loss: 1.020365  [70464/90240]\n",
      "loss: 0.993450  [76864/90240]\n",
      "loss: 0.956238  [83264/90240]\n",
      "loss: 0.744809  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.963286 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.859945  [   64/90240]\n",
      "loss: 0.836894  [ 6464/90240]\n",
      "loss: 0.823948  [12864/90240]\n",
      "loss: 1.230952  [19264/90240]\n",
      "loss: 0.628817  [25664/90240]\n",
      "loss: 0.897653  [32064/90240]\n",
      "loss: 0.928900  [38464/90240]\n",
      "loss: 0.859960  [44864/90240]\n",
      "loss: 0.708107  [51264/90240]\n",
      "loss: 0.852285  [57664/90240]\n",
      "loss: 0.860144  [64064/90240]\n",
      "loss: 1.083668  [70464/90240]\n",
      "loss: 0.937994  [76864/90240]\n",
      "loss: 1.008114  [83264/90240]\n",
      "loss: 0.943782  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.907895 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.755155  [   64/90240]\n",
      "loss: 1.041826  [ 6464/90240]\n",
      "loss: 1.067822  [12864/90240]\n",
      "loss: 0.780050  [19264/90240]\n",
      "loss: 0.712989  [25664/90240]\n",
      "loss: 0.832004  [32064/90240]\n",
      "loss: 0.568173  [38464/90240]\n",
      "loss: 0.962449  [44864/90240]\n",
      "loss: 0.946446  [51264/90240]\n",
      "loss: 0.835005  [57664/90240]\n",
      "loss: 0.687763  [64064/90240]\n",
      "loss: 0.750442  [70464/90240]\n",
      "loss: 0.645812  [76864/90240]\n",
      "loss: 0.564747  [83264/90240]\n",
      "loss: 0.676694  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.836521 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.684498  [   64/90240]\n",
      "loss: 0.788386  [ 6464/90240]\n",
      "loss: 0.793790  [12864/90240]\n",
      "loss: 0.832289  [19264/90240]\n",
      "loss: 1.194628  [25664/90240]\n",
      "loss: 0.787609  [32064/90240]\n",
      "loss: 0.722985  [38464/90240]\n",
      "loss: 0.930215  [44864/90240]\n",
      "loss: 1.126116  [51264/90240]\n",
      "loss: 1.250758  [57664/90240]\n",
      "loss: 1.140203  [64064/90240]\n",
      "loss: 0.526063  [70464/90240]\n",
      "loss: 0.436459  [76864/90240]\n",
      "loss: 0.981496  [83264/90240]\n",
      "loss: 0.813959  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.792605 \n",
      "\n",
      "Done!\n",
      "model : m5\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10816, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.852198  [   64/90240]\n",
      "loss: 3.743461  [ 6464/90240]\n",
      "loss: 3.112548  [12864/90240]\n",
      "loss: 1.516850  [19264/90240]\n",
      "loss: 1.505975  [25664/90240]\n",
      "loss: 1.377025  [32064/90240]\n",
      "loss: 1.273060  [38464/90240]\n",
      "loss: 0.769526  [44864/90240]\n",
      "loss: 1.489014  [51264/90240]\n",
      "loss: 1.611160  [57664/90240]\n",
      "loss: 1.562634  [64064/90240]\n",
      "loss: 1.562666  [70464/90240]\n",
      "loss: 1.512911  [76864/90240]\n",
      "loss: 1.146662  [83264/90240]\n",
      "loss: 0.934202  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.255634 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.473934  [   64/90240]\n",
      "loss: 1.126801  [ 6464/90240]\n",
      "loss: 0.926993  [12864/90240]\n",
      "loss: 1.195565  [19264/90240]\n",
      "loss: 1.607895  [25664/90240]\n",
      "loss: 1.230923  [32064/90240]\n",
      "loss: 1.138452  [38464/90240]\n",
      "loss: 1.055595  [44864/90240]\n",
      "loss: 1.351991  [51264/90240]\n",
      "loss: 1.325578  [57664/90240]\n",
      "loss: 1.146916  [64064/90240]\n",
      "loss: 1.043029  [70464/90240]\n",
      "loss: 1.076261  [76864/90240]\n",
      "loss: 1.022362  [83264/90240]\n",
      "loss: 1.315689  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 1.189145 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.178288  [   64/90240]\n",
      "loss: 1.129318  [ 6464/90240]\n",
      "loss: 0.960466  [12864/90240]\n",
      "loss: 1.400756  [19264/90240]\n",
      "loss: 1.198928  [25664/90240]\n",
      "loss: 1.288959  [32064/90240]\n",
      "loss: 1.082537  [38464/90240]\n",
      "loss: 1.028529  [44864/90240]\n",
      "loss: 1.304951  [51264/90240]\n",
      "loss: 1.155393  [57664/90240]\n",
      "loss: 1.190443  [64064/90240]\n",
      "loss: 0.942811  [70464/90240]\n",
      "loss: 0.939920  [76864/90240]\n",
      "loss: 0.970431  [83264/90240]\n",
      "loss: 1.361603  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.018339 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.982851  [   64/90240]\n",
      "loss: 0.837915  [ 6464/90240]\n",
      "loss: 1.047110  [12864/90240]\n",
      "loss: 0.693624  [19264/90240]\n",
      "loss: 0.928155  [25664/90240]\n",
      "loss: 1.181566  [32064/90240]\n",
      "loss: 0.677350  [38464/90240]\n",
      "loss: 0.858199  [44864/90240]\n",
      "loss: 0.797870  [51264/90240]\n",
      "loss: 0.769235  [57664/90240]\n",
      "loss: 0.683335  [64064/90240]\n",
      "loss: 0.884730  [70464/90240]\n",
      "loss: 0.803394  [76864/90240]\n",
      "loss: 0.720376  [83264/90240]\n",
      "loss: 1.006530  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.843415 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.894257  [   64/90240]\n",
      "loss: 0.645629  [ 6464/90240]\n",
      "loss: 0.910049  [12864/90240]\n",
      "loss: 0.704393  [19264/90240]\n",
      "loss: 0.563829  [25664/90240]\n",
      "loss: 1.133017  [32064/90240]\n",
      "loss: 0.706762  [38464/90240]\n",
      "loss: 0.858961  [44864/90240]\n",
      "loss: 0.623931  [51264/90240]\n",
      "loss: 0.738756  [57664/90240]\n",
      "loss: 0.625852  [64064/90240]\n",
      "loss: 1.015831  [70464/90240]\n",
      "loss: 0.672137  [76864/90240]\n",
      "loss: 0.636411  [83264/90240]\n",
      "loss: 0.761332  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.708086 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.672295  [   64/90240]\n",
      "loss: 0.722805  [ 6464/90240]\n",
      "loss: 0.606450  [12864/90240]\n",
      "loss: 0.531156  [19264/90240]\n",
      "loss: 0.589655  [25664/90240]\n",
      "loss: 0.777453  [32064/90240]\n",
      "loss: 0.618047  [38464/90240]\n",
      "loss: 0.740473  [44864/90240]\n",
      "loss: 0.600306  [51264/90240]\n",
      "loss: 0.457050  [57664/90240]\n",
      "loss: 0.550044  [64064/90240]\n",
      "loss: 0.865668  [70464/90240]\n",
      "loss: 0.601923  [76864/90240]\n",
      "loss: 1.160809  [83264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.773584  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.639850 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.461292  [   64/90240]\n",
      "loss: 0.611257  [ 6464/90240]\n",
      "loss: 0.493441  [12864/90240]\n",
      "loss: 0.596696  [19264/90240]\n",
      "loss: 0.608089  [25664/90240]\n",
      "loss: 0.416228  [32064/90240]\n",
      "loss: 0.380064  [38464/90240]\n",
      "loss: 0.577617  [44864/90240]\n",
      "loss: 0.709077  [51264/90240]\n",
      "loss: 0.472526  [57664/90240]\n",
      "loss: 0.729326  [64064/90240]\n",
      "loss: 0.561941  [70464/90240]\n",
      "loss: 0.467104  [76864/90240]\n",
      "loss: 0.369637  [83264/90240]\n",
      "loss: 0.548564  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.582165 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.822988  [   64/90240]\n",
      "loss: 0.521401  [ 6464/90240]\n",
      "loss: 0.547387  [12864/90240]\n",
      "loss: 1.207883  [19264/90240]\n",
      "loss: 0.378733  [25664/90240]\n",
      "loss: 0.770781  [32064/90240]\n",
      "loss: 0.447495  [38464/90240]\n",
      "loss: 0.526693  [44864/90240]\n",
      "loss: 0.617887  [51264/90240]\n",
      "loss: 0.463375  [57664/90240]\n",
      "loss: 0.666618  [64064/90240]\n",
      "loss: 0.278167  [70464/90240]\n",
      "loss: 0.600101  [76864/90240]\n",
      "loss: 0.623509  [83264/90240]\n",
      "loss: 0.554070  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.548513 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.574158  [   64/90240]\n",
      "loss: 0.441547  [ 6464/90240]\n",
      "loss: 0.630558  [12864/90240]\n",
      "loss: 0.377140  [19264/90240]\n",
      "loss: 0.620416  [25664/90240]\n",
      "loss: 0.346768  [32064/90240]\n",
      "loss: 0.535494  [38464/90240]\n",
      "loss: 0.644263  [44864/90240]\n",
      "loss: 0.455330  [51264/90240]\n",
      "loss: 0.425414  [57664/90240]\n",
      "loss: 0.348030  [64064/90240]\n",
      "loss: 0.687417  [70464/90240]\n",
      "loss: 0.362817  [76864/90240]\n",
      "loss: 0.590417  [83264/90240]\n",
      "loss: 0.906729  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.545363 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.336024  [   64/90240]\n",
      "loss: 0.495192  [ 6464/90240]\n",
      "loss: 0.421844  [12864/90240]\n",
      "loss: 0.580597  [19264/90240]\n",
      "loss: 0.355830  [25664/90240]\n",
      "loss: 0.543887  [32064/90240]\n",
      "loss: 0.629744  [38464/90240]\n",
      "loss: 0.368258  [44864/90240]\n",
      "loss: 0.444953  [51264/90240]\n",
      "loss: 0.600009  [57664/90240]\n",
      "loss: 0.579245  [64064/90240]\n",
      "loss: 0.413613  [70464/90240]\n",
      "loss: 0.330904  [76864/90240]\n",
      "loss: 0.476827  [83264/90240]\n",
      "loss: 0.415601  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.517686 \n",
      "\n",
      "Done!\n",
      "model : m5\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.855622  [   64/90240]\n",
      "loss: 3.853521  [ 6464/90240]\n",
      "loss: 3.841473  [12864/90240]\n",
      "loss: 3.827658  [19264/90240]\n",
      "loss: 3.813536  [25664/90240]\n",
      "loss: 3.745295  [32064/90240]\n",
      "loss: 3.462186  [38464/90240]\n",
      "loss: 2.370287  [44864/90240]\n",
      "loss: 1.346324  [51264/90240]\n",
      "loss: 1.550720  [57664/90240]\n",
      "loss: 1.137588  [64064/90240]\n",
      "loss: 1.426571  [70464/90240]\n",
      "loss: 1.529064  [76864/90240]\n",
      "loss: 0.741374  [83264/90240]\n",
      "loss: 1.077745  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.206014 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.962747  [   64/90240]\n",
      "loss: 0.884481  [ 6464/90240]\n",
      "loss: 1.272874  [12864/90240]\n",
      "loss: 0.990156  [19264/90240]\n",
      "loss: 1.063922  [25664/90240]\n",
      "loss: 1.091182  [32064/90240]\n",
      "loss: 1.176033  [38464/90240]\n",
      "loss: 1.144832  [44864/90240]\n",
      "loss: 0.832047  [51264/90240]\n",
      "loss: 0.968771  [57664/90240]\n",
      "loss: 0.831572  [64064/90240]\n",
      "loss: 0.646659  [70464/90240]\n",
      "loss: 0.968186  [76864/90240]\n",
      "loss: 0.773282  [83264/90240]\n",
      "loss: 0.747255  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.876828 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.259680  [   64/90240]\n",
      "loss: 0.847311  [ 6464/90240]\n",
      "loss: 0.900402  [12864/90240]\n",
      "loss: 1.114643  [19264/90240]\n",
      "loss: 0.529355  [25664/90240]\n",
      "loss: 0.527207  [32064/90240]\n",
      "loss: 0.745111  [38464/90240]\n",
      "loss: 0.924605  [44864/90240]\n",
      "loss: 0.921733  [51264/90240]\n",
      "loss: 0.988235  [57664/90240]\n",
      "loss: 0.912952  [64064/90240]\n",
      "loss: 1.161634  [70464/90240]\n",
      "loss: 0.782213  [76864/90240]\n",
      "loss: 0.724905  [83264/90240]\n",
      "loss: 0.554716  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.739156 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.494095  [   64/90240]\n",
      "loss: 0.865600  [ 6464/90240]\n",
      "loss: 0.635418  [12864/90240]\n",
      "loss: 0.748188  [19264/90240]\n",
      "loss: 0.659028  [25664/90240]\n",
      "loss: 0.597902  [32064/90240]\n",
      "loss: 0.761419  [38464/90240]\n",
      "loss: 0.906681  [44864/90240]\n",
      "loss: 0.618782  [51264/90240]\n",
      "loss: 0.550418  [57664/90240]\n",
      "loss: 0.948764  [64064/90240]\n",
      "loss: 0.632164  [70464/90240]\n",
      "loss: 0.659007  [76864/90240]\n",
      "loss: 0.758747  [83264/90240]\n",
      "loss: 0.886802  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.662398 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.518708  [   64/90240]\n",
      "loss: 0.531520  [ 6464/90240]\n",
      "loss: 0.658777  [12864/90240]\n",
      "loss: 0.559353  [19264/90240]\n",
      "loss: 0.794282  [25664/90240]\n",
      "loss: 0.467758  [32064/90240]\n",
      "loss: 0.778335  [38464/90240]\n",
      "loss: 0.697926  [44864/90240]\n",
      "loss: 0.444451  [51264/90240]\n",
      "loss: 0.832251  [57664/90240]\n",
      "loss: 0.546867  [64064/90240]\n",
      "loss: 0.606741  [70464/90240]\n",
      "loss: 0.500614  [76864/90240]\n",
      "loss: 0.496344  [83264/90240]\n",
      "loss: 0.738123  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.628278 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.635797  [   64/90240]\n",
      "loss: 0.613392  [ 6464/90240]\n",
      "loss: 0.726776  [12864/90240]\n",
      "loss: 0.516828  [19264/90240]\n",
      "loss: 0.639622  [25664/90240]\n",
      "loss: 0.396365  [32064/90240]\n",
      "loss: 0.465035  [38464/90240]\n",
      "loss: 0.638534  [44864/90240]\n",
      "loss: 0.384938  [51264/90240]\n",
      "loss: 0.564396  [57664/90240]\n",
      "loss: 0.612107  [64064/90240]\n",
      "loss: 0.783052  [70464/90240]\n",
      "loss: 0.540156  [76864/90240]\n",
      "loss: 0.666966  [83264/90240]\n",
      "loss: 0.489438  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.616987 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.573784  [   64/90240]\n",
      "loss: 0.298327  [ 6464/90240]\n",
      "loss: 0.321915  [12864/90240]\n",
      "loss: 0.377917  [19264/90240]\n",
      "loss: 0.528086  [25664/90240]\n",
      "loss: 0.626254  [32064/90240]\n",
      "loss: 0.564292  [38464/90240]\n",
      "loss: 0.422508  [44864/90240]\n",
      "loss: 0.510586  [51264/90240]\n",
      "loss: 0.537148  [57664/90240]\n",
      "loss: 0.571317  [64064/90240]\n",
      "loss: 0.640070  [70464/90240]\n",
      "loss: 0.571500  [76864/90240]\n",
      "loss: 0.312664  [83264/90240]\n",
      "loss: 0.546578  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.582245 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.600051  [   64/90240]\n",
      "loss: 0.598498  [ 6464/90240]\n",
      "loss: 0.437583  [12864/90240]\n",
      "loss: 0.526892  [19264/90240]\n",
      "loss: 0.415328  [25664/90240]\n",
      "loss: 0.349189  [32064/90240]\n",
      "loss: 0.360763  [38464/90240]\n",
      "loss: 0.605620  [44864/90240]\n",
      "loss: 0.517523  [51264/90240]\n",
      "loss: 0.341149  [57664/90240]\n",
      "loss: 0.549963  [64064/90240]\n",
      "loss: 0.557332  [70464/90240]\n",
      "loss: 0.431538  [76864/90240]\n",
      "loss: 0.262963  [83264/90240]\n",
      "loss: 0.461153  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.564050 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.846641  [   64/90240]\n",
      "loss: 0.294755  [ 6464/90240]\n",
      "loss: 0.586558  [12864/90240]\n",
      "loss: 0.391638  [19264/90240]\n",
      "loss: 0.402043  [25664/90240]\n",
      "loss: 0.638215  [32064/90240]\n",
      "loss: 0.597846  [38464/90240]\n",
      "loss: 0.393738  [44864/90240]\n",
      "loss: 0.516765  [51264/90240]\n",
      "loss: 0.680528  [57664/90240]\n",
      "loss: 0.441913  [64064/90240]\n",
      "loss: 0.392738  [70464/90240]\n",
      "loss: 0.332173  [76864/90240]\n",
      "loss: 0.541612  [83264/90240]\n",
      "loss: 0.601197  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.553783 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.468474  [   64/90240]\n",
      "loss: 0.725140  [ 6464/90240]\n",
      "loss: 0.534593  [12864/90240]\n",
      "loss: 0.397671  [19264/90240]\n",
      "loss: 0.720979  [25664/90240]\n",
      "loss: 0.388156  [32064/90240]\n",
      "loss: 0.407842  [38464/90240]\n",
      "loss: 0.763354  [44864/90240]\n",
      "loss: 0.442734  [51264/90240]\n",
      "loss: 0.424537  [57664/90240]\n",
      "loss: 0.493152  [64064/90240]\n",
      "loss: 0.786358  [70464/90240]\n",
      "loss: 0.617308  [76864/90240]\n",
      "loss: 0.493248  [83264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.702848  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.544599 \n",
      "\n",
      "Done!\n",
      "model : m5\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.841815  [   64/90240]\n",
      "loss: 3.845753  [ 6464/90240]\n",
      "loss: 3.847496  [12864/90240]\n",
      "loss: 3.866701  [19264/90240]\n",
      "loss: 3.844515  [25664/90240]\n",
      "loss: 3.847548  [32064/90240]\n",
      "loss: 3.857915  [38464/90240]\n",
      "loss: 3.845614  [44864/90240]\n",
      "loss: 3.844351  [51264/90240]\n",
      "loss: 3.851570  [57664/90240]\n",
      "loss: 3.849528  [64064/90240]\n",
      "loss: 3.849348  [70464/90240]\n",
      "loss: 3.842718  [76864/90240]\n",
      "loss: 3.843027  [83264/90240]\n",
      "loss: 3.835389  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 3.839100 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.841202  [   64/90240]\n",
      "loss: 3.830250  [ 6464/90240]\n",
      "loss: 3.831880  [12864/90240]\n",
      "loss: 3.821885  [19264/90240]\n",
      "loss: 3.818343  [25664/90240]\n",
      "loss: 3.810584  [32064/90240]\n",
      "loss: 3.805929  [38464/90240]\n",
      "loss: 3.745088  [44864/90240]\n",
      "loss: 3.648364  [51264/90240]\n",
      "loss: 3.473602  [57664/90240]\n",
      "loss: 2.828290  [64064/90240]\n",
      "loss: 2.246005  [70464/90240]\n",
      "loss: 1.416531  [76864/90240]\n",
      "loss: 1.595347  [83264/90240]\n",
      "loss: 1.314615  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.415313 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.286258  [   64/90240]\n",
      "loss: 1.417694  [ 6464/90240]\n",
      "loss: 1.632101  [12864/90240]\n",
      "loss: 1.238219  [19264/90240]\n",
      "loss: 1.020645  [25664/90240]\n",
      "loss: 1.065338  [32064/90240]\n",
      "loss: 0.976564  [38464/90240]\n",
      "loss: 1.166003  [44864/90240]\n",
      "loss: 1.095248  [51264/90240]\n",
      "loss: 1.062593  [57664/90240]\n",
      "loss: 1.134033  [64064/90240]\n",
      "loss: 1.033364  [70464/90240]\n",
      "loss: 1.073751  [76864/90240]\n",
      "loss: 1.046272  [83264/90240]\n",
      "loss: 0.807450  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.939942 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.907986  [   64/90240]\n",
      "loss: 1.391442  [ 6464/90240]\n",
      "loss: 0.798025  [12864/90240]\n",
      "loss: 1.009817  [19264/90240]\n",
      "loss: 0.864610  [25664/90240]\n",
      "loss: 0.533033  [32064/90240]\n",
      "loss: 0.840179  [38464/90240]\n",
      "loss: 0.579032  [44864/90240]\n",
      "loss: 0.840195  [51264/90240]\n",
      "loss: 0.711551  [57664/90240]\n",
      "loss: 0.861958  [64064/90240]\n",
      "loss: 0.703147  [70464/90240]\n",
      "loss: 0.626946  [76864/90240]\n",
      "loss: 0.991248  [83264/90240]\n",
      "loss: 0.714137  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.790846 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.675232  [   64/90240]\n",
      "loss: 0.675433  [ 6464/90240]\n",
      "loss: 0.825659  [12864/90240]\n",
      "loss: 0.735735  [19264/90240]\n",
      "loss: 0.720415  [25664/90240]\n",
      "loss: 0.691239  [32064/90240]\n",
      "loss: 0.584504  [38464/90240]\n",
      "loss: 0.725758  [44864/90240]\n",
      "loss: 0.635860  [51264/90240]\n",
      "loss: 0.562940  [57664/90240]\n",
      "loss: 1.087114  [64064/90240]\n",
      "loss: 0.673709  [70464/90240]\n",
      "loss: 0.652880  [76864/90240]\n",
      "loss: 0.504520  [83264/90240]\n",
      "loss: 0.529104  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.703384 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.934200  [   64/90240]\n",
      "loss: 0.682293  [ 6464/90240]\n",
      "loss: 0.717037  [12864/90240]\n",
      "loss: 0.542233  [19264/90240]\n",
      "loss: 0.752784  [25664/90240]\n",
      "loss: 0.565782  [32064/90240]\n",
      "loss: 0.657753  [38464/90240]\n",
      "loss: 0.801941  [44864/90240]\n",
      "loss: 0.646161  [51264/90240]\n",
      "loss: 0.532887  [57664/90240]\n",
      "loss: 0.637730  [64064/90240]\n",
      "loss: 0.970885  [70464/90240]\n",
      "loss: 0.548831  [76864/90240]\n",
      "loss: 0.398092  [83264/90240]\n",
      "loss: 0.343707  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.637300 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.513318  [   64/90240]\n",
      "loss: 0.692140  [ 6464/90240]\n",
      "loss: 0.847603  [12864/90240]\n",
      "loss: 0.711983  [19264/90240]\n",
      "loss: 0.627255  [25664/90240]\n",
      "loss: 0.671181  [32064/90240]\n",
      "loss: 0.474410  [38464/90240]\n",
      "loss: 0.596579  [44864/90240]\n",
      "loss: 0.766066  [51264/90240]\n",
      "loss: 0.731468  [57664/90240]\n",
      "loss: 0.432877  [64064/90240]\n",
      "loss: 0.477257  [70464/90240]\n",
      "loss: 0.557324  [76864/90240]\n",
      "loss: 0.442890  [83264/90240]\n",
      "loss: 0.680433  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.644980 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.533196  [   64/90240]\n",
      "loss: 0.634539  [ 6464/90240]\n",
      "loss: 0.591584  [12864/90240]\n",
      "loss: 0.364629  [19264/90240]\n",
      "loss: 0.867754  [25664/90240]\n",
      "loss: 0.476113  [32064/90240]\n",
      "loss: 0.871453  [38464/90240]\n",
      "loss: 0.637621  [44864/90240]\n",
      "loss: 0.508690  [51264/90240]\n",
      "loss: 0.663302  [57664/90240]\n",
      "loss: 0.453675  [64064/90240]\n",
      "loss: 0.546282  [70464/90240]\n",
      "loss: 0.653877  [76864/90240]\n",
      "loss: 0.664813  [83264/90240]\n",
      "loss: 0.537143  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.606848 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.505805  [   64/90240]\n",
      "loss: 1.104648  [ 6464/90240]\n",
      "loss: 0.649583  [12864/90240]\n",
      "loss: 0.609088  [19264/90240]\n",
      "loss: 0.375142  [25664/90240]\n",
      "loss: 0.529917  [32064/90240]\n",
      "loss: 0.721633  [38464/90240]\n",
      "loss: 0.481125  [44864/90240]\n",
      "loss: 0.425106  [51264/90240]\n",
      "loss: 0.355319  [57664/90240]\n",
      "loss: 0.402868  [64064/90240]\n",
      "loss: 0.618128  [70464/90240]\n",
      "loss: 0.649044  [76864/90240]\n",
      "loss: 0.294797  [83264/90240]\n",
      "loss: 0.333871  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.559427 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.447634  [   64/90240]\n",
      "loss: 0.479021  [ 6464/90240]\n",
      "loss: 0.404730  [12864/90240]\n",
      "loss: 0.541430  [19264/90240]\n",
      "loss: 0.723480  [25664/90240]\n",
      "loss: 0.644760  [32064/90240]\n",
      "loss: 0.538572  [38464/90240]\n",
      "loss: 0.372883  [44864/90240]\n",
      "loss: 0.364212  [51264/90240]\n",
      "loss: 0.517259  [57664/90240]\n",
      "loss: 0.375196  [64064/90240]\n",
      "loss: 0.464577  [70464/90240]\n",
      "loss: 0.479103  [76864/90240]\n",
      "loss: 0.484242  [83264/90240]\n",
      "loss: 0.497129  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.555627 \n",
      "\n",
      "Done!\n",
      "model : m6\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10816, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.868097  [   64/90240]\n",
      "loss: 3.930406  [ 6464/90240]\n",
      "loss: 3.892558  [12864/90240]\n",
      "loss: 3.980143  [19264/90240]\n",
      "loss: 3.874864  [25664/90240]\n",
      "loss: 3.911839  [32064/90240]\n",
      "loss: 3.929841  [38464/90240]\n",
      "loss: 3.848194  [44864/90240]\n",
      "loss: 3.911186  [51264/90240]\n",
      "loss: 3.836909  [57664/90240]\n",
      "loss: 3.838933  [64064/90240]\n",
      "loss: 3.883543  [70464/90240]\n",
      "loss: 3.809916  [76864/90240]\n",
      "loss: 3.812999  [83264/90240]\n",
      "loss: 3.837662  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 3.804159 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.820222  [   64/90240]\n",
      "loss: 3.778219  [ 6464/90240]\n",
      "loss: 3.722855  [12864/90240]\n",
      "loss: 3.827729  [19264/90240]\n",
      "loss: 3.766285  [25664/90240]\n",
      "loss: 3.712933  [32064/90240]\n",
      "loss: 3.657782  [38464/90240]\n",
      "loss: 3.545584  [44864/90240]\n",
      "loss: 3.446686  [51264/90240]\n",
      "loss: 3.300439  [57664/90240]\n",
      "loss: 3.126384  [64064/90240]\n",
      "loss: 2.968506  [70464/90240]\n",
      "loss: 2.822969  [76864/90240]\n",
      "loss: 2.620957  [83264/90240]\n",
      "loss: 2.361093  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 2.325812 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.445905  [   64/90240]\n",
      "loss: 2.135135  [ 6464/90240]\n",
      "loss: 2.031602  [12864/90240]\n",
      "loss: 1.892509  [19264/90240]\n",
      "loss: 2.084679  [25664/90240]\n",
      "loss: 1.684916  [32064/90240]\n",
      "loss: 1.859366  [38464/90240]\n",
      "loss: 1.463999  [44864/90240]\n",
      "loss: 1.888278  [51264/90240]\n",
      "loss: 1.473693  [57664/90240]\n",
      "loss: 1.360814  [64064/90240]\n",
      "loss: 1.457412  [70464/90240]\n",
      "loss: 1.492231  [76864/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.582527  [83264/90240]\n",
      "loss: 1.186815  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 1.414613 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.435527  [   64/90240]\n",
      "loss: 2.184614  [ 6464/90240]\n",
      "loss: 1.464459  [12864/90240]\n",
      "loss: 1.444808  [19264/90240]\n",
      "loss: 1.331612  [25664/90240]\n",
      "loss: 1.380459  [32064/90240]\n",
      "loss: 1.296152  [38464/90240]\n",
      "loss: 1.482092  [44864/90240]\n",
      "loss: 1.132105  [51264/90240]\n",
      "loss: 1.333628  [57664/90240]\n",
      "loss: 1.140262  [64064/90240]\n",
      "loss: 1.059593  [70464/90240]\n",
      "loss: 1.157696  [76864/90240]\n",
      "loss: 1.120348  [83264/90240]\n",
      "loss: 1.313036  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.281704 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.283076  [   64/90240]\n",
      "loss: 1.321137  [ 6464/90240]\n",
      "loss: 1.336560  [12864/90240]\n",
      "loss: 1.098320  [19264/90240]\n",
      "loss: 1.127609  [25664/90240]\n",
      "loss: 0.968140  [32064/90240]\n",
      "loss: 1.579450  [38464/90240]\n",
      "loss: 1.355560  [44864/90240]\n",
      "loss: 1.409825  [51264/90240]\n",
      "loss: 1.262218  [57664/90240]\n",
      "loss: 1.071472  [64064/90240]\n",
      "loss: 1.442268  [70464/90240]\n",
      "loss: 1.269163  [76864/90240]\n",
      "loss: 1.237554  [83264/90240]\n",
      "loss: 1.459803  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.222925 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.516803  [   64/90240]\n",
      "loss: 1.395842  [ 6464/90240]\n",
      "loss: 1.009949  [12864/90240]\n",
      "loss: 0.996137  [19264/90240]\n",
      "loss: 1.257441  [25664/90240]\n",
      "loss: 1.183510  [32064/90240]\n",
      "loss: 1.312721  [38464/90240]\n",
      "loss: 1.449043  [44864/90240]\n",
      "loss: 1.082427  [51264/90240]\n",
      "loss: 1.763101  [57664/90240]\n",
      "loss: 1.329971  [64064/90240]\n",
      "loss: 1.295353  [70464/90240]\n",
      "loss: 1.572203  [76864/90240]\n",
      "loss: 0.982236  [83264/90240]\n",
      "loss: 1.249966  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.184563 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.986380  [   64/90240]\n",
      "loss: 0.925497  [ 6464/90240]\n",
      "loss: 1.277624  [12864/90240]\n",
      "loss: 1.138104  [19264/90240]\n",
      "loss: 1.331816  [25664/90240]\n",
      "loss: 1.140568  [32064/90240]\n",
      "loss: 1.157013  [38464/90240]\n",
      "loss: 1.662064  [44864/90240]\n",
      "loss: 1.180690  [51264/90240]\n",
      "loss: 1.228490  [57664/90240]\n",
      "loss: 1.330463  [64064/90240]\n",
      "loss: 1.017467  [70464/90240]\n",
      "loss: 1.202644  [76864/90240]\n",
      "loss: 1.406819  [83264/90240]\n",
      "loss: 1.264110  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 1.153402 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.950803  [   64/90240]\n",
      "loss: 1.561985  [ 6464/90240]\n",
      "loss: 1.514010  [12864/90240]\n",
      "loss: 1.303464  [19264/90240]\n",
      "loss: 1.373855  [25664/90240]\n",
      "loss: 0.889657  [32064/90240]\n",
      "loss: 1.019169  [38464/90240]\n",
      "loss: 1.302279  [44864/90240]\n",
      "loss: 0.912912  [51264/90240]\n",
      "loss: 1.426419  [57664/90240]\n",
      "loss: 1.071714  [64064/90240]\n",
      "loss: 0.713250  [70464/90240]\n",
      "loss: 1.170699  [76864/90240]\n",
      "loss: 1.258359  [83264/90240]\n",
      "loss: 1.016402  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 1.130721 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.011585  [   64/90240]\n",
      "loss: 1.046252  [ 6464/90240]\n",
      "loss: 1.538081  [12864/90240]\n",
      "loss: 1.139104  [19264/90240]\n",
      "loss: 1.085130  [25664/90240]\n",
      "loss: 1.167241  [32064/90240]\n",
      "loss: 1.150510  [38464/90240]\n",
      "loss: 1.135403  [44864/90240]\n",
      "loss: 1.183368  [51264/90240]\n",
      "loss: 1.378047  [57664/90240]\n",
      "loss: 0.989251  [64064/90240]\n",
      "loss: 1.313681  [70464/90240]\n",
      "loss: 1.011739  [76864/90240]\n",
      "loss: 0.999711  [83264/90240]\n",
      "loss: 1.117165  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 1.096607 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.955531  [   64/90240]\n",
      "loss: 1.059693  [ 6464/90240]\n",
      "loss: 1.155307  [12864/90240]\n",
      "loss: 1.084514  [19264/90240]\n",
      "loss: 1.478683  [25664/90240]\n",
      "loss: 0.909619  [32064/90240]\n",
      "loss: 1.066137  [38464/90240]\n",
      "loss: 1.119873  [44864/90240]\n",
      "loss: 0.918369  [51264/90240]\n",
      "loss: 0.917182  [57664/90240]\n",
      "loss: 1.176750  [64064/90240]\n",
      "loss: 1.161730  [70464/90240]\n",
      "loss: 0.972629  [76864/90240]\n",
      "loss: 0.936410  [83264/90240]\n",
      "loss: 1.094837  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 1.075915 \n",
      "\n",
      "Done!\n",
      "model : m6\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.881266  [   64/90240]\n",
      "loss: 3.834248  [ 6464/90240]\n",
      "loss: 3.853006  [12864/90240]\n",
      "loss: 3.859235  [19264/90240]\n",
      "loss: 3.844999  [25664/90240]\n",
      "loss: 3.845612  [32064/90240]\n",
      "loss: 3.852151  [38464/90240]\n",
      "loss: 3.853285  [44864/90240]\n",
      "loss: 3.850558  [51264/90240]\n",
      "loss: 3.859647  [57664/90240]\n",
      "loss: 3.850162  [64064/90240]\n",
      "loss: 3.858292  [70464/90240]\n",
      "loss: 3.848857  [76864/90240]\n",
      "loss: 3.853246  [83264/90240]\n",
      "loss: 3.849043  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850901 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.845546  [   64/90240]\n",
      "loss: 3.856649  [ 6464/90240]\n",
      "loss: 3.854049  [12864/90240]\n",
      "loss: 3.845217  [19264/90240]\n",
      "loss: 3.856743  [25664/90240]\n",
      "loss: 3.851978  [32064/90240]\n",
      "loss: 3.853269  [38464/90240]\n",
      "loss: 3.850115  [44864/90240]\n",
      "loss: 3.847647  [51264/90240]\n",
      "loss: 3.845061  [57664/90240]\n",
      "loss: 3.851576  [64064/90240]\n",
      "loss: 3.850419  [70464/90240]\n",
      "loss: 3.851502  [76864/90240]\n",
      "loss: 3.844999  [83264/90240]\n",
      "loss: 3.844621  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850824 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.849627  [   64/90240]\n",
      "loss: 3.855412  [ 6464/90240]\n",
      "loss: 3.853954  [12864/90240]\n",
      "loss: 3.848258  [19264/90240]\n",
      "loss: 3.851196  [25664/90240]\n",
      "loss: 3.845682  [32064/90240]\n",
      "loss: 3.851989  [38464/90240]\n",
      "loss: 3.846406  [44864/90240]\n",
      "loss: 3.844980  [51264/90240]\n",
      "loss: 3.848765  [57664/90240]\n",
      "loss: 3.846776  [64064/90240]\n",
      "loss: 3.849829  [70464/90240]\n",
      "loss: 3.851994  [76864/90240]\n",
      "loss: 3.853195  [83264/90240]\n",
      "loss: 3.852037  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850761 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.849942  [   64/90240]\n",
      "loss: 3.846119  [ 6464/90240]\n",
      "loss: 3.853414  [12864/90240]\n",
      "loss: 3.850988  [19264/90240]\n",
      "loss: 3.846961  [25664/90240]\n",
      "loss: 3.852067  [32064/90240]\n",
      "loss: 3.855006  [38464/90240]\n",
      "loss: 3.856294  [44864/90240]\n",
      "loss: 3.850102  [51264/90240]\n",
      "loss: 3.851864  [57664/90240]\n",
      "loss: 3.848629  [64064/90240]\n",
      "loss: 3.852874  [70464/90240]\n",
      "loss: 3.847297  [76864/90240]\n",
      "loss: 3.849643  [83264/90240]\n",
      "loss: 3.850912  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850731 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.850153  [   64/90240]\n",
      "loss: 3.851684  [ 6464/90240]\n",
      "loss: 3.847422  [12864/90240]\n",
      "loss: 3.851254  [19264/90240]\n",
      "loss: 3.849766  [25664/90240]\n",
      "loss: 3.848112  [32064/90240]\n",
      "loss: 3.848535  [38464/90240]\n",
      "loss: 3.853868  [44864/90240]\n",
      "loss: 3.849856  [51264/90240]\n",
      "loss: 3.845122  [57664/90240]\n",
      "loss: 3.851159  [64064/90240]\n",
      "loss: 3.844759  [70464/90240]\n",
      "loss: 3.848359  [76864/90240]\n",
      "loss: 3.852269  [83264/90240]\n",
      "loss: 3.849642  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850710 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.852095  [   64/90240]\n",
      "loss: 3.854189  [ 6464/90240]\n",
      "loss: 3.851856  [12864/90240]\n",
      "loss: 3.849374  [19264/90240]\n",
      "loss: 3.847586  [25664/90240]\n",
      "loss: 3.850544  [32064/90240]\n",
      "loss: 3.853782  [38464/90240]\n",
      "loss: 3.851196  [44864/90240]\n",
      "loss: 3.851624  [51264/90240]\n",
      "loss: 3.849582  [57664/90240]\n",
      "loss: 3.848657  [64064/90240]\n",
      "loss: 3.849350  [70464/90240]\n",
      "loss: 3.850619  [76864/90240]\n",
      "loss: 3.850469  [83264/90240]\n",
      "loss: 3.849643  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850703 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.850322  [   64/90240]\n",
      "loss: 3.851226  [ 6464/90240]\n",
      "loss: 3.846981  [12864/90240]\n",
      "loss: 3.849421  [19264/90240]\n",
      "loss: 3.853543  [25664/90240]\n",
      "loss: 3.852196  [32064/90240]\n",
      "loss: 3.849381  [38464/90240]\n",
      "loss: 3.847125  [44864/90240]\n",
      "loss: 3.848383  [51264/90240]\n",
      "loss: 3.850957  [57664/90240]\n",
      "loss: 3.848186  [64064/90240]\n",
      "loss: 3.847994  [70464/90240]\n",
      "loss: 3.851114  [76864/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.854786  [83264/90240]\n",
      "loss: 3.846723  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850699 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.851259  [   64/90240]\n",
      "loss: 3.850588  [ 6464/90240]\n",
      "loss: 3.850852  [12864/90240]\n",
      "loss: 3.848421  [19264/90240]\n",
      "loss: 3.852250  [25664/90240]\n",
      "loss: 3.845821  [32064/90240]\n",
      "loss: 3.849326  [38464/90240]\n",
      "loss: 3.849944  [44864/90240]\n",
      "loss: 3.847316  [51264/90240]\n",
      "loss: 3.849450  [57664/90240]\n",
      "loss: 3.849190  [64064/90240]\n",
      "loss: 3.851466  [70464/90240]\n",
      "loss: 3.848659  [76864/90240]\n",
      "loss: 3.848940  [83264/90240]\n",
      "loss: 3.849087  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850692 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.851907  [   64/90240]\n",
      "loss: 3.848042  [ 6464/90240]\n",
      "loss: 3.847028  [12864/90240]\n",
      "loss: 3.847565  [19264/90240]\n",
      "loss: 3.848220  [25664/90240]\n",
      "loss: 3.848515  [32064/90240]\n",
      "loss: 3.852323  [38464/90240]\n",
      "loss: 3.850978  [44864/90240]\n",
      "loss: 3.851851  [51264/90240]\n",
      "loss: 3.848397  [57664/90240]\n",
      "loss: 3.852640  [64064/90240]\n",
      "loss: 3.854093  [70464/90240]\n",
      "loss: 3.849094  [76864/90240]\n",
      "loss: 3.853324  [83264/90240]\n",
      "loss: 3.849870  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850698 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.852462  [   64/90240]\n",
      "loss: 3.852158  [ 6464/90240]\n",
      "loss: 3.850400  [12864/90240]\n",
      "loss: 3.851913  [19264/90240]\n",
      "loss: 3.851178  [25664/90240]\n",
      "loss: 3.852709  [32064/90240]\n",
      "loss: 3.851569  [38464/90240]\n",
      "loss: 3.847164  [44864/90240]\n",
      "loss: 3.854176  [51264/90240]\n",
      "loss: 3.849576  [57664/90240]\n",
      "loss: 3.850320  [64064/90240]\n",
      "loss: 3.849407  [70464/90240]\n",
      "loss: 3.849050  [76864/90240]\n",
      "loss: 3.850614  [83264/90240]\n",
      "loss: 3.848855  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850707 \n",
      "\n",
      "Done!\n",
      "model : m6\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.850165  [   64/90240]\n",
      "loss: 3.850374  [ 6464/90240]\n",
      "loss: 3.858385  [12864/90240]\n",
      "loss: 3.853310  [19264/90240]\n",
      "loss: 3.840228  [25664/90240]\n",
      "loss: 3.851577  [32064/90240]\n",
      "loss: 3.852425  [38464/90240]\n",
      "loss: 3.849138  [44864/90240]\n",
      "loss: 3.852283  [51264/90240]\n",
      "loss: 3.846690  [57664/90240]\n",
      "loss: 3.853459  [64064/90240]\n",
      "loss: 3.854887  [70464/90240]\n",
      "loss: 3.851839  [76864/90240]\n",
      "loss: 3.853820  [83264/90240]\n",
      "loss: 3.847617  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 3.850395 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.856163  [   64/90240]\n",
      "loss: 3.851830  [ 6464/90240]\n",
      "loss: 3.850522  [12864/90240]\n",
      "loss: 3.848021  [19264/90240]\n",
      "loss: 3.850361  [25664/90240]\n",
      "loss: 3.853958  [32064/90240]\n",
      "loss: 3.850867  [38464/90240]\n",
      "loss: 3.848926  [44864/90240]\n",
      "loss: 3.844388  [51264/90240]\n",
      "loss: 3.849939  [57664/90240]\n",
      "loss: 3.856000  [64064/90240]\n",
      "loss: 3.851940  [70464/90240]\n",
      "loss: 3.856094  [76864/90240]\n",
      "loss: 3.844572  [83264/90240]\n",
      "loss: 3.846765  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850506 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.849330  [   64/90240]\n",
      "loss: 3.849659  [ 6464/90240]\n",
      "loss: 3.848692  [12864/90240]\n",
      "loss: 3.851916  [19264/90240]\n",
      "loss: 3.853583  [25664/90240]\n",
      "loss: 3.847944  [32064/90240]\n",
      "loss: 3.849385  [38464/90240]\n",
      "loss: 3.846804  [44864/90240]\n",
      "loss: 3.853122  [51264/90240]\n",
      "loss: 3.854907  [57664/90240]\n",
      "loss: 3.846828  [64064/90240]\n",
      "loss: 3.846448  [70464/90240]\n",
      "loss: 3.849764  [76864/90240]\n",
      "loss: 3.849938  [83264/90240]\n",
      "loss: 3.852883  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 3.850549 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.853009  [   64/90240]\n",
      "loss: 3.845735  [ 6464/90240]\n",
      "loss: 3.851660  [12864/90240]\n",
      "loss: 3.848411  [19264/90240]\n",
      "loss: 3.852834  [25664/90240]\n",
      "loss: 3.853515  [32064/90240]\n",
      "loss: 3.851080  [38464/90240]\n",
      "loss: 3.846082  [44864/90240]\n",
      "loss: 3.851100  [51264/90240]\n",
      "loss: 3.852380  [57664/90240]\n",
      "loss: 3.852077  [64064/90240]\n",
      "loss: 3.851594  [70464/90240]\n",
      "loss: 3.849321  [76864/90240]\n",
      "loss: 3.850181  [83264/90240]\n",
      "loss: 3.852836  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850946 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.851305  [   64/90240]\n",
      "loss: 3.853444  [ 6464/90240]\n",
      "loss: 3.850376  [12864/90240]\n",
      "loss: 3.849369  [19264/90240]\n",
      "loss: 3.849224  [25664/90240]\n",
      "loss: 3.850640  [32064/90240]\n",
      "loss: 3.845021  [38464/90240]\n",
      "loss: 3.849226  [44864/90240]\n",
      "loss: 3.849550  [51264/90240]\n",
      "loss: 3.849609  [57664/90240]\n",
      "loss: 3.853203  [64064/90240]\n",
      "loss: 3.847761  [70464/90240]\n",
      "loss: 3.854717  [76864/90240]\n",
      "loss: 3.851797  [83264/90240]\n",
      "loss: 3.850671  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.4%, Avg loss: 3.850599 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.853631  [   64/90240]\n",
      "loss: 3.849631  [ 6464/90240]\n",
      "loss: 3.851002  [12864/90240]\n",
      "loss: 3.848348  [19264/90240]\n",
      "loss: 3.849471  [25664/90240]\n",
      "loss: 3.849150  [32064/90240]\n",
      "loss: 3.853647  [38464/90240]\n",
      "loss: 3.849485  [44864/90240]\n",
      "loss: 3.852606  [51264/90240]\n",
      "loss: 3.850334  [57664/90240]\n",
      "loss: 3.852708  [64064/90240]\n",
      "loss: 3.850587  [70464/90240]\n",
      "loss: 3.849069  [76864/90240]\n",
      "loss: 3.848963  [83264/90240]\n",
      "loss: 3.850163  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850618 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.848590  [   64/90240]\n",
      "loss: 3.849656  [ 6464/90240]\n",
      "loss: 3.848321  [12864/90240]\n",
      "loss: 3.847561  [19264/90240]\n",
      "loss: 3.846633  [25664/90240]\n",
      "loss: 3.853155  [32064/90240]\n",
      "loss: 3.849908  [38464/90240]\n",
      "loss: 3.849353  [44864/90240]\n",
      "loss: 3.851097  [51264/90240]\n",
      "loss: 3.852745  [57664/90240]\n",
      "loss: 3.850915  [64064/90240]\n",
      "loss: 3.849262  [70464/90240]\n",
      "loss: 3.846568  [76864/90240]\n",
      "loss: 3.848138  [83264/90240]\n",
      "loss: 3.855404  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850594 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.851386  [   64/90240]\n",
      "loss: 3.846781  [ 6464/90240]\n",
      "loss: 3.851223  [12864/90240]\n",
      "loss: 3.846080  [19264/90240]\n",
      "loss: 3.851820  [25664/90240]\n",
      "loss: 3.850286  [32064/90240]\n",
      "loss: 3.852611  [38464/90240]\n",
      "loss: 3.853935  [44864/90240]\n",
      "loss: 3.851616  [51264/90240]\n",
      "loss: 3.851006  [57664/90240]\n",
      "loss: 3.849352  [64064/90240]\n",
      "loss: 3.849838  [70464/90240]\n",
      "loss: 3.850016  [76864/90240]\n",
      "loss: 3.846958  [83264/90240]\n",
      "loss: 3.850889  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850770 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.853460  [   64/90240]\n",
      "loss: 3.847620  [ 6464/90240]\n",
      "loss: 3.848970  [12864/90240]\n",
      "loss: 3.848763  [19264/90240]\n",
      "loss: 3.850396  [25664/90240]\n",
      "loss: 3.852436  [32064/90240]\n",
      "loss: 3.847916  [38464/90240]\n",
      "loss: 3.850405  [44864/90240]\n",
      "loss: 3.851997  [51264/90240]\n",
      "loss: 3.846308  [57664/90240]\n",
      "loss: 3.852482  [64064/90240]\n",
      "loss: 3.849708  [70464/90240]\n",
      "loss: 3.850829  [76864/90240]\n",
      "loss: 3.848496  [83264/90240]\n",
      "loss: 3.848574  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850897 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.851347  [   64/90240]\n",
      "loss: 3.849757  [ 6464/90240]\n",
      "loss: 3.860651  [12864/90240]\n",
      "loss: 3.852417  [19264/90240]\n",
      "loss: 3.842597  [25664/90240]\n",
      "loss: 3.850771  [32064/90240]\n",
      "loss: 3.851416  [38464/90240]\n",
      "loss: 3.851012  [44864/90240]\n",
      "loss: 3.848812  [51264/90240]\n",
      "loss: 3.848959  [57664/90240]\n",
      "loss: 3.849093  [64064/90240]\n",
      "loss: 3.850209  [70464/90240]\n",
      "loss: 3.848293  [76864/90240]\n",
      "loss: 3.848600  [83264/90240]\n",
      "loss: 3.850724  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850681 \n",
      "\n",
      "Done!\n",
      "model : m7\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10816, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.946796  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.076419  [ 6464/90240]\n",
      "loss: 0.925217  [12864/90240]\n",
      "loss: 1.025097  [19264/90240]\n",
      "loss: 0.967971  [25664/90240]\n",
      "loss: 0.642687  [32064/90240]\n",
      "loss: 0.700450  [38464/90240]\n",
      "loss: 0.519221  [44864/90240]\n",
      "loss: 0.692315  [51264/90240]\n",
      "loss: 0.737388  [57664/90240]\n",
      "loss: 0.596840  [64064/90240]\n",
      "loss: 0.593770  [70464/90240]\n",
      "loss: 0.666576  [76864/90240]\n",
      "loss: 0.531549  [83264/90240]\n",
      "loss: 0.500752  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.579178 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.372269  [   64/90240]\n",
      "loss: 0.601673  [ 6464/90240]\n",
      "loss: 0.324966  [12864/90240]\n",
      "loss: 0.799826  [19264/90240]\n",
      "loss: 0.780851  [25664/90240]\n",
      "loss: 0.435196  [32064/90240]\n",
      "loss: 0.665488  [38464/90240]\n",
      "loss: 0.306866  [44864/90240]\n",
      "loss: 0.243033  [51264/90240]\n",
      "loss: 0.696129  [57664/90240]\n",
      "loss: 0.533265  [64064/90240]\n",
      "loss: 0.592216  [70464/90240]\n",
      "loss: 0.343222  [76864/90240]\n",
      "loss: 0.675665  [83264/90240]\n",
      "loss: 0.340938  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.541036 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.297107  [   64/90240]\n",
      "loss: 0.389924  [ 6464/90240]\n",
      "loss: 0.412832  [12864/90240]\n",
      "loss: 0.565757  [19264/90240]\n",
      "loss: 0.296822  [25664/90240]\n",
      "loss: 0.295438  [32064/90240]\n",
      "loss: 0.493533  [38464/90240]\n",
      "loss: 0.703256  [44864/90240]\n",
      "loss: 0.596146  [51264/90240]\n",
      "loss: 0.579936  [57664/90240]\n",
      "loss: 0.466440  [64064/90240]\n",
      "loss: 0.573632  [70464/90240]\n",
      "loss: 0.503980  [76864/90240]\n",
      "loss: 0.417090  [83264/90240]\n",
      "loss: 0.230463  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.481301 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.432269  [   64/90240]\n",
      "loss: 0.476495  [ 6464/90240]\n",
      "loss: 0.453910  [12864/90240]\n",
      "loss: 0.452392  [19264/90240]\n",
      "loss: 0.417769  [25664/90240]\n",
      "loss: 0.380973  [32064/90240]\n",
      "loss: 0.640756  [38464/90240]\n",
      "loss: 0.563435  [44864/90240]\n",
      "loss: 0.318567  [51264/90240]\n",
      "loss: 0.394587  [57664/90240]\n",
      "loss: 0.423034  [64064/90240]\n",
      "loss: 0.453993  [70464/90240]\n",
      "loss: 0.439013  [76864/90240]\n",
      "loss: 0.245376  [83264/90240]\n",
      "loss: 0.296732  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.473430 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.326554  [   64/90240]\n",
      "loss: 0.522148  [ 6464/90240]\n",
      "loss: 0.519391  [12864/90240]\n",
      "loss: 0.468868  [19264/90240]\n",
      "loss: 0.472196  [25664/90240]\n",
      "loss: 0.400627  [32064/90240]\n",
      "loss: 0.497809  [38464/90240]\n",
      "loss: 0.362774  [44864/90240]\n",
      "loss: 0.378737  [51264/90240]\n",
      "loss: 0.315480  [57664/90240]\n",
      "loss: 0.316788  [64064/90240]\n",
      "loss: 0.260410  [70464/90240]\n",
      "loss: 0.495010  [76864/90240]\n",
      "loss: 0.395590  [83264/90240]\n",
      "loss: 0.513465  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.475475 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.446983  [   64/90240]\n",
      "loss: 0.271985  [ 6464/90240]\n",
      "loss: 0.184878  [12864/90240]\n",
      "loss: 0.230524  [19264/90240]\n",
      "loss: 0.356137  [25664/90240]\n",
      "loss: 0.296009  [32064/90240]\n",
      "loss: 0.512438  [38464/90240]\n",
      "loss: 0.442030  [44864/90240]\n",
      "loss: 0.633171  [51264/90240]\n",
      "loss: 0.357642  [57664/90240]\n",
      "loss: 0.339796  [64064/90240]\n",
      "loss: 0.342981  [70464/90240]\n",
      "loss: 0.414619  [76864/90240]\n",
      "loss: 0.571816  [83264/90240]\n",
      "loss: 0.325863  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.473462 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.294903  [   64/90240]\n",
      "loss: 0.227254  [ 6464/90240]\n",
      "loss: 0.312622  [12864/90240]\n",
      "loss: 0.519679  [19264/90240]\n",
      "loss: 0.467095  [25664/90240]\n",
      "loss: 0.464876  [32064/90240]\n",
      "loss: 0.361643  [38464/90240]\n",
      "loss: 0.180033  [44864/90240]\n",
      "loss: 0.331016  [51264/90240]\n",
      "loss: 0.371713  [57664/90240]\n",
      "loss: 0.271482  [64064/90240]\n",
      "loss: 0.243893  [70464/90240]\n",
      "loss: 0.229799  [76864/90240]\n",
      "loss: 0.277501  [83264/90240]\n",
      "loss: 0.306859  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.475509 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.357517  [   64/90240]\n",
      "loss: 0.370098  [ 6464/90240]\n",
      "loss: 0.382422  [12864/90240]\n",
      "loss: 0.361894  [19264/90240]\n",
      "loss: 0.194050  [25664/90240]\n",
      "loss: 0.236987  [32064/90240]\n",
      "loss: 0.228882  [38464/90240]\n",
      "loss: 0.294108  [44864/90240]\n",
      "loss: 0.422286  [51264/90240]\n",
      "loss: 0.349961  [57664/90240]\n",
      "loss: 0.346776  [64064/90240]\n",
      "loss: 0.346261  [70464/90240]\n",
      "loss: 0.370366  [76864/90240]\n",
      "loss: 0.266292  [83264/90240]\n",
      "loss: 0.290302  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.465218 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.320183  [   64/90240]\n",
      "loss: 0.280797  [ 6464/90240]\n",
      "loss: 0.268540  [12864/90240]\n",
      "loss: 0.230908  [19264/90240]\n",
      "loss: 0.377235  [25664/90240]\n",
      "loss: 0.209199  [32064/90240]\n",
      "loss: 0.328820  [38464/90240]\n",
      "loss: 0.431424  [44864/90240]\n",
      "loss: 0.327350  [51264/90240]\n",
      "loss: 0.327534  [57664/90240]\n",
      "loss: 0.268091  [64064/90240]\n",
      "loss: 0.298004  [70464/90240]\n",
      "loss: 0.437993  [76864/90240]\n",
      "loss: 0.274222  [83264/90240]\n",
      "loss: 0.231906  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.459510 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.395483  [   64/90240]\n",
      "loss: 0.385143  [ 6464/90240]\n",
      "loss: 0.736065  [12864/90240]\n",
      "loss: 0.174159  [19264/90240]\n",
      "loss: 0.206288  [25664/90240]\n",
      "loss: 0.326018  [32064/90240]\n",
      "loss: 0.322846  [38464/90240]\n",
      "loss: 0.284611  [44864/90240]\n",
      "loss: 0.321002  [51264/90240]\n",
      "loss: 0.282600  [57664/90240]\n",
      "loss: 0.187547  [64064/90240]\n",
      "loss: 0.300719  [70464/90240]\n",
      "loss: 0.142829  [76864/90240]\n",
      "loss: 0.318698  [83264/90240]\n",
      "loss: 0.391420  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.447819 \n",
      "\n",
      "Done!\n",
      "model : m7\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.850722  [   64/90240]\n",
      "loss: 2.399202  [ 6464/90240]\n",
      "loss: 1.655974  [12864/90240]\n",
      "loss: 1.308516  [19264/90240]\n",
      "loss: 0.897792  [25664/90240]\n",
      "loss: 0.733249  [32064/90240]\n",
      "loss: 0.744460  [38464/90240]\n",
      "loss: 0.716197  [44864/90240]\n",
      "loss: 0.510129  [51264/90240]\n",
      "loss: 0.797823  [57664/90240]\n",
      "loss: 0.866112  [64064/90240]\n",
      "loss: 0.716085  [70464/90240]\n",
      "loss: 0.591625  [76864/90240]\n",
      "loss: 0.439065  [83264/90240]\n",
      "loss: 0.766772  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.618359 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.864604  [   64/90240]\n",
      "loss: 0.816488  [ 6464/90240]\n",
      "loss: 0.519182  [12864/90240]\n",
      "loss: 0.663764  [19264/90240]\n",
      "loss: 0.477763  [25664/90240]\n",
      "loss: 0.469999  [32064/90240]\n",
      "loss: 0.570957  [38464/90240]\n",
      "loss: 0.388731  [44864/90240]\n",
      "loss: 0.494879  [51264/90240]\n",
      "loss: 0.591565  [57664/90240]\n",
      "loss: 0.814756  [64064/90240]\n",
      "loss: 0.519322  [70464/90240]\n",
      "loss: 0.418964  [76864/90240]\n",
      "loss: 0.579854  [83264/90240]\n",
      "loss: 0.555977  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.510728 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.400516  [   64/90240]\n",
      "loss: 0.476797  [ 6464/90240]\n",
      "loss: 0.677912  [12864/90240]\n",
      "loss: 0.424143  [19264/90240]\n",
      "loss: 0.406542  [25664/90240]\n",
      "loss: 0.413077  [32064/90240]\n",
      "loss: 0.440854  [38464/90240]\n",
      "loss: 0.502310  [44864/90240]\n",
      "loss: 0.361137  [51264/90240]\n",
      "loss: 0.417705  [57664/90240]\n",
      "loss: 0.430474  [64064/90240]\n",
      "loss: 0.443220  [70464/90240]\n",
      "loss: 0.340850  [76864/90240]\n",
      "loss: 0.755490  [83264/90240]\n",
      "loss: 0.317717  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.464148 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.454734  [   64/90240]\n",
      "loss: 0.686185  [ 6464/90240]\n",
      "loss: 0.276551  [12864/90240]\n",
      "loss: 0.308581  [19264/90240]\n",
      "loss: 0.322581  [25664/90240]\n",
      "loss: 0.528625  [32064/90240]\n",
      "loss: 0.289532  [38464/90240]\n",
      "loss: 0.232326  [44864/90240]\n",
      "loss: 0.452202  [51264/90240]\n",
      "loss: 0.284134  [57664/90240]\n",
      "loss: 0.528369  [64064/90240]\n",
      "loss: 0.316995  [70464/90240]\n",
      "loss: 0.331022  [76864/90240]\n",
      "loss: 0.531443  [83264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.252865  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.433748 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.215335  [   64/90240]\n",
      "loss: 0.483576  [ 6464/90240]\n",
      "loss: 0.486809  [12864/90240]\n",
      "loss: 0.407534  [19264/90240]\n",
      "loss: 0.411818  [25664/90240]\n",
      "loss: 0.259723  [32064/90240]\n",
      "loss: 0.494895  [38464/90240]\n",
      "loss: 0.247855  [44864/90240]\n",
      "loss: 0.349115  [51264/90240]\n",
      "loss: 0.268830  [57664/90240]\n",
      "loss: 0.410273  [64064/90240]\n",
      "loss: 0.384107  [70464/90240]\n",
      "loss: 0.400944  [76864/90240]\n",
      "loss: 0.307058  [83264/90240]\n",
      "loss: 0.543589  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.429330 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.477001  [   64/90240]\n",
      "loss: 0.361591  [ 6464/90240]\n",
      "loss: 0.429554  [12864/90240]\n",
      "loss: 0.227074  [19264/90240]\n",
      "loss: 0.484094  [25664/90240]\n",
      "loss: 0.517438  [32064/90240]\n",
      "loss: 0.436942  [38464/90240]\n",
      "loss: 0.360891  [44864/90240]\n",
      "loss: 0.409370  [51264/90240]\n",
      "loss: 0.173300  [57664/90240]\n",
      "loss: 0.318594  [64064/90240]\n",
      "loss: 0.409661  [70464/90240]\n",
      "loss: 0.320141  [76864/90240]\n",
      "loss: 0.194850  [83264/90240]\n",
      "loss: 0.401152  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.411323 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.202511  [   64/90240]\n",
      "loss: 0.267733  [ 6464/90240]\n",
      "loss: 0.423320  [12864/90240]\n",
      "loss: 0.286385  [19264/90240]\n",
      "loss: 0.410193  [25664/90240]\n",
      "loss: 0.521895  [32064/90240]\n",
      "loss: 0.330662  [38464/90240]\n",
      "loss: 0.255364  [44864/90240]\n",
      "loss: 0.320224  [51264/90240]\n",
      "loss: 0.276768  [57664/90240]\n",
      "loss: 0.283857  [64064/90240]\n",
      "loss: 0.250721  [70464/90240]\n",
      "loss: 0.401915  [76864/90240]\n",
      "loss: 0.400714  [83264/90240]\n",
      "loss: 0.294945  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.401884 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.226206  [   64/90240]\n",
      "loss: 0.260117  [ 6464/90240]\n",
      "loss: 0.243543  [12864/90240]\n",
      "loss: 0.419710  [19264/90240]\n",
      "loss: 0.286875  [25664/90240]\n",
      "loss: 0.320596  [32064/90240]\n",
      "loss: 0.370715  [38464/90240]\n",
      "loss: 0.283198  [44864/90240]\n",
      "loss: 0.236656  [51264/90240]\n",
      "loss: 0.325111  [57664/90240]\n",
      "loss: 0.280312  [64064/90240]\n",
      "loss: 0.140514  [70464/90240]\n",
      "loss: 0.359603  [76864/90240]\n",
      "loss: 0.440569  [83264/90240]\n",
      "loss: 0.313332  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.392299 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.194412  [   64/90240]\n",
      "loss: 0.287294  [ 6464/90240]\n",
      "loss: 0.235252  [12864/90240]\n",
      "loss: 0.250934  [19264/90240]\n",
      "loss: 0.442581  [25664/90240]\n",
      "loss: 0.342183  [32064/90240]\n",
      "loss: 0.215111  [38464/90240]\n",
      "loss: 0.409770  [44864/90240]\n",
      "loss: 0.412236  [51264/90240]\n",
      "loss: 0.303913  [57664/90240]\n",
      "loss: 0.166993  [64064/90240]\n",
      "loss: 0.200030  [70464/90240]\n",
      "loss: 0.171783  [76864/90240]\n",
      "loss: 0.278106  [83264/90240]\n",
      "loss: 0.328244  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.391329 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.172450  [   64/90240]\n",
      "loss: 0.190005  [ 6464/90240]\n",
      "loss: 0.239530  [12864/90240]\n",
      "loss: 0.477624  [19264/90240]\n",
      "loss: 0.214220  [25664/90240]\n",
      "loss: 0.163837  [32064/90240]\n",
      "loss: 0.397108  [38464/90240]\n",
      "loss: 0.260315  [44864/90240]\n",
      "loss: 0.346360  [51264/90240]\n",
      "loss: 0.387784  [57664/90240]\n",
      "loss: 0.332022  [64064/90240]\n",
      "loss: 0.270573  [70464/90240]\n",
      "loss: 0.373560  [76864/90240]\n",
      "loss: 0.177575  [83264/90240]\n",
      "loss: 0.265481  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.395310 \n",
      "\n",
      "Done!\n",
      "model : m7\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.874846  [   64/90240]\n",
      "loss: 3.499776  [ 6464/90240]\n",
      "loss: 2.925614  [12864/90240]\n",
      "loss: 1.800029  [19264/90240]\n",
      "loss: 1.441957  [25664/90240]\n",
      "loss: 1.069330  [32064/90240]\n",
      "loss: 1.089207  [38464/90240]\n",
      "loss: 0.814466  [44864/90240]\n",
      "loss: 0.797455  [51264/90240]\n",
      "loss: 0.701865  [57664/90240]\n",
      "loss: 1.085135  [64064/90240]\n",
      "loss: 0.788737  [70464/90240]\n",
      "loss: 0.891413  [76864/90240]\n",
      "loss: 0.564679  [83264/90240]\n",
      "loss: 0.729202  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.669926 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.613152  [   64/90240]\n",
      "loss: 0.399849  [ 6464/90240]\n",
      "loss: 0.611005  [12864/90240]\n",
      "loss: 0.620675  [19264/90240]\n",
      "loss: 0.496458  [25664/90240]\n",
      "loss: 0.488086  [32064/90240]\n",
      "loss: 0.635696  [38464/90240]\n",
      "loss: 0.430148  [44864/90240]\n",
      "loss: 0.401492  [51264/90240]\n",
      "loss: 0.664589  [57664/90240]\n",
      "loss: 0.638417  [64064/90240]\n",
      "loss: 0.535578  [70464/90240]\n",
      "loss: 0.487935  [76864/90240]\n",
      "loss: 0.583328  [83264/90240]\n",
      "loss: 0.519888  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.530821 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.571286  [   64/90240]\n",
      "loss: 0.577712  [ 6464/90240]\n",
      "loss: 0.292001  [12864/90240]\n",
      "loss: 0.582160  [19264/90240]\n",
      "loss: 0.457630  [25664/90240]\n",
      "loss: 0.554824  [32064/90240]\n",
      "loss: 0.302439  [38464/90240]\n",
      "loss: 0.380265  [44864/90240]\n",
      "loss: 0.580010  [51264/90240]\n",
      "loss: 0.595651  [57664/90240]\n",
      "loss: 0.536884  [64064/90240]\n",
      "loss: 0.497890  [70464/90240]\n",
      "loss: 0.379110  [76864/90240]\n",
      "loss: 0.631343  [83264/90240]\n",
      "loss: 0.620664  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.489813 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.560510  [   64/90240]\n",
      "loss: 0.390598  [ 6464/90240]\n",
      "loss: 0.490156  [12864/90240]\n",
      "loss: 0.387009  [19264/90240]\n",
      "loss: 0.295735  [25664/90240]\n",
      "loss: 0.374410  [32064/90240]\n",
      "loss: 0.375746  [38464/90240]\n",
      "loss: 0.381857  [44864/90240]\n",
      "loss: 0.272277  [51264/90240]\n",
      "loss: 0.316452  [57664/90240]\n",
      "loss: 0.628934  [64064/90240]\n",
      "loss: 0.424692  [70464/90240]\n",
      "loss: 0.424683  [76864/90240]\n",
      "loss: 0.394043  [83264/90240]\n",
      "loss: 0.262127  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.455596 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.272281  [   64/90240]\n",
      "loss: 0.360700  [ 6464/90240]\n",
      "loss: 0.368816  [12864/90240]\n",
      "loss: 0.394258  [19264/90240]\n",
      "loss: 0.455936  [25664/90240]\n",
      "loss: 0.520979  [32064/90240]\n",
      "loss: 0.422352  [38464/90240]\n",
      "loss: 0.459217  [44864/90240]\n",
      "loss: 0.565032  [51264/90240]\n",
      "loss: 0.380686  [57664/90240]\n",
      "loss: 0.297242  [64064/90240]\n",
      "loss: 0.334734  [70464/90240]\n",
      "loss: 0.396871  [76864/90240]\n",
      "loss: 0.495613  [83264/90240]\n",
      "loss: 0.392889  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.425893 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.391431  [   64/90240]\n",
      "loss: 0.419963  [ 6464/90240]\n",
      "loss: 0.486522  [12864/90240]\n",
      "loss: 0.410046  [19264/90240]\n",
      "loss: 0.318925  [25664/90240]\n",
      "loss: 0.234106  [32064/90240]\n",
      "loss: 0.396441  [38464/90240]\n",
      "loss: 0.216768  [44864/90240]\n",
      "loss: 0.406905  [51264/90240]\n",
      "loss: 0.355433  [57664/90240]\n",
      "loss: 0.385827  [64064/90240]\n",
      "loss: 0.415563  [70464/90240]\n",
      "loss: 0.461174  [76864/90240]\n",
      "loss: 0.344959  [83264/90240]\n",
      "loss: 0.442260  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.419378 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.715862  [   64/90240]\n",
      "loss: 0.777729  [ 6464/90240]\n",
      "loss: 0.548238  [12864/90240]\n",
      "loss: 0.350177  [19264/90240]\n",
      "loss: 0.614200  [25664/90240]\n",
      "loss: 0.285466  [32064/90240]\n",
      "loss: 0.306031  [38464/90240]\n",
      "loss: 0.359686  [44864/90240]\n",
      "loss: 0.273444  [51264/90240]\n",
      "loss: 0.423348  [57664/90240]\n",
      "loss: 0.510033  [64064/90240]\n",
      "loss: 0.327697  [70464/90240]\n",
      "loss: 0.277247  [76864/90240]\n",
      "loss: 0.231597  [83264/90240]\n",
      "loss: 0.405435  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.408843 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.411453  [   64/90240]\n",
      "loss: 0.211982  [ 6464/90240]\n",
      "loss: 0.247002  [12864/90240]\n",
      "loss: 0.370864  [19264/90240]\n",
      "loss: 0.373800  [25664/90240]\n",
      "loss: 0.426169  [32064/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.366055  [38464/90240]\n",
      "loss: 0.325374  [44864/90240]\n",
      "loss: 0.278467  [51264/90240]\n",
      "loss: 0.240102  [57664/90240]\n",
      "loss: 0.241618  [64064/90240]\n",
      "loss: 0.495402  [70464/90240]\n",
      "loss: 0.492338  [76864/90240]\n",
      "loss: 0.372744  [83264/90240]\n",
      "loss: 0.404125  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.402234 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.265499  [   64/90240]\n",
      "loss: 0.259119  [ 6464/90240]\n",
      "loss: 0.411287  [12864/90240]\n",
      "loss: 0.271404  [19264/90240]\n",
      "loss: 0.302689  [25664/90240]\n",
      "loss: 0.190772  [32064/90240]\n",
      "loss: 0.296118  [38464/90240]\n",
      "loss: 0.415965  [44864/90240]\n",
      "loss: 0.394475  [51264/90240]\n",
      "loss: 0.543868  [57664/90240]\n",
      "loss: 0.485913  [64064/90240]\n",
      "loss: 0.505076  [70464/90240]\n",
      "loss: 0.421066  [76864/90240]\n",
      "loss: 0.390142  [83264/90240]\n",
      "loss: 0.176335  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.391341 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.404166  [   64/90240]\n",
      "loss: 0.272821  [ 6464/90240]\n",
      "loss: 0.154550  [12864/90240]\n",
      "loss: 0.283022  [19264/90240]\n",
      "loss: 0.230515  [25664/90240]\n",
      "loss: 0.348210  [32064/90240]\n",
      "loss: 0.336797  [38464/90240]\n",
      "loss: 0.278105  [44864/90240]\n",
      "loss: 0.449682  [51264/90240]\n",
      "loss: 0.251969  [57664/90240]\n",
      "loss: 0.263202  [64064/90240]\n",
      "loss: 0.294556  [70464/90240]\n",
      "loss: 0.383912  [76864/90240]\n",
      "loss: 0.313211  [83264/90240]\n",
      "loss: 0.250663  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.395147 \n",
      "\n",
      "Done!\n",
      "model : m8\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Sigmoid()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10816, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.905049  [   64/90240]\n",
      "loss: 3.458343  [ 6464/90240]\n",
      "loss: 2.881921  [12864/90240]\n",
      "loss: 2.516783  [19264/90240]\n",
      "loss: 2.270905  [25664/90240]\n",
      "loss: 2.018565  [32064/90240]\n",
      "loss: 1.774015  [38464/90240]\n",
      "loss: 1.936421  [44864/90240]\n",
      "loss: 1.655822  [51264/90240]\n",
      "loss: 1.536329  [57664/90240]\n",
      "loss: 1.579926  [64064/90240]\n",
      "loss: 1.171173  [70464/90240]\n",
      "loss: 1.326782  [76864/90240]\n",
      "loss: 1.185941  [83264/90240]\n",
      "loss: 1.420827  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.391763 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.362744  [   64/90240]\n",
      "loss: 1.524706  [ 6464/90240]\n",
      "loss: 1.077844  [12864/90240]\n",
      "loss: 1.214861  [19264/90240]\n",
      "loss: 1.252340  [25664/90240]\n",
      "loss: 1.169641  [32064/90240]\n",
      "loss: 1.215978  [38464/90240]\n",
      "loss: 1.320248  [44864/90240]\n",
      "loss: 1.290757  [51264/90240]\n",
      "loss: 1.276452  [57664/90240]\n",
      "loss: 1.384249  [64064/90240]\n",
      "loss: 1.095198  [70464/90240]\n",
      "loss: 1.194954  [76864/90240]\n",
      "loss: 1.207840  [83264/90240]\n",
      "loss: 1.528042  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 1.187995 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.059463  [   64/90240]\n",
      "loss: 1.396182  [ 6464/90240]\n",
      "loss: 1.010183  [12864/90240]\n",
      "loss: 1.117045  [19264/90240]\n",
      "loss: 0.946184  [25664/90240]\n",
      "loss: 0.990153  [32064/90240]\n",
      "loss: 1.094709  [38464/90240]\n",
      "loss: 1.405258  [44864/90240]\n",
      "loss: 1.332313  [51264/90240]\n",
      "loss: 0.790175  [57664/90240]\n",
      "loss: 1.053956  [64064/90240]\n",
      "loss: 1.126103  [70464/90240]\n",
      "loss: 1.045744  [76864/90240]\n",
      "loss: 0.904331  [83264/90240]\n",
      "loss: 1.231922  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.042616 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.949750  [   64/90240]\n",
      "loss: 1.014562  [ 6464/90240]\n",
      "loss: 0.968813  [12864/90240]\n",
      "loss: 1.272677  [19264/90240]\n",
      "loss: 1.105941  [25664/90240]\n",
      "loss: 1.173074  [32064/90240]\n",
      "loss: 0.620165  [38464/90240]\n",
      "loss: 0.864263  [44864/90240]\n",
      "loss: 0.991166  [51264/90240]\n",
      "loss: 1.031038  [57664/90240]\n",
      "loss: 0.937069  [64064/90240]\n",
      "loss: 0.846886  [70464/90240]\n",
      "loss: 1.024432  [76864/90240]\n",
      "loss: 1.029925  [83264/90240]\n",
      "loss: 1.067055  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.960520 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.899233  [   64/90240]\n",
      "loss: 0.937679  [ 6464/90240]\n",
      "loss: 0.865355  [12864/90240]\n",
      "loss: 0.803825  [19264/90240]\n",
      "loss: 0.919609  [25664/90240]\n",
      "loss: 1.015656  [32064/90240]\n",
      "loss: 1.150833  [38464/90240]\n",
      "loss: 1.104683  [44864/90240]\n",
      "loss: 0.769980  [51264/90240]\n",
      "loss: 0.999007  [57664/90240]\n",
      "loss: 1.271248  [64064/90240]\n",
      "loss: 0.955643  [70464/90240]\n",
      "loss: 0.934510  [76864/90240]\n",
      "loss: 1.265746  [83264/90240]\n",
      "loss: 1.033310  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.870249 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.867310  [   64/90240]\n",
      "loss: 0.974027  [ 6464/90240]\n",
      "loss: 0.955707  [12864/90240]\n",
      "loss: 0.784887  [19264/90240]\n",
      "loss: 0.978800  [25664/90240]\n",
      "loss: 0.712067  [32064/90240]\n",
      "loss: 0.922479  [38464/90240]\n",
      "loss: 0.784126  [44864/90240]\n",
      "loss: 0.881251  [51264/90240]\n",
      "loss: 0.599516  [57664/90240]\n",
      "loss: 0.685101  [64064/90240]\n",
      "loss: 0.796993  [70464/90240]\n",
      "loss: 0.807583  [76864/90240]\n",
      "loss: 0.739775  [83264/90240]\n",
      "loss: 0.714409  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.798361 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.660494  [   64/90240]\n",
      "loss: 0.618608  [ 6464/90240]\n",
      "loss: 0.587660  [12864/90240]\n",
      "loss: 0.796732  [19264/90240]\n",
      "loss: 0.798070  [25664/90240]\n",
      "loss: 0.819746  [32064/90240]\n",
      "loss: 0.688392  [38464/90240]\n",
      "loss: 0.713410  [44864/90240]\n",
      "loss: 0.631541  [51264/90240]\n",
      "loss: 0.542189  [57664/90240]\n",
      "loss: 0.747164  [64064/90240]\n",
      "loss: 0.801875  [70464/90240]\n",
      "loss: 0.935402  [76864/90240]\n",
      "loss: 0.508308  [83264/90240]\n",
      "loss: 0.804848  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.740331 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.654650  [   64/90240]\n",
      "loss: 1.073154  [ 6464/90240]\n",
      "loss: 0.684609  [12864/90240]\n",
      "loss: 0.742697  [19264/90240]\n",
      "loss: 0.765495  [25664/90240]\n",
      "loss: 0.643564  [32064/90240]\n",
      "loss: 0.569599  [38464/90240]\n",
      "loss: 0.630715  [44864/90240]\n",
      "loss: 0.462070  [51264/90240]\n",
      "loss: 0.771854  [57664/90240]\n",
      "loss: 0.802068  [64064/90240]\n",
      "loss: 0.463990  [70464/90240]\n",
      "loss: 0.839909  [76864/90240]\n",
      "loss: 0.809609  [83264/90240]\n",
      "loss: 0.770270  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.699706 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.549323  [   64/90240]\n",
      "loss: 0.549601  [ 6464/90240]\n",
      "loss: 0.659205  [12864/90240]\n",
      "loss: 0.598691  [19264/90240]\n",
      "loss: 0.571944  [25664/90240]\n",
      "loss: 0.966865  [32064/90240]\n",
      "loss: 0.639386  [38464/90240]\n",
      "loss: 0.523250  [44864/90240]\n",
      "loss: 0.548421  [51264/90240]\n",
      "loss: 0.845707  [57664/90240]\n",
      "loss: 0.526271  [64064/90240]\n",
      "loss: 0.641807  [70464/90240]\n",
      "loss: 0.444985  [76864/90240]\n",
      "loss: 0.619838  [83264/90240]\n",
      "loss: 0.593289  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.645690 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.739558  [   64/90240]\n",
      "loss: 0.516827  [ 6464/90240]\n",
      "loss: 0.855854  [12864/90240]\n",
      "loss: 0.432606  [19264/90240]\n",
      "loss: 0.601690  [25664/90240]\n",
      "loss: 0.565551  [32064/90240]\n",
      "loss: 0.560946  [38464/90240]\n",
      "loss: 0.476232  [44864/90240]\n",
      "loss: 0.650768  [51264/90240]\n",
      "loss: 0.529386  [57664/90240]\n",
      "loss: 0.583571  [64064/90240]\n",
      "loss: 0.522361  [70464/90240]\n",
      "loss: 0.820923  [76864/90240]\n",
      "loss: 0.588871  [83264/90240]\n",
      "loss: 0.488504  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.605787 \n",
      "\n",
      "Done!\n",
      "model : m8\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Sigmoid()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.879428  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.753147  [ 6464/90240]\n",
      "loss: 3.701320  [12864/90240]\n",
      "loss: 3.536268  [19264/90240]\n",
      "loss: 3.404464  [25664/90240]\n",
      "loss: 3.032700  [32064/90240]\n",
      "loss: 2.823988  [38464/90240]\n",
      "loss: 2.564305  [44864/90240]\n",
      "loss: 2.270902  [51264/90240]\n",
      "loss: 2.145626  [57664/90240]\n",
      "loss: 2.115438  [64064/90240]\n",
      "loss: 2.120268  [70464/90240]\n",
      "loss: 1.773910  [76864/90240]\n",
      "loss: 1.803555  [83264/90240]\n",
      "loss: 1.553514  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.604058 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.594769  [   64/90240]\n",
      "loss: 1.663653  [ 6464/90240]\n",
      "loss: 1.407871  [12864/90240]\n",
      "loss: 1.485833  [19264/90240]\n",
      "loss: 1.511230  [25664/90240]\n",
      "loss: 1.404455  [32064/90240]\n",
      "loss: 1.358869  [38464/90240]\n",
      "loss: 1.201632  [44864/90240]\n",
      "loss: 1.461573  [51264/90240]\n",
      "loss: 1.627840  [57664/90240]\n",
      "loss: 1.208587  [64064/90240]\n",
      "loss: 1.442101  [70464/90240]\n",
      "loss: 1.354224  [76864/90240]\n",
      "loss: 1.528882  [83264/90240]\n",
      "loss: 1.069368  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.265655 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.318425  [   64/90240]\n",
      "loss: 1.225168  [ 6464/90240]\n",
      "loss: 0.971346  [12864/90240]\n",
      "loss: 1.631324  [19264/90240]\n",
      "loss: 1.417060  [25664/90240]\n",
      "loss: 1.490464  [32064/90240]\n",
      "loss: 0.913029  [38464/90240]\n",
      "loss: 1.121106  [44864/90240]\n",
      "loss: 1.232401  [51264/90240]\n",
      "loss: 1.202726  [57664/90240]\n",
      "loss: 1.589413  [64064/90240]\n",
      "loss: 1.155552  [70464/90240]\n",
      "loss: 1.078778  [76864/90240]\n",
      "loss: 1.405069  [83264/90240]\n",
      "loss: 1.137559  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 1.125052 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.063826  [   64/90240]\n",
      "loss: 1.100166  [ 6464/90240]\n",
      "loss: 1.202775  [12864/90240]\n",
      "loss: 1.092128  [19264/90240]\n",
      "loss: 0.950967  [25664/90240]\n",
      "loss: 1.086656  [32064/90240]\n",
      "loss: 0.726692  [38464/90240]\n",
      "loss: 1.300825  [44864/90240]\n",
      "loss: 1.136619  [51264/90240]\n",
      "loss: 1.060827  [57664/90240]\n",
      "loss: 1.185635  [64064/90240]\n",
      "loss: 0.933579  [70464/90240]\n",
      "loss: 1.097435  [76864/90240]\n",
      "loss: 1.099258  [83264/90240]\n",
      "loss: 1.100543  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.014611 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.100350  [   64/90240]\n",
      "loss: 1.161038  [ 6464/90240]\n",
      "loss: 0.775269  [12864/90240]\n",
      "loss: 1.032381  [19264/90240]\n",
      "loss: 0.961673  [25664/90240]\n",
      "loss: 0.734925  [32064/90240]\n",
      "loss: 0.908025  [38464/90240]\n",
      "loss: 0.783351  [44864/90240]\n",
      "loss: 1.227086  [51264/90240]\n",
      "loss: 1.146551  [57664/90240]\n",
      "loss: 0.791011  [64064/90240]\n",
      "loss: 0.896938  [70464/90240]\n",
      "loss: 0.949696  [76864/90240]\n",
      "loss: 1.423290  [83264/90240]\n",
      "loss: 0.823763  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.913081 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.730749  [   64/90240]\n",
      "loss: 0.663802  [ 6464/90240]\n",
      "loss: 0.891893  [12864/90240]\n",
      "loss: 0.890851  [19264/90240]\n",
      "loss: 0.775138  [25664/90240]\n",
      "loss: 0.702160  [32064/90240]\n",
      "loss: 0.800624  [38464/90240]\n",
      "loss: 0.804540  [44864/90240]\n",
      "loss: 0.765871  [51264/90240]\n",
      "loss: 1.000634  [57664/90240]\n",
      "loss: 0.572814  [64064/90240]\n",
      "loss: 0.634061  [70464/90240]\n",
      "loss: 0.771002  [76864/90240]\n",
      "loss: 0.958177  [83264/90240]\n",
      "loss: 0.622482  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.797581 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.676791  [   64/90240]\n",
      "loss: 0.967692  [ 6464/90240]\n",
      "loss: 0.608007  [12864/90240]\n",
      "loss: 0.628419  [19264/90240]\n",
      "loss: 0.634576  [25664/90240]\n",
      "loss: 0.668572  [32064/90240]\n",
      "loss: 0.865131  [38464/90240]\n",
      "loss: 0.684029  [44864/90240]\n",
      "loss: 0.838329  [51264/90240]\n",
      "loss: 0.802456  [57664/90240]\n",
      "loss: 0.771356  [64064/90240]\n",
      "loss: 0.662518  [70464/90240]\n",
      "loss: 0.695693  [76864/90240]\n",
      "loss: 0.668188  [83264/90240]\n",
      "loss: 0.592744  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.706992 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.646563  [   64/90240]\n",
      "loss: 0.675504  [ 6464/90240]\n",
      "loss: 0.562390  [12864/90240]\n",
      "loss: 0.713901  [19264/90240]\n",
      "loss: 0.699689  [25664/90240]\n",
      "loss: 0.640679  [32064/90240]\n",
      "loss: 0.669856  [38464/90240]\n",
      "loss: 0.403424  [44864/90240]\n",
      "loss: 0.661058  [51264/90240]\n",
      "loss: 0.748984  [57664/90240]\n",
      "loss: 0.538587  [64064/90240]\n",
      "loss: 0.562576  [70464/90240]\n",
      "loss: 0.811583  [76864/90240]\n",
      "loss: 0.782160  [83264/90240]\n",
      "loss: 0.567236  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.640945 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.674204  [   64/90240]\n",
      "loss: 0.677044  [ 6464/90240]\n",
      "loss: 0.612311  [12864/90240]\n",
      "loss: 0.671451  [19264/90240]\n",
      "loss: 0.561501  [25664/90240]\n",
      "loss: 0.606506  [32064/90240]\n",
      "loss: 0.469263  [38464/90240]\n",
      "loss: 0.526736  [44864/90240]\n",
      "loss: 0.611775  [51264/90240]\n",
      "loss: 0.473742  [57664/90240]\n",
      "loss: 0.601742  [64064/90240]\n",
      "loss: 0.538699  [70464/90240]\n",
      "loss: 0.366993  [76864/90240]\n",
      "loss: 0.434076  [83264/90240]\n",
      "loss: 0.458131  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.597775 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.545333  [   64/90240]\n",
      "loss: 0.571309  [ 6464/90240]\n",
      "loss: 0.425611  [12864/90240]\n",
      "loss: 0.463603  [19264/90240]\n",
      "loss: 0.681949  [25664/90240]\n",
      "loss: 0.549100  [32064/90240]\n",
      "loss: 0.465570  [38464/90240]\n",
      "loss: 0.582371  [44864/90240]\n",
      "loss: 0.495733  [51264/90240]\n",
      "loss: 0.406229  [57664/90240]\n",
      "loss: 0.402069  [64064/90240]\n",
      "loss: 0.418664  [70464/90240]\n",
      "loss: 0.951231  [76864/90240]\n",
      "loss: 0.458822  [83264/90240]\n",
      "loss: 0.722171  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.580207 \n",
      "\n",
      "Done!\n",
      "model : m8\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Sigmoid()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.866528  [   64/90240]\n",
      "loss: 3.846932  [ 6464/90240]\n",
      "loss: 3.833086  [12864/90240]\n",
      "loss: 3.809213  [19264/90240]\n",
      "loss: 3.777298  [25664/90240]\n",
      "loss: 3.736439  [32064/90240]\n",
      "loss: 3.692646  [38464/90240]\n",
      "loss: 3.635150  [44864/90240]\n",
      "loss: 3.501137  [51264/90240]\n",
      "loss: 3.417489  [57664/90240]\n",
      "loss: 3.194777  [64064/90240]\n",
      "loss: 3.054476  [70464/90240]\n",
      "loss: 2.828393  [76864/90240]\n",
      "loss: 2.635937  [83264/90240]\n",
      "loss: 2.460844  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 2.428610 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.394876  [   64/90240]\n",
      "loss: 2.149727  [ 6464/90240]\n",
      "loss: 1.974484  [12864/90240]\n",
      "loss: 1.937667  [19264/90240]\n",
      "loss: 1.829664  [25664/90240]\n",
      "loss: 1.920533  [32064/90240]\n",
      "loss: 1.798160  [38464/90240]\n",
      "loss: 1.916281  [44864/90240]\n",
      "loss: 1.661248  [51264/90240]\n",
      "loss: 1.316727  [57664/90240]\n",
      "loss: 1.495528  [64064/90240]\n",
      "loss: 1.873524  [70464/90240]\n",
      "loss: 1.677168  [76864/90240]\n",
      "loss: 1.217972  [83264/90240]\n",
      "loss: 1.492407  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.392000 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.658641  [   64/90240]\n",
      "loss: 1.290350  [ 6464/90240]\n",
      "loss: 1.407125  [12864/90240]\n",
      "loss: 1.416563  [19264/90240]\n",
      "loss: 1.275716  [25664/90240]\n",
      "loss: 1.370066  [32064/90240]\n",
      "loss: 1.359966  [38464/90240]\n",
      "loss: 1.172044  [44864/90240]\n",
      "loss: 1.303440  [51264/90240]\n",
      "loss: 1.216972  [57664/90240]\n",
      "loss: 1.012256  [64064/90240]\n",
      "loss: 1.130644  [70464/90240]\n",
      "loss: 1.096028  [76864/90240]\n",
      "loss: 1.215557  [83264/90240]\n",
      "loss: 1.084821  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 1.120759 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.866581  [   64/90240]\n",
      "loss: 0.936712  [ 6464/90240]\n",
      "loss: 1.016857  [12864/90240]\n",
      "loss: 1.231737  [19264/90240]\n",
      "loss: 1.143350  [25664/90240]\n",
      "loss: 1.085322  [32064/90240]\n",
      "loss: 1.284622  [38464/90240]\n",
      "loss: 1.008467  [44864/90240]\n",
      "loss: 1.135971  [51264/90240]\n",
      "loss: 0.923146  [57664/90240]\n",
      "loss: 1.102813  [64064/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.782547  [70464/90240]\n",
      "loss: 0.828792  [76864/90240]\n",
      "loss: 1.025121  [83264/90240]\n",
      "loss: 1.247756  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.884416 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.713036  [   64/90240]\n",
      "loss: 0.663845  [ 6464/90240]\n",
      "loss: 0.844015  [12864/90240]\n",
      "loss: 0.897445  [19264/90240]\n",
      "loss: 1.006328  [25664/90240]\n",
      "loss: 0.692199  [32064/90240]\n",
      "loss: 0.803128  [38464/90240]\n",
      "loss: 0.773841  [44864/90240]\n",
      "loss: 0.721952  [51264/90240]\n",
      "loss: 0.823728  [57664/90240]\n",
      "loss: 1.052557  [64064/90240]\n",
      "loss: 0.885723  [70464/90240]\n",
      "loss: 0.563896  [76864/90240]\n",
      "loss: 0.999693  [83264/90240]\n",
      "loss: 0.632653  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.761168 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.042305  [   64/90240]\n",
      "loss: 0.708229  [ 6464/90240]\n",
      "loss: 0.806561  [12864/90240]\n",
      "loss: 0.812002  [19264/90240]\n",
      "loss: 0.767526  [25664/90240]\n",
      "loss: 0.599239  [32064/90240]\n",
      "loss: 0.674388  [38464/90240]\n",
      "loss: 0.601700  [44864/90240]\n",
      "loss: 0.773828  [51264/90240]\n",
      "loss: 0.621096  [57664/90240]\n",
      "loss: 0.626049  [64064/90240]\n",
      "loss: 0.511887  [70464/90240]\n",
      "loss: 0.997810  [76864/90240]\n",
      "loss: 0.440811  [83264/90240]\n",
      "loss: 0.790506  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.668317 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.791493  [   64/90240]\n",
      "loss: 0.585130  [ 6464/90240]\n",
      "loss: 0.518546  [12864/90240]\n",
      "loss: 0.352465  [19264/90240]\n",
      "loss: 0.600034  [25664/90240]\n",
      "loss: 0.623549  [32064/90240]\n",
      "loss: 0.490709  [38464/90240]\n",
      "loss: 0.485012  [44864/90240]\n",
      "loss: 0.445673  [51264/90240]\n",
      "loss: 0.650369  [57664/90240]\n",
      "loss: 0.465509  [64064/90240]\n",
      "loss: 0.572729  [70464/90240]\n",
      "loss: 0.823216  [76864/90240]\n",
      "loss: 0.576979  [83264/90240]\n",
      "loss: 0.487576  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.615482 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.654560  [   64/90240]\n",
      "loss: 0.463553  [ 6464/90240]\n",
      "loss: 0.462216  [12864/90240]\n",
      "loss: 0.487657  [19264/90240]\n",
      "loss: 0.628281  [25664/90240]\n",
      "loss: 0.583257  [32064/90240]\n",
      "loss: 0.613416  [38464/90240]\n",
      "loss: 0.673060  [44864/90240]\n",
      "loss: 0.567062  [51264/90240]\n",
      "loss: 0.371827  [57664/90240]\n",
      "loss: 0.757427  [64064/90240]\n",
      "loss: 0.599537  [70464/90240]\n",
      "loss: 0.305774  [76864/90240]\n",
      "loss: 0.451543  [83264/90240]\n",
      "loss: 0.525849  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.581488 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.453889  [   64/90240]\n",
      "loss: 0.441166  [ 6464/90240]\n",
      "loss: 0.510413  [12864/90240]\n",
      "loss: 0.571503  [19264/90240]\n",
      "loss: 0.578713  [25664/90240]\n",
      "loss: 0.761920  [32064/90240]\n",
      "loss: 0.780219  [38464/90240]\n",
      "loss: 0.421609  [44864/90240]\n",
      "loss: 0.541309  [51264/90240]\n",
      "loss: 0.582208  [57664/90240]\n",
      "loss: 0.459666  [64064/90240]\n",
      "loss: 0.494576  [70464/90240]\n",
      "loss: 0.398483  [76864/90240]\n",
      "loss: 0.515368  [83264/90240]\n",
      "loss: 0.584790  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.567785 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.576438  [   64/90240]\n",
      "loss: 0.754947  [ 6464/90240]\n",
      "loss: 0.542599  [12864/90240]\n",
      "loss: 0.737167  [19264/90240]\n",
      "loss: 0.627021  [25664/90240]\n",
      "loss: 0.239224  [32064/90240]\n",
      "loss: 0.523367  [38464/90240]\n",
      "loss: 0.552996  [44864/90240]\n",
      "loss: 0.590626  [51264/90240]\n",
      "loss: 0.538393  [57664/90240]\n",
      "loss: 0.452112  [64064/90240]\n",
      "loss: 0.615279  [70464/90240]\n",
      "loss: 0.282482  [76864/90240]\n",
      "loss: 0.769386  [83264/90240]\n",
      "loss: 0.258063  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.553666 \n",
      "\n",
      "Done!\n",
      "model : m9\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10816, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.852129  [   64/90240]\n",
      "loss: 3.755611  [ 6464/90240]\n",
      "loss: 2.866070  [12864/90240]\n",
      "loss: 1.525206  [19264/90240]\n",
      "loss: 1.319372  [25664/90240]\n",
      "loss: 1.492792  [32064/90240]\n",
      "loss: 1.166789  [38464/90240]\n",
      "loss: 1.769498  [44864/90240]\n",
      "loss: 1.353764  [51264/90240]\n",
      "loss: 1.295628  [57664/90240]\n",
      "loss: 1.123440  [64064/90240]\n",
      "loss: 1.544219  [70464/90240]\n",
      "loss: 1.375325  [76864/90240]\n",
      "loss: 1.159445  [83264/90240]\n",
      "loss: 1.554805  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.256965 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.123181  [   64/90240]\n",
      "loss: 1.086690  [ 6464/90240]\n",
      "loss: 1.489772  [12864/90240]\n",
      "loss: 1.001291  [19264/90240]\n",
      "loss: 1.339216  [25664/90240]\n",
      "loss: 1.339573  [32064/90240]\n",
      "loss: 1.458086  [38464/90240]\n",
      "loss: 1.398408  [44864/90240]\n",
      "loss: 1.217450  [51264/90240]\n",
      "loss: 0.998756  [57664/90240]\n",
      "loss: 1.383355  [64064/90240]\n",
      "loss: 1.681604  [70464/90240]\n",
      "loss: 1.075964  [76864/90240]\n",
      "loss: 0.981264  [83264/90240]\n",
      "loss: 1.173160  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.207455 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.397925  [   64/90240]\n",
      "loss: 1.185088  [ 6464/90240]\n",
      "loss: 0.875740  [12864/90240]\n",
      "loss: 0.988603  [19264/90240]\n",
      "loss: 1.558210  [25664/90240]\n",
      "loss: 1.436825  [32064/90240]\n",
      "loss: 1.099422  [38464/90240]\n",
      "loss: 1.284597  [44864/90240]\n",
      "loss: 0.827417  [51264/90240]\n",
      "loss: 1.551551  [57664/90240]\n",
      "loss: 0.940598  [64064/90240]\n",
      "loss: 1.252416  [70464/90240]\n",
      "loss: 1.284484  [76864/90240]\n",
      "loss: 1.174625  [83264/90240]\n",
      "loss: 1.146969  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.068613 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.257239  [   64/90240]\n",
      "loss: 0.952153  [ 6464/90240]\n",
      "loss: 1.245095  [12864/90240]\n",
      "loss: 0.774181  [19264/90240]\n",
      "loss: 0.960668  [25664/90240]\n",
      "loss: 1.125400  [32064/90240]\n",
      "loss: 0.717199  [38464/90240]\n",
      "loss: 0.923323  [44864/90240]\n",
      "loss: 1.170946  [51264/90240]\n",
      "loss: 1.051431  [57664/90240]\n",
      "loss: 0.705184  [64064/90240]\n",
      "loss: 0.764405  [70464/90240]\n",
      "loss: 0.747420  [76864/90240]\n",
      "loss: 0.705513  [83264/90240]\n",
      "loss: 0.925600  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.892482 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.890071  [   64/90240]\n",
      "loss: 1.032682  [ 6464/90240]\n",
      "loss: 0.898698  [12864/90240]\n",
      "loss: 0.887775  [19264/90240]\n",
      "loss: 0.499253  [25664/90240]\n",
      "loss: 0.638603  [32064/90240]\n",
      "loss: 0.635445  [38464/90240]\n",
      "loss: 0.868782  [44864/90240]\n",
      "loss: 0.704892  [51264/90240]\n",
      "loss: 0.852756  [57664/90240]\n",
      "loss: 1.057349  [64064/90240]\n",
      "loss: 0.637034  [70464/90240]\n",
      "loss: 0.759898  [76864/90240]\n",
      "loss: 0.622199  [83264/90240]\n",
      "loss: 0.701838  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.736591 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.716648  [   64/90240]\n",
      "loss: 0.642776  [ 6464/90240]\n",
      "loss: 0.588668  [12864/90240]\n",
      "loss: 0.827592  [19264/90240]\n",
      "loss: 0.647454  [25664/90240]\n",
      "loss: 0.480193  [32064/90240]\n",
      "loss: 0.928797  [38464/90240]\n",
      "loss: 0.559341  [44864/90240]\n",
      "loss: 0.778226  [51264/90240]\n",
      "loss: 0.805778  [57664/90240]\n",
      "loss: 0.540957  [64064/90240]\n",
      "loss: 0.802600  [70464/90240]\n",
      "loss: 0.718601  [76864/90240]\n",
      "loss: 0.323697  [83264/90240]\n",
      "loss: 0.329525  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.653601 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.513949  [   64/90240]\n",
      "loss: 0.657640  [ 6464/90240]\n",
      "loss: 0.458755  [12864/90240]\n",
      "loss: 0.455859  [19264/90240]\n",
      "loss: 0.654462  [25664/90240]\n",
      "loss: 0.581902  [32064/90240]\n",
      "loss: 0.417304  [38464/90240]\n",
      "loss: 0.456843  [44864/90240]\n",
      "loss: 0.831691  [51264/90240]\n",
      "loss: 0.616228  [57664/90240]\n",
      "loss: 0.675560  [64064/90240]\n",
      "loss: 0.856298  [70464/90240]\n",
      "loss: 0.615876  [76864/90240]\n",
      "loss: 0.615629  [83264/90240]\n",
      "loss: 0.548913  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.626031 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.516911  [   64/90240]\n",
      "loss: 0.598047  [ 6464/90240]\n",
      "loss: 0.544296  [12864/90240]\n",
      "loss: 0.606962  [19264/90240]\n",
      "loss: 0.417158  [25664/90240]\n",
      "loss: 0.507341  [32064/90240]\n",
      "loss: 0.674691  [38464/90240]\n",
      "loss: 0.341395  [44864/90240]\n",
      "loss: 0.529998  [51264/90240]\n",
      "loss: 0.510613  [57664/90240]\n",
      "loss: 0.569282  [64064/90240]\n",
      "loss: 0.569059  [70464/90240]\n",
      "loss: 0.335140  [76864/90240]\n",
      "loss: 0.410280  [83264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.411436  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.587258 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.426942  [   64/90240]\n",
      "loss: 0.467085  [ 6464/90240]\n",
      "loss: 0.311934  [12864/90240]\n",
      "loss: 0.546719  [19264/90240]\n",
      "loss: 0.570646  [25664/90240]\n",
      "loss: 0.465196  [32064/90240]\n",
      "loss: 0.384153  [38464/90240]\n",
      "loss: 0.460313  [44864/90240]\n",
      "loss: 0.631430  [51264/90240]\n",
      "loss: 0.560549  [57664/90240]\n",
      "loss: 0.554263  [64064/90240]\n",
      "loss: 0.405448  [70464/90240]\n",
      "loss: 0.820013  [76864/90240]\n",
      "loss: 0.462469  [83264/90240]\n",
      "loss: 0.777768  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.570585 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.560318  [   64/90240]\n",
      "loss: 0.586357  [ 6464/90240]\n",
      "loss: 0.507031  [12864/90240]\n",
      "loss: 0.544366  [19264/90240]\n",
      "loss: 0.483290  [25664/90240]\n",
      "loss: 0.532165  [32064/90240]\n",
      "loss: 0.730228  [38464/90240]\n",
      "loss: 0.357397  [44864/90240]\n",
      "loss: 0.584070  [51264/90240]\n",
      "loss: 0.518981  [57664/90240]\n",
      "loss: 0.497700  [64064/90240]\n",
      "loss: 0.358975  [70464/90240]\n",
      "loss: 0.414100  [76864/90240]\n",
      "loss: 0.435112  [83264/90240]\n",
      "loss: 0.599986  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.560464 \n",
      "\n",
      "Done!\n",
      "model : m9\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.868484  [   64/90240]\n",
      "loss: 3.835219  [ 6464/90240]\n",
      "loss: 3.807862  [12864/90240]\n",
      "loss: 3.715214  [19264/90240]\n",
      "loss: 3.446972  [25664/90240]\n",
      "loss: 2.395670  [32064/90240]\n",
      "loss: 2.002859  [38464/90240]\n",
      "loss: 1.469631  [44864/90240]\n",
      "loss: 1.613047  [51264/90240]\n",
      "loss: 1.227088  [57664/90240]\n",
      "loss: 1.228683  [64064/90240]\n",
      "loss: 1.077603  [70464/90240]\n",
      "loss: 1.264500  [76864/90240]\n",
      "loss: 1.268242  [83264/90240]\n",
      "loss: 1.251129  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.113989 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.302872  [   64/90240]\n",
      "loss: 1.281535  [ 6464/90240]\n",
      "loss: 1.035857  [12864/90240]\n",
      "loss: 0.751430  [19264/90240]\n",
      "loss: 1.005460  [25664/90240]\n",
      "loss: 0.856038  [32064/90240]\n",
      "loss: 0.810746  [38464/90240]\n",
      "loss: 0.801271  [44864/90240]\n",
      "loss: 0.798401  [51264/90240]\n",
      "loss: 0.750903  [57664/90240]\n",
      "loss: 0.898473  [64064/90240]\n",
      "loss: 1.150062  [70464/90240]\n",
      "loss: 0.997285  [76864/90240]\n",
      "loss: 0.697219  [83264/90240]\n",
      "loss: 0.733005  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.865415 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.674137  [   64/90240]\n",
      "loss: 0.965877  [ 6464/90240]\n",
      "loss: 0.668947  [12864/90240]\n",
      "loss: 0.560543  [19264/90240]\n",
      "loss: 1.328611  [25664/90240]\n",
      "loss: 0.503945  [32064/90240]\n",
      "loss: 0.711576  [38464/90240]\n",
      "loss: 0.650237  [44864/90240]\n",
      "loss: 0.898110  [51264/90240]\n",
      "loss: 0.972314  [57664/90240]\n",
      "loss: 0.748026  [64064/90240]\n",
      "loss: 0.669710  [70464/90240]\n",
      "loss: 0.691857  [76864/90240]\n",
      "loss: 0.395544  [83264/90240]\n",
      "loss: 0.556013  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.754945 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.600614  [   64/90240]\n",
      "loss: 0.924361  [ 6464/90240]\n",
      "loss: 0.583272  [12864/90240]\n",
      "loss: 0.759371  [19264/90240]\n",
      "loss: 0.370210  [25664/90240]\n",
      "loss: 0.696521  [32064/90240]\n",
      "loss: 0.587172  [38464/90240]\n",
      "loss: 0.842084  [44864/90240]\n",
      "loss: 0.731273  [51264/90240]\n",
      "loss: 0.638239  [57664/90240]\n",
      "loss: 0.406117  [64064/90240]\n",
      "loss: 0.666190  [70464/90240]\n",
      "loss: 0.485295  [76864/90240]\n",
      "loss: 0.532086  [83264/90240]\n",
      "loss: 0.746426  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.676182 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.616209  [   64/90240]\n",
      "loss: 0.672770  [ 6464/90240]\n",
      "loss: 0.724120  [12864/90240]\n",
      "loss: 0.538664  [19264/90240]\n",
      "loss: 0.485173  [25664/90240]\n",
      "loss: 0.791143  [32064/90240]\n",
      "loss: 0.683971  [38464/90240]\n",
      "loss: 0.465184  [44864/90240]\n",
      "loss: 0.509733  [51264/90240]\n",
      "loss: 0.523478  [57664/90240]\n",
      "loss: 0.677584  [64064/90240]\n",
      "loss: 0.773462  [70464/90240]\n",
      "loss: 0.535365  [76864/90240]\n",
      "loss: 0.791105  [83264/90240]\n",
      "loss: 0.738413  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.640577 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.704038  [   64/90240]\n",
      "loss: 0.436919  [ 6464/90240]\n",
      "loss: 0.650369  [12864/90240]\n",
      "loss: 0.664495  [19264/90240]\n",
      "loss: 0.656393  [25664/90240]\n",
      "loss: 0.699283  [32064/90240]\n",
      "loss: 1.183642  [38464/90240]\n",
      "loss: 0.393087  [44864/90240]\n",
      "loss: 0.568399  [51264/90240]\n",
      "loss: 0.780219  [57664/90240]\n",
      "loss: 0.530517  [64064/90240]\n",
      "loss: 0.549386  [70464/90240]\n",
      "loss: 0.811681  [76864/90240]\n",
      "loss: 0.511109  [83264/90240]\n",
      "loss: 0.446050  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.609397 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.562050  [   64/90240]\n",
      "loss: 0.422280  [ 6464/90240]\n",
      "loss: 0.314494  [12864/90240]\n",
      "loss: 0.586297  [19264/90240]\n",
      "loss: 0.612608  [25664/90240]\n",
      "loss: 0.430833  [32064/90240]\n",
      "loss: 0.557140  [38464/90240]\n",
      "loss: 0.848326  [44864/90240]\n",
      "loss: 0.662613  [51264/90240]\n",
      "loss: 0.300713  [57664/90240]\n",
      "loss: 0.474358  [64064/90240]\n",
      "loss: 0.409502  [70464/90240]\n",
      "loss: 0.506834  [76864/90240]\n",
      "loss: 0.620670  [83264/90240]\n",
      "loss: 0.606739  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.596089 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.736393  [   64/90240]\n",
      "loss: 0.383208  [ 6464/90240]\n",
      "loss: 0.457124  [12864/90240]\n",
      "loss: 0.460112  [19264/90240]\n",
      "loss: 0.538152  [25664/90240]\n",
      "loss: 0.602350  [32064/90240]\n",
      "loss: 0.478512  [38464/90240]\n",
      "loss: 0.436741  [44864/90240]\n",
      "loss: 0.454503  [51264/90240]\n",
      "loss: 0.451590  [57664/90240]\n",
      "loss: 0.353121  [64064/90240]\n",
      "loss: 0.356013  [70464/90240]\n",
      "loss: 0.548531  [76864/90240]\n",
      "loss: 0.614740  [83264/90240]\n",
      "loss: 0.347744  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.569400 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.489595  [   64/90240]\n",
      "loss: 0.506846  [ 6464/90240]\n",
      "loss: 0.571837  [12864/90240]\n",
      "loss: 0.483015  [19264/90240]\n",
      "loss: 0.859748  [25664/90240]\n",
      "loss: 0.453356  [32064/90240]\n",
      "loss: 0.639920  [38464/90240]\n",
      "loss: 0.595302  [44864/90240]\n",
      "loss: 0.637578  [51264/90240]\n",
      "loss: 0.563772  [57664/90240]\n",
      "loss: 0.485907  [64064/90240]\n",
      "loss: 0.500407  [70464/90240]\n",
      "loss: 0.448372  [76864/90240]\n",
      "loss: 0.559641  [83264/90240]\n",
      "loss: 0.536000  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.555345 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.468994  [   64/90240]\n",
      "loss: 0.318062  [ 6464/90240]\n",
      "loss: 0.362757  [12864/90240]\n",
      "loss: 0.599192  [19264/90240]\n",
      "loss: 0.614683  [25664/90240]\n",
      "loss: 0.257688  [32064/90240]\n",
      "loss: 0.234269  [38464/90240]\n",
      "loss: 0.542158  [44864/90240]\n",
      "loss: 0.663966  [51264/90240]\n",
      "loss: 0.467665  [57664/90240]\n",
      "loss: 0.518194  [64064/90240]\n",
      "loss: 0.663149  [70464/90240]\n",
      "loss: 0.519490  [76864/90240]\n",
      "loss: 0.302474  [83264/90240]\n",
      "loss: 0.420198  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.559936 \n",
      "\n",
      "Done!\n",
      "model : m9\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.850109  [   64/90240]\n",
      "loss: 3.865658  [ 6464/90240]\n",
      "loss: 3.843335  [12864/90240]\n",
      "loss: 3.844138  [19264/90240]\n",
      "loss: 3.860494  [25664/90240]\n",
      "loss: 3.842172  [32064/90240]\n",
      "loss: 3.847029  [38464/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.843332  [44864/90240]\n",
      "loss: 3.845011  [51264/90240]\n",
      "loss: 3.839220  [57664/90240]\n",
      "loss: 3.850154  [64064/90240]\n",
      "loss: 3.840619  [70464/90240]\n",
      "loss: 3.845337  [76864/90240]\n",
      "loss: 3.840154  [83264/90240]\n",
      "loss: 3.834921  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 5.0%, Avg loss: 3.834633 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.834116  [   64/90240]\n",
      "loss: 3.838436  [ 6464/90240]\n",
      "loss: 3.828526  [12864/90240]\n",
      "loss: 3.818736  [19264/90240]\n",
      "loss: 3.799929  [25664/90240]\n",
      "loss: 3.792919  [32064/90240]\n",
      "loss: 3.757581  [38464/90240]\n",
      "loss: 3.684561  [44864/90240]\n",
      "loss: 3.524542  [51264/90240]\n",
      "loss: 2.930366  [57664/90240]\n",
      "loss: 1.842181  [64064/90240]\n",
      "loss: 1.570866  [70464/90240]\n",
      "loss: 1.659688  [76864/90240]\n",
      "loss: 1.263767  [83264/90240]\n",
      "loss: 1.396255  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 1.364668 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.322446  [   64/90240]\n",
      "loss: 1.167332  [ 6464/90240]\n",
      "loss: 1.845907  [12864/90240]\n",
      "loss: 1.274018  [19264/90240]\n",
      "loss: 0.892688  [25664/90240]\n",
      "loss: 1.271969  [32064/90240]\n",
      "loss: 0.835186  [38464/90240]\n",
      "loss: 1.303110  [44864/90240]\n",
      "loss: 1.022509  [51264/90240]\n",
      "loss: 1.258882  [57664/90240]\n",
      "loss: 1.189640  [64064/90240]\n",
      "loss: 1.049247  [70464/90240]\n",
      "loss: 0.810688  [76864/90240]\n",
      "loss: 0.766023  [83264/90240]\n",
      "loss: 0.975660  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.943607 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.016683  [   64/90240]\n",
      "loss: 0.981821  [ 6464/90240]\n",
      "loss: 0.859679  [12864/90240]\n",
      "loss: 1.184022  [19264/90240]\n",
      "loss: 0.853964  [25664/90240]\n",
      "loss: 0.818537  [32064/90240]\n",
      "loss: 1.149110  [38464/90240]\n",
      "loss: 0.754833  [44864/90240]\n",
      "loss: 0.696104  [51264/90240]\n",
      "loss: 0.529231  [57664/90240]\n",
      "loss: 0.803195  [64064/90240]\n",
      "loss: 0.875457  [70464/90240]\n",
      "loss: 0.571655  [76864/90240]\n",
      "loss: 0.974077  [83264/90240]\n",
      "loss: 0.987163  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.772712 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.519504  [   64/90240]\n",
      "loss: 0.507052  [ 6464/90240]\n",
      "loss: 0.594949  [12864/90240]\n",
      "loss: 0.996273  [19264/90240]\n",
      "loss: 0.726273  [25664/90240]\n",
      "loss: 0.939846  [32064/90240]\n",
      "loss: 0.704349  [38464/90240]\n",
      "loss: 0.738390  [44864/90240]\n",
      "loss: 0.569866  [51264/90240]\n",
      "loss: 0.775300  [57664/90240]\n",
      "loss: 0.612682  [64064/90240]\n",
      "loss: 0.609944  [70464/90240]\n",
      "loss: 0.726815  [76864/90240]\n",
      "loss: 0.523199  [83264/90240]\n",
      "loss: 0.641452  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.674885 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.450316  [   64/90240]\n",
      "loss: 0.826831  [ 6464/90240]\n",
      "loss: 0.508478  [12864/90240]\n",
      "loss: 0.597068  [19264/90240]\n",
      "loss: 0.664720  [25664/90240]\n",
      "loss: 0.554861  [32064/90240]\n",
      "loss: 0.748135  [38464/90240]\n",
      "loss: 0.822540  [44864/90240]\n",
      "loss: 0.731372  [51264/90240]\n",
      "loss: 0.492151  [57664/90240]\n",
      "loss: 0.464161  [64064/90240]\n",
      "loss: 0.881865  [70464/90240]\n",
      "loss: 0.653319  [76864/90240]\n",
      "loss: 0.661862  [83264/90240]\n",
      "loss: 0.525171  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.651350 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.727735  [   64/90240]\n",
      "loss: 0.370358  [ 6464/90240]\n",
      "loss: 0.654382  [12864/90240]\n",
      "loss: 0.494491  [19264/90240]\n",
      "loss: 0.514516  [25664/90240]\n",
      "loss: 0.636364  [32064/90240]\n",
      "loss: 0.516229  [38464/90240]\n",
      "loss: 0.443621  [44864/90240]\n",
      "loss: 0.637294  [51264/90240]\n",
      "loss: 0.602307  [57664/90240]\n",
      "loss: 0.484314  [64064/90240]\n",
      "loss: 0.441419  [70464/90240]\n",
      "loss: 0.488089  [76864/90240]\n",
      "loss: 0.516776  [83264/90240]\n",
      "loss: 0.612330  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.615418 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.616092  [   64/90240]\n",
      "loss: 0.602578  [ 6464/90240]\n",
      "loss: 0.458794  [12864/90240]\n",
      "loss: 0.656585  [19264/90240]\n",
      "loss: 0.745541  [25664/90240]\n",
      "loss: 0.657522  [32064/90240]\n",
      "loss: 0.304069  [38464/90240]\n",
      "loss: 0.670196  [44864/90240]\n",
      "loss: 0.354489  [51264/90240]\n",
      "loss: 0.502123  [57664/90240]\n",
      "loss: 0.468870  [64064/90240]\n",
      "loss: 0.721212  [70464/90240]\n",
      "loss: 0.415597  [76864/90240]\n",
      "loss: 0.401493  [83264/90240]\n",
      "loss: 0.483397  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.590191 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.608625  [   64/90240]\n",
      "loss: 0.853714  [ 6464/90240]\n",
      "loss: 0.525119  [12864/90240]\n",
      "loss: 0.351108  [19264/90240]\n",
      "loss: 0.631621  [25664/90240]\n",
      "loss: 0.574334  [32064/90240]\n",
      "loss: 0.631010  [38464/90240]\n",
      "loss: 0.807267  [44864/90240]\n",
      "loss: 0.527193  [51264/90240]\n",
      "loss: 0.423397  [57664/90240]\n",
      "loss: 0.376358  [64064/90240]\n",
      "loss: 0.562465  [70464/90240]\n",
      "loss: 0.712911  [76864/90240]\n",
      "loss: 0.561670  [83264/90240]\n",
      "loss: 0.544830  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.572521 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.506297  [   64/90240]\n",
      "loss: 0.784451  [ 6464/90240]\n",
      "loss: 0.607844  [12864/90240]\n",
      "loss: 0.381069  [19264/90240]\n",
      "loss: 0.500971  [25664/90240]\n",
      "loss: 0.374640  [32064/90240]\n",
      "loss: 0.932139  [38464/90240]\n",
      "loss: 0.573786  [44864/90240]\n",
      "loss: 0.563748  [51264/90240]\n",
      "loss: 0.387620  [57664/90240]\n",
      "loss: 0.713525  [64064/90240]\n",
      "loss: 0.519786  [70464/90240]\n",
      "loss: 0.387370  [76864/90240]\n",
      "loss: 0.672568  [83264/90240]\n",
      "loss: 0.346048  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.567872 \n",
      "\n",
      "Done!\n",
      "model : m10\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): Sigmoid()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10816, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.872180  [   64/90240]\n",
      "loss: 3.978861  [ 6464/90240]\n",
      "loss: 3.896357  [12864/90240]\n",
      "loss: 3.930608  [19264/90240]\n",
      "loss: 3.909808  [25664/90240]\n",
      "loss: 3.962442  [32064/90240]\n",
      "loss: 3.877720  [38464/90240]\n",
      "loss: 3.875937  [44864/90240]\n",
      "loss: 3.863363  [51264/90240]\n",
      "loss: 3.886808  [57664/90240]\n",
      "loss: 3.943599  [64064/90240]\n",
      "loss: 3.917998  [70464/90240]\n",
      "loss: 3.907181  [76864/90240]\n",
      "loss: 3.822540  [83264/90240]\n",
      "loss: 3.921530  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.8%, Avg loss: 3.879866 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.865120  [   64/90240]\n",
      "loss: 3.877131  [ 6464/90240]\n",
      "loss: 3.863687  [12864/90240]\n",
      "loss: 3.856993  [19264/90240]\n",
      "loss: 3.899191  [25664/90240]\n",
      "loss: 3.830005  [32064/90240]\n",
      "loss: 3.832141  [38464/90240]\n",
      "loss: 3.843662  [44864/90240]\n",
      "loss: 3.850250  [51264/90240]\n",
      "loss: 3.840478  [57664/90240]\n",
      "loss: 3.830419  [64064/90240]\n",
      "loss: 3.831112  [70464/90240]\n",
      "loss: 3.813954  [76864/90240]\n",
      "loss: 3.784408  [83264/90240]\n",
      "loss: 3.827292  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.825299 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.817129  [   64/90240]\n",
      "loss: 3.818032  [ 6464/90240]\n",
      "loss: 3.776160  [12864/90240]\n",
      "loss: 3.807510  [19264/90240]\n",
      "loss: 3.754153  [25664/90240]\n",
      "loss: 3.697928  [32064/90240]\n",
      "loss: 3.661112  [38464/90240]\n",
      "loss: 3.590767  [44864/90240]\n",
      "loss: 3.526316  [51264/90240]\n",
      "loss: 3.504559  [57664/90240]\n",
      "loss: 3.360711  [64064/90240]\n",
      "loss: 3.149414  [70464/90240]\n",
      "loss: 2.927670  [76864/90240]\n",
      "loss: 2.660764  [83264/90240]\n",
      "loss: 2.570237  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 2.525964 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.525145  [   64/90240]\n",
      "loss: 2.379137  [ 6464/90240]\n",
      "loss: 2.290185  [12864/90240]\n",
      "loss: 2.070159  [19264/90240]\n",
      "loss: 1.667988  [25664/90240]\n",
      "loss: 1.724134  [32064/90240]\n",
      "loss: 1.780009  [38464/90240]\n",
      "loss: 1.893006  [44864/90240]\n",
      "loss: 1.644732  [51264/90240]\n",
      "loss: 1.517987  [57664/90240]\n",
      "loss: 1.702594  [64064/90240]\n",
      "loss: 1.317841  [70464/90240]\n",
      "loss: 1.358652  [76864/90240]\n",
      "loss: 1.614480  [83264/90240]\n",
      "loss: 1.534513  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 1.459968 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.367609  [   64/90240]\n",
      "loss: 1.484561  [ 6464/90240]\n",
      "loss: 1.547824  [12864/90240]\n",
      "loss: 1.344746  [19264/90240]\n",
      "loss: 1.641581  [25664/90240]\n",
      "loss: 1.077404  [32064/90240]\n",
      "loss: 1.167524  [38464/90240]\n",
      "loss: 1.305803  [44864/90240]\n",
      "loss: 1.487781  [51264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.396271  [57664/90240]\n",
      "loss: 1.389998  [64064/90240]\n",
      "loss: 1.338722  [70464/90240]\n",
      "loss: 1.301914  [76864/90240]\n",
      "loss: 1.259101  [83264/90240]\n",
      "loss: 1.366922  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 1.315197 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.158737  [   64/90240]\n",
      "loss: 1.448871  [ 6464/90240]\n",
      "loss: 1.333566  [12864/90240]\n",
      "loss: 1.124565  [19264/90240]\n",
      "loss: 1.399309  [25664/90240]\n",
      "loss: 1.190876  [32064/90240]\n",
      "loss: 1.245285  [38464/90240]\n",
      "loss: 1.048686  [44864/90240]\n",
      "loss: 1.115677  [51264/90240]\n",
      "loss: 1.265673  [57664/90240]\n",
      "loss: 0.888370  [64064/90240]\n",
      "loss: 1.571753  [70464/90240]\n",
      "loss: 1.266480  [76864/90240]\n",
      "loss: 1.382910  [83264/90240]\n",
      "loss: 1.102394  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.259786 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.193299  [   64/90240]\n",
      "loss: 1.272686  [ 6464/90240]\n",
      "loss: 1.110073  [12864/90240]\n",
      "loss: 1.447660  [19264/90240]\n",
      "loss: 1.410794  [25664/90240]\n",
      "loss: 1.722716  [32064/90240]\n",
      "loss: 1.293040  [38464/90240]\n",
      "loss: 1.021412  [44864/90240]\n",
      "loss: 1.202907  [51264/90240]\n",
      "loss: 1.279085  [57664/90240]\n",
      "loss: 0.936946  [64064/90240]\n",
      "loss: 0.892043  [70464/90240]\n",
      "loss: 1.075974  [76864/90240]\n",
      "loss: 1.230187  [83264/90240]\n",
      "loss: 1.334946  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 1.213763 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.181126  [   64/90240]\n",
      "loss: 1.125255  [ 6464/90240]\n",
      "loss: 1.391909  [12864/90240]\n",
      "loss: 1.408548  [19264/90240]\n",
      "loss: 1.412655  [25664/90240]\n",
      "loss: 1.349437  [32064/90240]\n",
      "loss: 1.223728  [38464/90240]\n",
      "loss: 1.127287  [44864/90240]\n",
      "loss: 0.962933  [51264/90240]\n",
      "loss: 1.134067  [57664/90240]\n",
      "loss: 1.079015  [64064/90240]\n",
      "loss: 1.564546  [70464/90240]\n",
      "loss: 1.204253  [76864/90240]\n",
      "loss: 1.113442  [83264/90240]\n",
      "loss: 1.291481  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.187650 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.066436  [   64/90240]\n",
      "loss: 1.125117  [ 6464/90240]\n",
      "loss: 1.041532  [12864/90240]\n",
      "loss: 1.390088  [19264/90240]\n",
      "loss: 0.934689  [25664/90240]\n",
      "loss: 0.934976  [32064/90240]\n",
      "loss: 1.124957  [38464/90240]\n",
      "loss: 1.411935  [44864/90240]\n",
      "loss: 1.486638  [51264/90240]\n",
      "loss: 1.364494  [57664/90240]\n",
      "loss: 0.961951  [64064/90240]\n",
      "loss: 1.025405  [70464/90240]\n",
      "loss: 1.019267  [76864/90240]\n",
      "loss: 1.273419  [83264/90240]\n",
      "loss: 1.107975  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 1.160542 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.152020  [   64/90240]\n",
      "loss: 0.952154  [ 6464/90240]\n",
      "loss: 1.239013  [12864/90240]\n",
      "loss: 0.999197  [19264/90240]\n",
      "loss: 1.327858  [25664/90240]\n",
      "loss: 0.944195  [32064/90240]\n",
      "loss: 1.056869  [38464/90240]\n",
      "loss: 1.101009  [44864/90240]\n",
      "loss: 0.985573  [51264/90240]\n",
      "loss: 1.226015  [57664/90240]\n",
      "loss: 0.948345  [64064/90240]\n",
      "loss: 1.351089  [70464/90240]\n",
      "loss: 1.272455  [76864/90240]\n",
      "loss: 0.973157  [83264/90240]\n",
      "loss: 1.224533  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 1.145789 \n",
      "\n",
      "Done!\n",
      "model : m10\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): Sigmoid()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.877859  [   64/90240]\n",
      "loss: 3.855839  [ 6464/90240]\n",
      "loss: 3.847110  [12864/90240]\n",
      "loss: 3.843083  [19264/90240]\n",
      "loss: 3.852466  [25664/90240]\n",
      "loss: 3.860653  [32064/90240]\n",
      "loss: 3.856992  [38464/90240]\n",
      "loss: 3.859972  [44864/90240]\n",
      "loss: 3.847291  [51264/90240]\n",
      "loss: 3.851870  [57664/90240]\n",
      "loss: 3.853921  [64064/90240]\n",
      "loss: 3.850641  [70464/90240]\n",
      "loss: 3.850756  [76864/90240]\n",
      "loss: 3.852462  [83264/90240]\n",
      "loss: 3.848531  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850597 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.850783  [   64/90240]\n",
      "loss: 3.840411  [ 6464/90240]\n",
      "loss: 3.855391  [12864/90240]\n",
      "loss: 3.851629  [19264/90240]\n",
      "loss: 3.853620  [25664/90240]\n",
      "loss: 3.855906  [32064/90240]\n",
      "loss: 3.850629  [38464/90240]\n",
      "loss: 3.851493  [44864/90240]\n",
      "loss: 3.848712  [51264/90240]\n",
      "loss: 3.847872  [57664/90240]\n",
      "loss: 3.855995  [64064/90240]\n",
      "loss: 3.842033  [70464/90240]\n",
      "loss: 3.847041  [76864/90240]\n",
      "loss: 3.853525  [83264/90240]\n",
      "loss: 3.850992  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850544 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.856600  [   64/90240]\n",
      "loss: 3.853258  [ 6464/90240]\n",
      "loss: 3.851449  [12864/90240]\n",
      "loss: 3.855873  [19264/90240]\n",
      "loss: 3.856196  [25664/90240]\n",
      "loss: 3.848448  [32064/90240]\n",
      "loss: 3.849192  [38464/90240]\n",
      "loss: 3.847265  [44864/90240]\n",
      "loss: 3.852202  [51264/90240]\n",
      "loss: 3.851961  [57664/90240]\n",
      "loss: 3.844494  [64064/90240]\n",
      "loss: 3.853253  [70464/90240]\n",
      "loss: 3.850278  [76864/90240]\n",
      "loss: 3.847448  [83264/90240]\n",
      "loss: 3.851171  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850517 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.856535  [   64/90240]\n",
      "loss: 3.851632  [ 6464/90240]\n",
      "loss: 3.849251  [12864/90240]\n",
      "loss: 3.849669  [19264/90240]\n",
      "loss: 3.849582  [25664/90240]\n",
      "loss: 3.851708  [32064/90240]\n",
      "loss: 3.856438  [38464/90240]\n",
      "loss: 3.847524  [44864/90240]\n",
      "loss: 3.851405  [51264/90240]\n",
      "loss: 3.851387  [57664/90240]\n",
      "loss: 3.852763  [64064/90240]\n",
      "loss: 3.854557  [70464/90240]\n",
      "loss: 3.852689  [76864/90240]\n",
      "loss: 3.850989  [83264/90240]\n",
      "loss: 3.850110  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850516 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.847990  [   64/90240]\n",
      "loss: 3.852073  [ 6464/90240]\n",
      "loss: 3.845233  [12864/90240]\n",
      "loss: 3.854417  [19264/90240]\n",
      "loss: 3.853866  [25664/90240]\n",
      "loss: 3.852095  [32064/90240]\n",
      "loss: 3.849929  [38464/90240]\n",
      "loss: 3.850506  [44864/90240]\n",
      "loss: 3.850041  [51264/90240]\n",
      "loss: 3.855006  [57664/90240]\n",
      "loss: 3.851900  [64064/90240]\n",
      "loss: 3.854848  [70464/90240]\n",
      "loss: 3.845636  [76864/90240]\n",
      "loss: 3.853921  [83264/90240]\n",
      "loss: 3.851293  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850520 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.851588  [   64/90240]\n",
      "loss: 3.849576  [ 6464/90240]\n",
      "loss: 3.851651  [12864/90240]\n",
      "loss: 3.848964  [19264/90240]\n",
      "loss: 3.848712  [25664/90240]\n",
      "loss: 3.848897  [32064/90240]\n",
      "loss: 3.848354  [38464/90240]\n",
      "loss: 3.847198  [44864/90240]\n",
      "loss: 3.852968  [51264/90240]\n",
      "loss: 3.851744  [57664/90240]\n",
      "loss: 3.854333  [64064/90240]\n",
      "loss: 3.847066  [70464/90240]\n",
      "loss: 3.850049  [76864/90240]\n",
      "loss: 3.851099  [83264/90240]\n",
      "loss: 3.851003  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850527 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.849947  [   64/90240]\n",
      "loss: 3.850751  [ 6464/90240]\n",
      "loss: 3.849461  [12864/90240]\n",
      "loss: 3.854357  [19264/90240]\n",
      "loss: 3.850286  [25664/90240]\n",
      "loss: 3.847989  [32064/90240]\n",
      "loss: 3.847992  [38464/90240]\n",
      "loss: 3.847021  [44864/90240]\n",
      "loss: 3.851990  [51264/90240]\n",
      "loss: 3.846134  [57664/90240]\n",
      "loss: 3.850135  [64064/90240]\n",
      "loss: 3.851770  [70464/90240]\n",
      "loss: 3.850756  [76864/90240]\n",
      "loss: 3.847523  [83264/90240]\n",
      "loss: 3.850501  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850536 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.850698  [   64/90240]\n",
      "loss: 3.850746  [ 6464/90240]\n",
      "loss: 3.846974  [12864/90240]\n",
      "loss: 3.852988  [19264/90240]\n",
      "loss: 3.851666  [25664/90240]\n",
      "loss: 3.851338  [32064/90240]\n",
      "loss: 3.854064  [38464/90240]\n",
      "loss: 3.847340  [44864/90240]\n",
      "loss: 3.849151  [51264/90240]\n",
      "loss: 3.848122  [57664/90240]\n",
      "loss: 3.847505  [64064/90240]\n",
      "loss: 3.850819  [70464/90240]\n",
      "loss: 3.847682  [76864/90240]\n",
      "loss: 3.850657  [83264/90240]\n",
      "loss: 3.849975  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850561 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.848780  [   64/90240]\n",
      "loss: 3.848528  [ 6464/90240]\n",
      "loss: 3.851269  [12864/90240]\n",
      "loss: 3.852300  [19264/90240]\n",
      "loss: 3.850611  [25664/90240]\n",
      "loss: 3.849560  [32064/90240]\n",
      "loss: 3.850684  [38464/90240]\n",
      "loss: 3.851578  [44864/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.850655  [51264/90240]\n",
      "loss: 3.850439  [57664/90240]\n",
      "loss: 3.849135  [64064/90240]\n",
      "loss: 3.851233  [70464/90240]\n",
      "loss: 3.849787  [76864/90240]\n",
      "loss: 3.851747  [83264/90240]\n",
      "loss: 3.851968  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850573 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.851631  [   64/90240]\n",
      "loss: 3.849846  [ 6464/90240]\n",
      "loss: 3.850686  [12864/90240]\n",
      "loss: 3.850013  [19264/90240]\n",
      "loss: 3.850232  [25664/90240]\n",
      "loss: 3.848737  [32064/90240]\n",
      "loss: 3.851564  [38464/90240]\n",
      "loss: 3.849360  [44864/90240]\n",
      "loss: 3.849372  [51264/90240]\n",
      "loss: 3.850398  [57664/90240]\n",
      "loss: 3.848774  [64064/90240]\n",
      "loss: 3.852537  [70464/90240]\n",
      "loss: 3.846558  [76864/90240]\n",
      "loss: 3.851888  [83264/90240]\n",
      "loss: 3.850745  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850597 \n",
      "\n",
      "Done!\n",
      "model : m10\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): Sigmoid()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.872907  [   64/90240]\n",
      "loss: 3.862923  [ 6464/90240]\n",
      "loss: 3.860344  [12864/90240]\n",
      "loss: 3.854158  [19264/90240]\n",
      "loss: 3.855230  [25664/90240]\n",
      "loss: 3.847795  [32064/90240]\n",
      "loss: 3.853577  [38464/90240]\n",
      "loss: 3.851517  [44864/90240]\n",
      "loss: 3.843244  [51264/90240]\n",
      "loss: 3.852286  [57664/90240]\n",
      "loss: 3.854217  [64064/90240]\n",
      "loss: 3.844699  [70464/90240]\n",
      "loss: 3.850035  [76864/90240]\n",
      "loss: 3.857092  [83264/90240]\n",
      "loss: 3.848724  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.851274 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.852947  [   64/90240]\n",
      "loss: 3.851499  [ 6464/90240]\n",
      "loss: 3.845097  [12864/90240]\n",
      "loss: 3.861908  [19264/90240]\n",
      "loss: 3.850707  [25664/90240]\n",
      "loss: 3.851152  [32064/90240]\n",
      "loss: 3.845526  [38464/90240]\n",
      "loss: 3.857477  [44864/90240]\n",
      "loss: 3.850593  [51264/90240]\n",
      "loss: 3.849792  [57664/90240]\n",
      "loss: 3.850795  [64064/90240]\n",
      "loss: 3.848311  [70464/90240]\n",
      "loss: 3.850951  [76864/90240]\n",
      "loss: 3.847859  [83264/90240]\n",
      "loss: 3.846906  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850961 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.850606  [   64/90240]\n",
      "loss: 3.852401  [ 6464/90240]\n",
      "loss: 3.850136  [12864/90240]\n",
      "loss: 3.847708  [19264/90240]\n",
      "loss: 3.856937  [25664/90240]\n",
      "loss: 3.849827  [32064/90240]\n",
      "loss: 3.852325  [38464/90240]\n",
      "loss: 3.844148  [44864/90240]\n",
      "loss: 3.854780  [51264/90240]\n",
      "loss: 3.844812  [57664/90240]\n",
      "loss: 3.849300  [64064/90240]\n",
      "loss: 3.847789  [70464/90240]\n",
      "loss: 3.852626  [76864/90240]\n",
      "loss: 3.854900  [83264/90240]\n",
      "loss: 3.846695  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.851090 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.844447  [   64/90240]\n",
      "loss: 3.846323  [ 6464/90240]\n",
      "loss: 3.852369  [12864/90240]\n",
      "loss: 3.847562  [19264/90240]\n",
      "loss: 3.845764  [25664/90240]\n",
      "loss: 3.850242  [32064/90240]\n",
      "loss: 3.851688  [38464/90240]\n",
      "loss: 3.850945  [44864/90240]\n",
      "loss: 3.846925  [51264/90240]\n",
      "loss: 3.851765  [57664/90240]\n",
      "loss: 3.850004  [64064/90240]\n",
      "loss: 3.851399  [70464/90240]\n",
      "loss: 3.848915  [76864/90240]\n",
      "loss: 3.847965  [83264/90240]\n",
      "loss: 3.851844  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850895 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.849659  [   64/90240]\n",
      "loss: 3.849498  [ 6464/90240]\n",
      "loss: 3.853175  [12864/90240]\n",
      "loss: 3.853641  [19264/90240]\n",
      "loss: 3.851655  [25664/90240]\n",
      "loss: 3.848874  [32064/90240]\n",
      "loss: 3.850514  [38464/90240]\n",
      "loss: 3.853696  [44864/90240]\n",
      "loss: 3.848699  [51264/90240]\n",
      "loss: 3.850684  [57664/90240]\n",
      "loss: 3.850860  [64064/90240]\n",
      "loss: 3.849317  [70464/90240]\n",
      "loss: 3.849654  [76864/90240]\n",
      "loss: 3.849370  [83264/90240]\n",
      "loss: 3.848411  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850747 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.850666  [   64/90240]\n",
      "loss: 3.849055  [ 6464/90240]\n",
      "loss: 3.853767  [12864/90240]\n",
      "loss: 3.852272  [19264/90240]\n",
      "loss: 3.849108  [25664/90240]\n",
      "loss: 3.851094  [32064/90240]\n",
      "loss: 3.852821  [38464/90240]\n",
      "loss: 3.849975  [44864/90240]\n",
      "loss: 3.847561  [51264/90240]\n",
      "loss: 3.849358  [57664/90240]\n",
      "loss: 3.849218  [64064/90240]\n",
      "loss: 3.851737  [70464/90240]\n",
      "loss: 3.848809  [76864/90240]\n",
      "loss: 3.852694  [83264/90240]\n",
      "loss: 3.847944  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 3.850692 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.850261  [   64/90240]\n",
      "loss: 3.849119  [ 6464/90240]\n",
      "loss: 3.851955  [12864/90240]\n",
      "loss: 3.849318  [19264/90240]\n",
      "loss: 3.852185  [25664/90240]\n",
      "loss: 3.848404  [32064/90240]\n",
      "loss: 3.852803  [38464/90240]\n",
      "loss: 3.847908  [44864/90240]\n",
      "loss: 3.850551  [51264/90240]\n",
      "loss: 3.845849  [57664/90240]\n",
      "loss: 3.849064  [64064/90240]\n",
      "loss: 3.853457  [70464/90240]\n",
      "loss: 3.850976  [76864/90240]\n",
      "loss: 3.850749  [83264/90240]\n",
      "loss: 3.847317  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850732 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.848520  [   64/90240]\n",
      "loss: 3.851700  [ 6464/90240]\n",
      "loss: 3.850868  [12864/90240]\n",
      "loss: 3.852205  [19264/90240]\n",
      "loss: 3.847983  [25664/90240]\n",
      "loss: 3.849092  [32064/90240]\n",
      "loss: 3.848783  [38464/90240]\n",
      "loss: 3.848583  [44864/90240]\n",
      "loss: 3.844620  [51264/90240]\n",
      "loss: 3.852134  [57664/90240]\n",
      "loss: 3.852844  [64064/90240]\n",
      "loss: 3.848885  [70464/90240]\n",
      "loss: 3.852666  [76864/90240]\n",
      "loss: 3.847883  [83264/90240]\n",
      "loss: 3.846221  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 3.850712 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.849577  [   64/90240]\n",
      "loss: 3.852965  [ 6464/90240]\n",
      "loss: 3.849305  [12864/90240]\n",
      "loss: 3.851692  [19264/90240]\n",
      "loss: 3.847748  [25664/90240]\n",
      "loss: 3.849547  [32064/90240]\n",
      "loss: 3.851923  [38464/90240]\n",
      "loss: 3.848473  [44864/90240]\n",
      "loss: 3.851273  [51264/90240]\n",
      "loss: 3.847629  [57664/90240]\n",
      "loss: 3.848203  [64064/90240]\n",
      "loss: 3.851683  [70464/90240]\n",
      "loss: 3.844849  [76864/90240]\n",
      "loss: 3.851573  [83264/90240]\n",
      "loss: 3.847372  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850622 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.850971  [   64/90240]\n",
      "loss: 3.850973  [ 6464/90240]\n",
      "loss: 3.851763  [12864/90240]\n",
      "loss: 3.850564  [19264/90240]\n",
      "loss: 3.852106  [25664/90240]\n",
      "loss: 3.850348  [32064/90240]\n",
      "loss: 3.849814  [38464/90240]\n",
      "loss: 3.855411  [44864/90240]\n",
      "loss: 3.851901  [51264/90240]\n",
      "loss: 3.851521  [57664/90240]\n",
      "loss: 3.848884  [64064/90240]\n",
      "loss: 3.852271  [70464/90240]\n",
      "loss: 3.850017  [76864/90240]\n",
      "loss: 3.851701  [83264/90240]\n",
      "loss: 3.851362  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850660 \n",
      "\n",
      "Done!\n",
      "model : m11\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10816, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.947558  [   64/90240]\n",
      "loss: 1.285572  [ 6464/90240]\n",
      "loss: 1.313488  [12864/90240]\n",
      "loss: 1.248198  [19264/90240]\n",
      "loss: 0.775894  [25664/90240]\n",
      "loss: 0.782971  [32064/90240]\n",
      "loss: 0.880905  [38464/90240]\n",
      "loss: 0.896820  [44864/90240]\n",
      "loss: 0.786069  [51264/90240]\n",
      "loss: 0.587474  [57664/90240]\n",
      "loss: 0.851388  [64064/90240]\n",
      "loss: 0.956633  [70464/90240]\n",
      "loss: 0.675476  [76864/90240]\n",
      "loss: 0.553042  [83264/90240]\n",
      "loss: 0.962308  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.654251 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.779655  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.555027  [ 6464/90240]\n",
      "loss: 0.863643  [12864/90240]\n",
      "loss: 0.586600  [19264/90240]\n",
      "loss: 0.476591  [25664/90240]\n",
      "loss: 0.711240  [32064/90240]\n",
      "loss: 0.601081  [38464/90240]\n",
      "loss: 0.618971  [44864/90240]\n",
      "loss: 0.365839  [51264/90240]\n",
      "loss: 0.540393  [57664/90240]\n",
      "loss: 0.572201  [64064/90240]\n",
      "loss: 0.867289  [70464/90240]\n",
      "loss: 0.593485  [76864/90240]\n",
      "loss: 0.652142  [83264/90240]\n",
      "loss: 0.458743  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.570486 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.495683  [   64/90240]\n",
      "loss: 0.715452  [ 6464/90240]\n",
      "loss: 0.574824  [12864/90240]\n",
      "loss: 0.480678  [19264/90240]\n",
      "loss: 0.458549  [25664/90240]\n",
      "loss: 0.566319  [32064/90240]\n",
      "loss: 0.645880  [38464/90240]\n",
      "loss: 0.573264  [44864/90240]\n",
      "loss: 0.435129  [51264/90240]\n",
      "loss: 0.491493  [57664/90240]\n",
      "loss: 0.526232  [64064/90240]\n",
      "loss: 0.573358  [70464/90240]\n",
      "loss: 0.765175  [76864/90240]\n",
      "loss: 0.374037  [83264/90240]\n",
      "loss: 0.546257  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.532030 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.414426  [   64/90240]\n",
      "loss: 0.373628  [ 6464/90240]\n",
      "loss: 0.500297  [12864/90240]\n",
      "loss: 0.395428  [19264/90240]\n",
      "loss: 0.609382  [25664/90240]\n",
      "loss: 0.373662  [32064/90240]\n",
      "loss: 0.531824  [38464/90240]\n",
      "loss: 0.396878  [44864/90240]\n",
      "loss: 0.510294  [51264/90240]\n",
      "loss: 0.575669  [57664/90240]\n",
      "loss: 0.450010  [64064/90240]\n",
      "loss: 0.646531  [70464/90240]\n",
      "loss: 0.463505  [76864/90240]\n",
      "loss: 0.484751  [83264/90240]\n",
      "loss: 0.740226  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.512674 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.363983  [   64/90240]\n",
      "loss: 0.298728  [ 6464/90240]\n",
      "loss: 0.304375  [12864/90240]\n",
      "loss: 0.440780  [19264/90240]\n",
      "loss: 0.443061  [25664/90240]\n",
      "loss: 0.216439  [32064/90240]\n",
      "loss: 0.446662  [38464/90240]\n",
      "loss: 0.466498  [44864/90240]\n",
      "loss: 0.363595  [51264/90240]\n",
      "loss: 0.465288  [57664/90240]\n",
      "loss: 0.294780  [64064/90240]\n",
      "loss: 0.486922  [70464/90240]\n",
      "loss: 0.491886  [76864/90240]\n",
      "loss: 0.468637  [83264/90240]\n",
      "loss: 0.623193  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.494868 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.321317  [   64/90240]\n",
      "loss: 0.571084  [ 6464/90240]\n",
      "loss: 0.616010  [12864/90240]\n",
      "loss: 0.499680  [19264/90240]\n",
      "loss: 0.444112  [25664/90240]\n",
      "loss: 0.270661  [32064/90240]\n",
      "loss: 0.676982  [38464/90240]\n",
      "loss: 0.433696  [44864/90240]\n",
      "loss: 0.432603  [51264/90240]\n",
      "loss: 0.232395  [57664/90240]\n",
      "loss: 0.776989  [64064/90240]\n",
      "loss: 0.590718  [70464/90240]\n",
      "loss: 0.480487  [76864/90240]\n",
      "loss: 0.317944  [83264/90240]\n",
      "loss: 0.489440  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.477077 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.497361  [   64/90240]\n",
      "loss: 0.580069  [ 6464/90240]\n",
      "loss: 0.508648  [12864/90240]\n",
      "loss: 0.771386  [19264/90240]\n",
      "loss: 0.424661  [25664/90240]\n",
      "loss: 0.559117  [32064/90240]\n",
      "loss: 0.571349  [38464/90240]\n",
      "loss: 0.473955  [44864/90240]\n",
      "loss: 0.417272  [51264/90240]\n",
      "loss: 0.772796  [57664/90240]\n",
      "loss: 0.422987  [64064/90240]\n",
      "loss: 0.554170  [70464/90240]\n",
      "loss: 0.433768  [76864/90240]\n",
      "loss: 0.452114  [83264/90240]\n",
      "loss: 0.420587  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.485536 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.327042  [   64/90240]\n",
      "loss: 0.455606  [ 6464/90240]\n",
      "loss: 0.399817  [12864/90240]\n",
      "loss: 0.339753  [19264/90240]\n",
      "loss: 0.457048  [25664/90240]\n",
      "loss: 0.524990  [32064/90240]\n",
      "loss: 0.440664  [38464/90240]\n",
      "loss: 0.262543  [44864/90240]\n",
      "loss: 0.215217  [51264/90240]\n",
      "loss: 0.616576  [57664/90240]\n",
      "loss: 0.531869  [64064/90240]\n",
      "loss: 0.473530  [70464/90240]\n",
      "loss: 0.332473  [76864/90240]\n",
      "loss: 0.328814  [83264/90240]\n",
      "loss: 0.444457  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.460311 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.262789  [   64/90240]\n",
      "loss: 0.428535  [ 6464/90240]\n",
      "loss: 0.381342  [12864/90240]\n",
      "loss: 0.454574  [19264/90240]\n",
      "loss: 0.309808  [25664/90240]\n",
      "loss: 0.444962  [32064/90240]\n",
      "loss: 0.345766  [38464/90240]\n",
      "loss: 0.265320  [44864/90240]\n",
      "loss: 0.513343  [51264/90240]\n",
      "loss: 0.358492  [57664/90240]\n",
      "loss: 0.214237  [64064/90240]\n",
      "loss: 0.509878  [70464/90240]\n",
      "loss: 0.570894  [76864/90240]\n",
      "loss: 0.426883  [83264/90240]\n",
      "loss: 0.435626  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.475179 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.327402  [   64/90240]\n",
      "loss: 0.433236  [ 6464/90240]\n",
      "loss: 0.421113  [12864/90240]\n",
      "loss: 0.286584  [19264/90240]\n",
      "loss: 0.285521  [25664/90240]\n",
      "loss: 0.507479  [32064/90240]\n",
      "loss: 0.216256  [38464/90240]\n",
      "loss: 0.493172  [44864/90240]\n",
      "loss: 0.437235  [51264/90240]\n",
      "loss: 0.483122  [57664/90240]\n",
      "loss: 0.387127  [64064/90240]\n",
      "loss: 0.353871  [70464/90240]\n",
      "loss: 0.553349  [76864/90240]\n",
      "loss: 0.230011  [83264/90240]\n",
      "loss: 0.405817  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.461710 \n",
      "\n",
      "Done!\n",
      "model : m11\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.867419  [   64/90240]\n",
      "loss: 2.491923  [ 6464/90240]\n",
      "loss: 1.387785  [12864/90240]\n",
      "loss: 0.977285  [19264/90240]\n",
      "loss: 1.074211  [25664/90240]\n",
      "loss: 1.000455  [32064/90240]\n",
      "loss: 1.181618  [38464/90240]\n",
      "loss: 1.004350  [44864/90240]\n",
      "loss: 0.955614  [51264/90240]\n",
      "loss: 0.656982  [57664/90240]\n",
      "loss: 0.883834  [64064/90240]\n",
      "loss: 0.787520  [70464/90240]\n",
      "loss: 0.858139  [76864/90240]\n",
      "loss: 0.772561  [83264/90240]\n",
      "loss: 0.635872  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.670313 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.546443  [   64/90240]\n",
      "loss: 0.584120  [ 6464/90240]\n",
      "loss: 0.720190  [12864/90240]\n",
      "loss: 0.741127  [19264/90240]\n",
      "loss: 0.603918  [25664/90240]\n",
      "loss: 0.684035  [32064/90240]\n",
      "loss: 0.604840  [38464/90240]\n",
      "loss: 0.624793  [44864/90240]\n",
      "loss: 0.647159  [51264/90240]\n",
      "loss: 0.736887  [57664/90240]\n",
      "loss: 0.543276  [64064/90240]\n",
      "loss: 0.777931  [70464/90240]\n",
      "loss: 0.499436  [76864/90240]\n",
      "loss: 0.463506  [83264/90240]\n",
      "loss: 0.481255  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.552179 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.797690  [   64/90240]\n",
      "loss: 0.374967  [ 6464/90240]\n",
      "loss: 0.457401  [12864/90240]\n",
      "loss: 0.556906  [19264/90240]\n",
      "loss: 0.677843  [25664/90240]\n",
      "loss: 0.551308  [32064/90240]\n",
      "loss: 0.310685  [38464/90240]\n",
      "loss: 0.480897  [44864/90240]\n",
      "loss: 0.525026  [51264/90240]\n",
      "loss: 0.637288  [57664/90240]\n",
      "loss: 0.331448  [64064/90240]\n",
      "loss: 0.501685  [70464/90240]\n",
      "loss: 0.697593  [76864/90240]\n",
      "loss: 0.463016  [83264/90240]\n",
      "loss: 0.312529  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.497751 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.650995  [   64/90240]\n",
      "loss: 0.470586  [ 6464/90240]\n",
      "loss: 0.312588  [12864/90240]\n",
      "loss: 0.530303  [19264/90240]\n",
      "loss: 0.579176  [25664/90240]\n",
      "loss: 0.468796  [32064/90240]\n",
      "loss: 0.473593  [38464/90240]\n",
      "loss: 0.654473  [44864/90240]\n",
      "loss: 0.495352  [51264/90240]\n",
      "loss: 0.453828  [57664/90240]\n",
      "loss: 0.268271  [64064/90240]\n",
      "loss: 0.772304  [70464/90240]\n",
      "loss: 0.410376  [76864/90240]\n",
      "loss: 0.458505  [83264/90240]\n",
      "loss: 0.715953  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.466577 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.344584  [   64/90240]\n",
      "loss: 0.374768  [ 6464/90240]\n",
      "loss: 0.418450  [12864/90240]\n",
      "loss: 0.464472  [19264/90240]\n",
      "loss: 0.391432  [25664/90240]\n",
      "loss: 0.338956  [32064/90240]\n",
      "loss: 0.312408  [38464/90240]\n",
      "loss: 0.543595  [44864/90240]\n",
      "loss: 0.513693  [51264/90240]\n",
      "loss: 0.395407  [57664/90240]\n",
      "loss: 0.355591  [64064/90240]\n",
      "loss: 0.474970  [70464/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.494734  [76864/90240]\n",
      "loss: 0.368185  [83264/90240]\n",
      "loss: 0.178430  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.446112 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.283781  [   64/90240]\n",
      "loss: 0.459356  [ 6464/90240]\n",
      "loss: 0.359875  [12864/90240]\n",
      "loss: 0.498752  [19264/90240]\n",
      "loss: 0.656478  [25664/90240]\n",
      "loss: 0.302654  [32064/90240]\n",
      "loss: 0.563002  [38464/90240]\n",
      "loss: 0.171899  [44864/90240]\n",
      "loss: 0.399524  [51264/90240]\n",
      "loss: 0.289605  [57664/90240]\n",
      "loss: 0.311485  [64064/90240]\n",
      "loss: 0.616103  [70464/90240]\n",
      "loss: 0.332959  [76864/90240]\n",
      "loss: 0.372835  [83264/90240]\n",
      "loss: 0.425851  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.427083 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.310052  [   64/90240]\n",
      "loss: 0.333325  [ 6464/90240]\n",
      "loss: 0.689827  [12864/90240]\n",
      "loss: 0.600642  [19264/90240]\n",
      "loss: 0.399575  [25664/90240]\n",
      "loss: 0.299930  [32064/90240]\n",
      "loss: 0.285886  [38464/90240]\n",
      "loss: 0.440059  [44864/90240]\n",
      "loss: 0.276964  [51264/90240]\n",
      "loss: 0.288510  [57664/90240]\n",
      "loss: 0.333991  [64064/90240]\n",
      "loss: 0.340165  [70464/90240]\n",
      "loss: 0.433500  [76864/90240]\n",
      "loss: 0.376389  [83264/90240]\n",
      "loss: 0.358779  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.417442 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.447870  [   64/90240]\n",
      "loss: 0.272590  [ 6464/90240]\n",
      "loss: 0.517657  [12864/90240]\n",
      "loss: 0.293849  [19264/90240]\n",
      "loss: 0.642393  [25664/90240]\n",
      "loss: 0.318880  [32064/90240]\n",
      "loss: 0.330809  [38464/90240]\n",
      "loss: 0.290590  [44864/90240]\n",
      "loss: 0.249644  [51264/90240]\n",
      "loss: 0.396932  [57664/90240]\n",
      "loss: 0.299735  [64064/90240]\n",
      "loss: 0.298236  [70464/90240]\n",
      "loss: 0.302937  [76864/90240]\n",
      "loss: 0.237919  [83264/90240]\n",
      "loss: 0.309932  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.413075 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.417781  [   64/90240]\n",
      "loss: 0.408601  [ 6464/90240]\n",
      "loss: 0.562223  [12864/90240]\n",
      "loss: 0.359591  [19264/90240]\n",
      "loss: 0.311654  [25664/90240]\n",
      "loss: 0.265655  [32064/90240]\n",
      "loss: 0.347214  [38464/90240]\n",
      "loss: 0.400764  [44864/90240]\n",
      "loss: 0.493198  [51264/90240]\n",
      "loss: 0.572557  [57664/90240]\n",
      "loss: 0.575182  [64064/90240]\n",
      "loss: 0.341615  [70464/90240]\n",
      "loss: 0.340709  [76864/90240]\n",
      "loss: 0.488688  [83264/90240]\n",
      "loss: 0.343748  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.399360 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.307874  [   64/90240]\n",
      "loss: 0.300753  [ 6464/90240]\n",
      "loss: 0.236275  [12864/90240]\n",
      "loss: 0.235566  [19264/90240]\n",
      "loss: 0.391684  [25664/90240]\n",
      "loss: 0.233959  [32064/90240]\n",
      "loss: 0.310987  [38464/90240]\n",
      "loss: 0.445286  [44864/90240]\n",
      "loss: 0.196176  [51264/90240]\n",
      "loss: 0.163585  [57664/90240]\n",
      "loss: 0.351205  [64064/90240]\n",
      "loss: 0.267980  [70464/90240]\n",
      "loss: 0.241651  [76864/90240]\n",
      "loss: 0.169904  [83264/90240]\n",
      "loss: 0.535949  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.399180 \n",
      "\n",
      "Done!\n",
      "model : m11\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.877095  [   64/90240]\n",
      "loss: 3.513487  [ 6464/90240]\n",
      "loss: 3.000826  [12864/90240]\n",
      "loss: 2.275983  [19264/90240]\n",
      "loss: 1.644199  [25664/90240]\n",
      "loss: 1.261931  [32064/90240]\n",
      "loss: 1.228691  [38464/90240]\n",
      "loss: 1.160177  [44864/90240]\n",
      "loss: 0.996312  [51264/90240]\n",
      "loss: 1.006324  [57664/90240]\n",
      "loss: 1.107248  [64064/90240]\n",
      "loss: 0.752461  [70464/90240]\n",
      "loss: 0.927260  [76864/90240]\n",
      "loss: 0.939643  [83264/90240]\n",
      "loss: 0.787784  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.816778 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.769761  [   64/90240]\n",
      "loss: 0.824448  [ 6464/90240]\n",
      "loss: 0.790466  [12864/90240]\n",
      "loss: 0.730291  [19264/90240]\n",
      "loss: 0.695537  [25664/90240]\n",
      "loss: 0.894848  [32064/90240]\n",
      "loss: 0.607771  [38464/90240]\n",
      "loss: 0.546795  [44864/90240]\n",
      "loss: 0.625999  [51264/90240]\n",
      "loss: 0.778475  [57664/90240]\n",
      "loss: 0.681378  [64064/90240]\n",
      "loss: 0.562304  [70464/90240]\n",
      "loss: 0.435535  [76864/90240]\n",
      "loss: 0.888324  [83264/90240]\n",
      "loss: 0.582497  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.629741 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.408013  [   64/90240]\n",
      "loss: 0.559928  [ 6464/90240]\n",
      "loss: 0.486039  [12864/90240]\n",
      "loss: 0.431334  [19264/90240]\n",
      "loss: 0.450299  [25664/90240]\n",
      "loss: 0.470567  [32064/90240]\n",
      "loss: 0.538770  [38464/90240]\n",
      "loss: 0.421333  [44864/90240]\n",
      "loss: 0.434122  [51264/90240]\n",
      "loss: 0.614037  [57664/90240]\n",
      "loss: 0.513699  [64064/90240]\n",
      "loss: 0.437961  [70464/90240]\n",
      "loss: 0.627121  [76864/90240]\n",
      "loss: 0.710327  [83264/90240]\n",
      "loss: 0.684921  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.549670 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.428794  [   64/90240]\n",
      "loss: 0.371946  [ 6464/90240]\n",
      "loss: 0.410681  [12864/90240]\n",
      "loss: 0.500463  [19264/90240]\n",
      "loss: 0.711539  [25664/90240]\n",
      "loss: 0.730001  [32064/90240]\n",
      "loss: 0.536260  [38464/90240]\n",
      "loss: 0.495300  [44864/90240]\n",
      "loss: 0.394896  [51264/90240]\n",
      "loss: 0.735895  [57664/90240]\n",
      "loss: 0.287082  [64064/90240]\n",
      "loss: 0.487380  [70464/90240]\n",
      "loss: 0.253740  [76864/90240]\n",
      "loss: 0.365740  [83264/90240]\n",
      "loss: 0.463019  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.500195 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.468215  [   64/90240]\n",
      "loss: 0.407118  [ 6464/90240]\n",
      "loss: 0.567798  [12864/90240]\n",
      "loss: 0.415896  [19264/90240]\n",
      "loss: 0.355832  [25664/90240]\n",
      "loss: 0.234645  [32064/90240]\n",
      "loss: 0.421599  [38464/90240]\n",
      "loss: 0.524463  [44864/90240]\n",
      "loss: 0.426212  [51264/90240]\n",
      "loss: 0.422980  [57664/90240]\n",
      "loss: 0.561415  [64064/90240]\n",
      "loss: 0.497559  [70464/90240]\n",
      "loss: 0.539632  [76864/90240]\n",
      "loss: 0.267921  [83264/90240]\n",
      "loss: 0.487389  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.471509 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.615658  [   64/90240]\n",
      "loss: 0.559659  [ 6464/90240]\n",
      "loss: 0.562376  [12864/90240]\n",
      "loss: 0.448172  [19264/90240]\n",
      "loss: 0.332621  [25664/90240]\n",
      "loss: 0.350992  [32064/90240]\n",
      "loss: 0.508270  [38464/90240]\n",
      "loss: 0.333582  [44864/90240]\n",
      "loss: 0.389205  [51264/90240]\n",
      "loss: 0.248788  [57664/90240]\n",
      "loss: 0.462773  [64064/90240]\n",
      "loss: 0.678760  [70464/90240]\n",
      "loss: 0.322933  [76864/90240]\n",
      "loss: 0.413743  [83264/90240]\n",
      "loss: 0.395884  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.459532 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.383199  [   64/90240]\n",
      "loss: 0.372957  [ 6464/90240]\n",
      "loss: 0.390629  [12864/90240]\n",
      "loss: 0.669109  [19264/90240]\n",
      "loss: 0.374207  [25664/90240]\n",
      "loss: 0.410699  [32064/90240]\n",
      "loss: 0.409490  [38464/90240]\n",
      "loss: 0.494006  [44864/90240]\n",
      "loss: 0.440839  [51264/90240]\n",
      "loss: 0.466434  [57664/90240]\n",
      "loss: 0.407752  [64064/90240]\n",
      "loss: 0.369126  [70464/90240]\n",
      "loss: 0.268874  [76864/90240]\n",
      "loss: 0.322866  [83264/90240]\n",
      "loss: 0.472977  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.441040 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.243933  [   64/90240]\n",
      "loss: 0.359639  [ 6464/90240]\n",
      "loss: 0.366220  [12864/90240]\n",
      "loss: 0.222044  [19264/90240]\n",
      "loss: 0.439550  [25664/90240]\n",
      "loss: 0.424978  [32064/90240]\n",
      "loss: 0.291700  [38464/90240]\n",
      "loss: 0.385981  [44864/90240]\n",
      "loss: 0.551293  [51264/90240]\n",
      "loss: 0.316695  [57664/90240]\n",
      "loss: 0.274165  [64064/90240]\n",
      "loss: 0.440390  [70464/90240]\n",
      "loss: 0.627309  [76864/90240]\n",
      "loss: 0.315815  [83264/90240]\n",
      "loss: 0.432489  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.416342 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.479238  [   64/90240]\n",
      "loss: 0.312693  [ 6464/90240]\n",
      "loss: 0.291308  [12864/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.392132  [19264/90240]\n",
      "loss: 0.252655  [25664/90240]\n",
      "loss: 0.320285  [32064/90240]\n",
      "loss: 0.406560  [38464/90240]\n",
      "loss: 0.422331  [44864/90240]\n",
      "loss: 0.344452  [51264/90240]\n",
      "loss: 0.180111  [57664/90240]\n",
      "loss: 0.245948  [64064/90240]\n",
      "loss: 0.828366  [70464/90240]\n",
      "loss: 0.358815  [76864/90240]\n",
      "loss: 0.205858  [83264/90240]\n",
      "loss: 0.298226  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.411926 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.312409  [   64/90240]\n",
      "loss: 0.310099  [ 6464/90240]\n",
      "loss: 0.305199  [12864/90240]\n",
      "loss: 0.507640  [19264/90240]\n",
      "loss: 0.430460  [25664/90240]\n",
      "loss: 0.388952  [32064/90240]\n",
      "loss: 0.313941  [38464/90240]\n",
      "loss: 0.347719  [44864/90240]\n",
      "loss: 0.368231  [51264/90240]\n",
      "loss: 0.225069  [57664/90240]\n",
      "loss: 0.465883  [64064/90240]\n",
      "loss: 0.318843  [70464/90240]\n",
      "loss: 0.478805  [76864/90240]\n",
      "loss: 0.342994  [83264/90240]\n",
      "loss: 0.314471  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.398707 \n",
      "\n",
      "Done!\n",
      "model : m12\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=10816, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.971342  [   64/90240]\n",
      "loss: 3.699024  [ 6464/90240]\n",
      "loss: 3.329856  [12864/90240]\n",
      "loss: 2.865066  [19264/90240]\n",
      "loss: 2.590463  [25664/90240]\n",
      "loss: 2.284441  [32064/90240]\n",
      "loss: 1.887971  [38464/90240]\n",
      "loss: 1.842686  [44864/90240]\n",
      "loss: 1.755212  [51264/90240]\n",
      "loss: 1.667516  [57664/90240]\n",
      "loss: 1.885228  [64064/90240]\n",
      "loss: 1.658905  [70464/90240]\n",
      "loss: 1.329641  [76864/90240]\n",
      "loss: 1.646791  [83264/90240]\n",
      "loss: 1.542895  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.490169 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.478509  [   64/90240]\n",
      "loss: 1.623656  [ 6464/90240]\n",
      "loss: 1.257683  [12864/90240]\n",
      "loss: 1.554377  [19264/90240]\n",
      "loss: 1.093118  [25664/90240]\n",
      "loss: 1.043438  [32064/90240]\n",
      "loss: 1.253304  [38464/90240]\n",
      "loss: 1.285215  [44864/90240]\n",
      "loss: 1.450018  [51264/90240]\n",
      "loss: 1.170951  [57664/90240]\n",
      "loss: 1.039454  [64064/90240]\n",
      "loss: 1.199302  [70464/90240]\n",
      "loss: 1.206546  [76864/90240]\n",
      "loss: 1.063579  [83264/90240]\n",
      "loss: 0.936341  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.320232 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.595016  [   64/90240]\n",
      "loss: 1.134302  [ 6464/90240]\n",
      "loss: 1.154134  [12864/90240]\n",
      "loss: 1.360323  [19264/90240]\n",
      "loss: 1.142567  [25664/90240]\n",
      "loss: 1.222889  [32064/90240]\n",
      "loss: 0.935771  [38464/90240]\n",
      "loss: 1.109412  [44864/90240]\n",
      "loss: 1.113841  [51264/90240]\n",
      "loss: 1.197785  [57664/90240]\n",
      "loss: 1.250224  [64064/90240]\n",
      "loss: 1.041268  [70464/90240]\n",
      "loss: 1.357847  [76864/90240]\n",
      "loss: 1.330812  [83264/90240]\n",
      "loss: 1.013372  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.225179 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.451075  [   64/90240]\n",
      "loss: 1.103984  [ 6464/90240]\n",
      "loss: 1.295212  [12864/90240]\n",
      "loss: 1.118704  [19264/90240]\n",
      "loss: 1.053821  [25664/90240]\n",
      "loss: 1.173024  [32064/90240]\n",
      "loss: 1.277197  [38464/90240]\n",
      "loss: 1.159902  [44864/90240]\n",
      "loss: 0.994346  [51264/90240]\n",
      "loss: 1.180127  [57664/90240]\n",
      "loss: 1.287386  [64064/90240]\n",
      "loss: 0.993937  [70464/90240]\n",
      "loss: 0.884168  [76864/90240]\n",
      "loss: 1.335998  [83264/90240]\n",
      "loss: 1.022010  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.196074 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.048251  [   64/90240]\n",
      "loss: 0.981434  [ 6464/90240]\n",
      "loss: 1.073208  [12864/90240]\n",
      "loss: 1.033937  [19264/90240]\n",
      "loss: 0.990544  [25664/90240]\n",
      "loss: 0.834786  [32064/90240]\n",
      "loss: 1.002992  [38464/90240]\n",
      "loss: 1.231926  [44864/90240]\n",
      "loss: 0.965252  [51264/90240]\n",
      "loss: 0.969345  [57664/90240]\n",
      "loss: 1.238843  [64064/90240]\n",
      "loss: 1.176332  [70464/90240]\n",
      "loss: 1.236163  [76864/90240]\n",
      "loss: 1.321913  [83264/90240]\n",
      "loss: 1.164865  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 1.154034 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.944831  [   64/90240]\n",
      "loss: 1.420110  [ 6464/90240]\n",
      "loss: 1.208263  [12864/90240]\n",
      "loss: 1.269631  [19264/90240]\n",
      "loss: 1.009295  [25664/90240]\n",
      "loss: 1.268127  [32064/90240]\n",
      "loss: 1.141190  [38464/90240]\n",
      "loss: 0.866415  [44864/90240]\n",
      "loss: 1.093567  [51264/90240]\n",
      "loss: 0.741990  [57664/90240]\n",
      "loss: 1.215910  [64064/90240]\n",
      "loss: 0.984130  [70464/90240]\n",
      "loss: 1.017628  [76864/90240]\n",
      "loss: 0.913342  [83264/90240]\n",
      "loss: 1.165532  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.112815 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.146049  [   64/90240]\n",
      "loss: 0.929320  [ 6464/90240]\n",
      "loss: 1.360006  [12864/90240]\n",
      "loss: 1.047558  [19264/90240]\n",
      "loss: 1.180078  [25664/90240]\n",
      "loss: 0.921429  [32064/90240]\n",
      "loss: 1.451473  [38464/90240]\n",
      "loss: 0.873016  [44864/90240]\n",
      "loss: 1.181516  [51264/90240]\n",
      "loss: 1.019662  [57664/90240]\n",
      "loss: 1.119620  [64064/90240]\n",
      "loss: 1.086063  [70464/90240]\n",
      "loss: 1.140175  [76864/90240]\n",
      "loss: 1.201506  [83264/90240]\n",
      "loss: 0.817304  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.071147 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.953096  [   64/90240]\n",
      "loss: 1.256371  [ 6464/90240]\n",
      "loss: 0.837091  [12864/90240]\n",
      "loss: 1.111373  [19264/90240]\n",
      "loss: 1.015085  [25664/90240]\n",
      "loss: 0.908115  [32064/90240]\n",
      "loss: 0.940671  [38464/90240]\n",
      "loss: 0.981567  [44864/90240]\n",
      "loss: 1.468266  [51264/90240]\n",
      "loss: 0.701620  [57664/90240]\n",
      "loss: 1.105186  [64064/90240]\n",
      "loss: 0.871514  [70464/90240]\n",
      "loss: 1.012464  [76864/90240]\n",
      "loss: 1.319264  [83264/90240]\n",
      "loss: 1.330384  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.060060 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.883756  [   64/90240]\n",
      "loss: 1.255398  [ 6464/90240]\n",
      "loss: 1.034037  [12864/90240]\n",
      "loss: 1.154327  [19264/90240]\n",
      "loss: 0.964491  [25664/90240]\n",
      "loss: 1.045953  [32064/90240]\n",
      "loss: 1.140098  [38464/90240]\n",
      "loss: 0.795301  [44864/90240]\n",
      "loss: 1.065390  [51264/90240]\n",
      "loss: 1.077848  [57664/90240]\n",
      "loss: 1.077667  [64064/90240]\n",
      "loss: 1.063759  [70464/90240]\n",
      "loss: 1.132690  [76864/90240]\n",
      "loss: 0.859178  [83264/90240]\n",
      "loss: 1.090184  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.031903 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.821284  [   64/90240]\n",
      "loss: 1.014619  [ 6464/90240]\n",
      "loss: 1.346419  [12864/90240]\n",
      "loss: 0.873756  [19264/90240]\n",
      "loss: 0.809522  [25664/90240]\n",
      "loss: 1.082255  [32064/90240]\n",
      "loss: 0.970701  [38464/90240]\n",
      "loss: 0.953332  [44864/90240]\n",
      "loss: 0.764067  [51264/90240]\n",
      "loss: 0.976909  [57664/90240]\n",
      "loss: 1.124946  [64064/90240]\n",
      "loss: 1.180609  [70464/90240]\n",
      "loss: 1.079317  [76864/90240]\n",
      "loss: 1.277260  [83264/90240]\n",
      "loss: 0.822353  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 1.005587 \n",
      "\n",
      "Done!\n",
      "model : m12\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.878374  [   64/90240]\n",
      "loss: 3.842438  [ 6464/90240]\n",
      "loss: 3.844764  [12864/90240]\n",
      "loss: 3.809459  [19264/90240]\n",
      "loss: 3.774770  [25664/90240]\n",
      "loss: 3.785000  [32064/90240]\n",
      "loss: 3.728287  [38464/90240]\n",
      "loss: 3.678903  [44864/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.559139  [51264/90240]\n",
      "loss: 3.442841  [57664/90240]\n",
      "loss: 3.263294  [64064/90240]\n",
      "loss: 3.067043  [70464/90240]\n",
      "loss: 2.746545  [76864/90240]\n",
      "loss: 2.801579  [83264/90240]\n",
      "loss: 2.284052  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.422632 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.274565  [   64/90240]\n",
      "loss: 2.200702  [ 6464/90240]\n",
      "loss: 2.073674  [12864/90240]\n",
      "loss: 2.008163  [19264/90240]\n",
      "loss: 1.654262  [25664/90240]\n",
      "loss: 1.821996  [32064/90240]\n",
      "loss: 1.667378  [38464/90240]\n",
      "loss: 1.871846  [44864/90240]\n",
      "loss: 1.526024  [51264/90240]\n",
      "loss: 1.452182  [57664/90240]\n",
      "loss: 1.592344  [64064/90240]\n",
      "loss: 1.533810  [70464/90240]\n",
      "loss: 1.273874  [76864/90240]\n",
      "loss: 1.617961  [83264/90240]\n",
      "loss: 1.541530  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 1.451906 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.289389  [   64/90240]\n",
      "loss: 1.531270  [ 6464/90240]\n",
      "loss: 1.340360  [12864/90240]\n",
      "loss: 1.899426  [19264/90240]\n",
      "loss: 1.436872  [25664/90240]\n",
      "loss: 1.423674  [32064/90240]\n",
      "loss: 0.918747  [38464/90240]\n",
      "loss: 1.389767  [44864/90240]\n",
      "loss: 1.649411  [51264/90240]\n",
      "loss: 1.259839  [57664/90240]\n",
      "loss: 1.272859  [64064/90240]\n",
      "loss: 1.191607  [70464/90240]\n",
      "loss: 1.588272  [76864/90240]\n",
      "loss: 1.576034  [83264/90240]\n",
      "loss: 1.140991  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.290236 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.066110  [   64/90240]\n",
      "loss: 1.178484  [ 6464/90240]\n",
      "loss: 1.276282  [12864/90240]\n",
      "loss: 1.384178  [19264/90240]\n",
      "loss: 1.681353  [25664/90240]\n",
      "loss: 1.265912  [32064/90240]\n",
      "loss: 1.416573  [38464/90240]\n",
      "loss: 1.264636  [44864/90240]\n",
      "loss: 1.219950  [51264/90240]\n",
      "loss: 1.142864  [57664/90240]\n",
      "loss: 1.035937  [64064/90240]\n",
      "loss: 1.186867  [70464/90240]\n",
      "loss: 1.178333  [76864/90240]\n",
      "loss: 0.909565  [83264/90240]\n",
      "loss: 1.147794  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 1.211556 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.456488  [   64/90240]\n",
      "loss: 1.705976  [ 6464/90240]\n",
      "loss: 1.327947  [12864/90240]\n",
      "loss: 0.776326  [19264/90240]\n",
      "loss: 1.237065  [25664/90240]\n",
      "loss: 1.308166  [32064/90240]\n",
      "loss: 1.063852  [38464/90240]\n",
      "loss: 1.129722  [44864/90240]\n",
      "loss: 1.076588  [51264/90240]\n",
      "loss: 1.127798  [57664/90240]\n",
      "loss: 0.996214  [64064/90240]\n",
      "loss: 1.056643  [70464/90240]\n",
      "loss: 1.226126  [76864/90240]\n",
      "loss: 0.940272  [83264/90240]\n",
      "loss: 1.111818  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 1.152464 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.919520  [   64/90240]\n",
      "loss: 1.390376  [ 6464/90240]\n",
      "loss: 1.112293  [12864/90240]\n",
      "loss: 1.114346  [19264/90240]\n",
      "loss: 0.966383  [25664/90240]\n",
      "loss: 1.150359  [32064/90240]\n",
      "loss: 1.219570  [38464/90240]\n",
      "loss: 1.446545  [44864/90240]\n",
      "loss: 0.860169  [51264/90240]\n",
      "loss: 1.241338  [57664/90240]\n",
      "loss: 0.683225  [64064/90240]\n",
      "loss: 1.060210  [70464/90240]\n",
      "loss: 1.098699  [76864/90240]\n",
      "loss: 1.005444  [83264/90240]\n",
      "loss: 1.323843  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 1.085275 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.063764  [   64/90240]\n",
      "loss: 1.054084  [ 6464/90240]\n",
      "loss: 0.748707  [12864/90240]\n",
      "loss: 1.029100  [19264/90240]\n",
      "loss: 1.159164  [25664/90240]\n",
      "loss: 0.966153  [32064/90240]\n",
      "loss: 0.822902  [38464/90240]\n",
      "loss: 1.032527  [44864/90240]\n",
      "loss: 1.266985  [51264/90240]\n",
      "loss: 1.213334  [57664/90240]\n",
      "loss: 1.104239  [64064/90240]\n",
      "loss: 0.972389  [70464/90240]\n",
      "loss: 0.771919  [76864/90240]\n",
      "loss: 1.006447  [83264/90240]\n",
      "loss: 1.097011  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.021084 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.806593  [   64/90240]\n",
      "loss: 0.930282  [ 6464/90240]\n",
      "loss: 0.902577  [12864/90240]\n",
      "loss: 0.953965  [19264/90240]\n",
      "loss: 0.810840  [25664/90240]\n",
      "loss: 0.858708  [32064/90240]\n",
      "loss: 1.197925  [38464/90240]\n",
      "loss: 1.069970  [44864/90240]\n",
      "loss: 0.915983  [51264/90240]\n",
      "loss: 0.940950  [57664/90240]\n",
      "loss: 0.884010  [64064/90240]\n",
      "loss: 0.564813  [70464/90240]\n",
      "loss: 1.074774  [76864/90240]\n",
      "loss: 0.583055  [83264/90240]\n",
      "loss: 1.032568  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.968212 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.976560  [   64/90240]\n",
      "loss: 1.020505  [ 6464/90240]\n",
      "loss: 0.941395  [12864/90240]\n",
      "loss: 1.275632  [19264/90240]\n",
      "loss: 1.001154  [25664/90240]\n",
      "loss: 0.799232  [32064/90240]\n",
      "loss: 0.930278  [38464/90240]\n",
      "loss: 1.294175  [44864/90240]\n",
      "loss: 1.042182  [51264/90240]\n",
      "loss: 0.944977  [57664/90240]\n",
      "loss: 0.587671  [64064/90240]\n",
      "loss: 0.880778  [70464/90240]\n",
      "loss: 0.839571  [76864/90240]\n",
      "loss: 0.840537  [83264/90240]\n",
      "loss: 1.129437  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.919469 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.910867  [   64/90240]\n",
      "loss: 0.931831  [ 6464/90240]\n",
      "loss: 1.086961  [12864/90240]\n",
      "loss: 1.057863  [19264/90240]\n",
      "loss: 0.983105  [25664/90240]\n",
      "loss: 0.895429  [32064/90240]\n",
      "loss: 1.099189  [38464/90240]\n",
      "loss: 0.961751  [44864/90240]\n",
      "loss: 0.933853  [51264/90240]\n",
      "loss: 0.776909  [57664/90240]\n",
      "loss: 1.090760  [64064/90240]\n",
      "loss: 0.808709  [70464/90240]\n",
      "loss: 0.985589  [76864/90240]\n",
      "loss: 0.754863  [83264/90240]\n",
      "loss: 0.897352  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.866004 \n",
      "\n",
      "Done!\n",
      "model : m12\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=10816, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.844845  [   64/90240]\n",
      "loss: 3.849388  [ 6464/90240]\n",
      "loss: 3.837786  [12864/90240]\n",
      "loss: 3.841624  [19264/90240]\n",
      "loss: 3.825370  [25664/90240]\n",
      "loss: 3.814245  [32064/90240]\n",
      "loss: 3.779554  [38464/90240]\n",
      "loss: 3.785230  [44864/90240]\n",
      "loss: 3.739877  [51264/90240]\n",
      "loss: 3.675819  [57664/90240]\n",
      "loss: 3.672092  [64064/90240]\n",
      "loss: 3.560351  [70464/90240]\n",
      "loss: 3.381181  [76864/90240]\n",
      "loss: 3.296637  [83264/90240]\n",
      "loss: 3.151587  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 22.0%, Avg loss: 3.138038 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.286742  [   64/90240]\n",
      "loss: 2.889928  [ 6464/90240]\n",
      "loss: 2.723113  [12864/90240]\n",
      "loss: 2.666648  [19264/90240]\n",
      "loss: 2.404814  [25664/90240]\n",
      "loss: 2.320551  [32064/90240]\n",
      "loss: 2.431539  [38464/90240]\n",
      "loss: 2.213297  [44864/90240]\n",
      "loss: 2.031862  [51264/90240]\n",
      "loss: 1.750035  [57664/90240]\n",
      "loss: 1.880269  [64064/90240]\n",
      "loss: 1.765737  [70464/90240]\n",
      "loss: 1.978406  [76864/90240]\n",
      "loss: 1.831927  [83264/90240]\n",
      "loss: 1.475831  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.696080 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.540131  [   64/90240]\n",
      "loss: 1.660921  [ 6464/90240]\n",
      "loss: 1.655869  [12864/90240]\n",
      "loss: 1.610474  [19264/90240]\n",
      "loss: 1.631254  [25664/90240]\n",
      "loss: 1.810874  [32064/90240]\n",
      "loss: 1.667492  [38464/90240]\n",
      "loss: 1.319842  [44864/90240]\n",
      "loss: 1.759166  [51264/90240]\n",
      "loss: 1.486566  [57664/90240]\n",
      "loss: 1.587743  [64064/90240]\n",
      "loss: 1.169214  [70464/90240]\n",
      "loss: 1.315728  [76864/90240]\n",
      "loss: 1.268804  [83264/90240]\n",
      "loss: 1.710214  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.381896 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.822375  [   64/90240]\n",
      "loss: 1.552186  [ 6464/90240]\n",
      "loss: 1.442541  [12864/90240]\n",
      "loss: 1.043655  [19264/90240]\n",
      "loss: 1.184332  [25664/90240]\n",
      "loss: 1.373784  [32064/90240]\n",
      "loss: 1.331213  [38464/90240]\n",
      "loss: 1.291821  [44864/90240]\n",
      "loss: 1.134917  [51264/90240]\n",
      "loss: 1.205986  [57664/90240]\n",
      "loss: 1.300866  [64064/90240]\n",
      "loss: 1.573246  [70464/90240]\n",
      "loss: 1.115593  [76864/90240]\n",
      "loss: 1.130708  [83264/90240]\n",
      "loss: 0.851063  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.248360 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.247783  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.121120  [ 6464/90240]\n",
      "loss: 0.923677  [12864/90240]\n",
      "loss: 1.175666  [19264/90240]\n",
      "loss: 1.162990  [25664/90240]\n",
      "loss: 1.291693  [32064/90240]\n",
      "loss: 1.014483  [38464/90240]\n",
      "loss: 1.227703  [44864/90240]\n",
      "loss: 1.107440  [51264/90240]\n",
      "loss: 1.281095  [57664/90240]\n",
      "loss: 0.808671  [64064/90240]\n",
      "loss: 1.027097  [70464/90240]\n",
      "loss: 1.213749  [76864/90240]\n",
      "loss: 1.324755  [83264/90240]\n",
      "loss: 1.054858  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.159345 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.103094  [   64/90240]\n",
      "loss: 0.884228  [ 6464/90240]\n",
      "loss: 1.577770  [12864/90240]\n",
      "loss: 1.376406  [19264/90240]\n",
      "loss: 1.222324  [25664/90240]\n",
      "loss: 1.233239  [32064/90240]\n",
      "loss: 1.190935  [38464/90240]\n",
      "loss: 1.128933  [44864/90240]\n",
      "loss: 1.269311  [51264/90240]\n",
      "loss: 1.071169  [57664/90240]\n",
      "loss: 0.977980  [64064/90240]\n",
      "loss: 1.066193  [70464/90240]\n",
      "loss: 1.134487  [76864/90240]\n",
      "loss: 1.176042  [83264/90240]\n",
      "loss: 1.364663  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 1.089255 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.223192  [   64/90240]\n",
      "loss: 1.216321  [ 6464/90240]\n",
      "loss: 1.073556  [12864/90240]\n",
      "loss: 1.243712  [19264/90240]\n",
      "loss: 0.761428  [25664/90240]\n",
      "loss: 1.020029  [32064/90240]\n",
      "loss: 1.041529  [38464/90240]\n",
      "loss: 1.354018  [44864/90240]\n",
      "loss: 1.008698  [51264/90240]\n",
      "loss: 1.127380  [57664/90240]\n",
      "loss: 0.997212  [64064/90240]\n",
      "loss: 0.940257  [70464/90240]\n",
      "loss: 1.153912  [76864/90240]\n",
      "loss: 1.153755  [83264/90240]\n",
      "loss: 1.121281  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.995983 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.014716  [   64/90240]\n",
      "loss: 1.092370  [ 6464/90240]\n",
      "loss: 0.749326  [12864/90240]\n",
      "loss: 0.957625  [19264/90240]\n",
      "loss: 0.909454  [25664/90240]\n",
      "loss: 1.027217  [32064/90240]\n",
      "loss: 1.237207  [38464/90240]\n",
      "loss: 0.816858  [44864/90240]\n",
      "loss: 1.183079  [51264/90240]\n",
      "loss: 1.205373  [57664/90240]\n",
      "loss: 0.938944  [64064/90240]\n",
      "loss: 1.164686  [70464/90240]\n",
      "loss: 0.971030  [76864/90240]\n",
      "loss: 0.650785  [83264/90240]\n",
      "loss: 1.322472  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.941733 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.236722  [   64/90240]\n",
      "loss: 1.073112  [ 6464/90240]\n",
      "loss: 1.007216  [12864/90240]\n",
      "loss: 0.842103  [19264/90240]\n",
      "loss: 0.932622  [25664/90240]\n",
      "loss: 0.900873  [32064/90240]\n",
      "loss: 1.026350  [38464/90240]\n",
      "loss: 0.869698  [44864/90240]\n",
      "loss: 1.151863  [51264/90240]\n",
      "loss: 0.812421  [57664/90240]\n",
      "loss: 0.903050  [64064/90240]\n",
      "loss: 1.189713  [70464/90240]\n",
      "loss: 0.942886  [76864/90240]\n",
      "loss: 0.878310  [83264/90240]\n",
      "loss: 0.837271  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.869125 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.804497  [   64/90240]\n",
      "loss: 0.793991  [ 6464/90240]\n",
      "loss: 0.896883  [12864/90240]\n",
      "loss: 0.948269  [19264/90240]\n",
      "loss: 0.752868  [25664/90240]\n",
      "loss: 1.005885  [32064/90240]\n",
      "loss: 0.626060  [38464/90240]\n",
      "loss: 0.733560  [44864/90240]\n",
      "loss: 0.869985  [51264/90240]\n",
      "loss: 0.602897  [57664/90240]\n",
      "loss: 0.730505  [64064/90240]\n",
      "loss: 0.927312  [70464/90240]\n",
      "loss: 0.648570  [76864/90240]\n",
      "loss: 0.832169  [83264/90240]\n",
      "loss: 0.782008  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.817097 \n",
      "\n",
      "Done!\n",
      "model : m13\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=20000, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.846334  [   64/90240]\n",
      "loss: 3.805599  [ 6464/90240]\n",
      "loss: 3.263716  [12864/90240]\n",
      "loss: 1.610695  [19264/90240]\n",
      "loss: 1.307954  [25664/90240]\n",
      "loss: 1.730246  [32064/90240]\n",
      "loss: 1.125103  [38464/90240]\n",
      "loss: 1.554731  [44864/90240]\n",
      "loss: 1.275023  [51264/90240]\n",
      "loss: 1.300783  [57664/90240]\n",
      "loss: 1.170639  [64064/90240]\n",
      "loss: 0.937186  [70464/90240]\n",
      "loss: 1.361329  [76864/90240]\n",
      "loss: 1.574662  [83264/90240]\n",
      "loss: 1.678645  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.227129 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.649628  [   64/90240]\n",
      "loss: 1.238691  [ 6464/90240]\n",
      "loss: 1.304692  [12864/90240]\n",
      "loss: 1.456288  [19264/90240]\n",
      "loss: 1.089255  [25664/90240]\n",
      "loss: 1.135325  [32064/90240]\n",
      "loss: 0.843613  [38464/90240]\n",
      "loss: 0.975564  [44864/90240]\n",
      "loss: 0.817713  [51264/90240]\n",
      "loss: 1.112095  [57664/90240]\n",
      "loss: 0.983198  [64064/90240]\n",
      "loss: 0.807083  [70464/90240]\n",
      "loss: 0.900830  [76864/90240]\n",
      "loss: 0.755370  [83264/90240]\n",
      "loss: 0.696028  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.871721 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.850272  [   64/90240]\n",
      "loss: 0.582704  [ 6464/90240]\n",
      "loss: 0.896737  [12864/90240]\n",
      "loss: 0.519150  [19264/90240]\n",
      "loss: 0.682981  [25664/90240]\n",
      "loss: 0.961229  [32064/90240]\n",
      "loss: 0.943090  [38464/90240]\n",
      "loss: 0.890450  [44864/90240]\n",
      "loss: 0.676240  [51264/90240]\n",
      "loss: 0.590706  [57664/90240]\n",
      "loss: 0.552472  [64064/90240]\n",
      "loss: 0.703170  [70464/90240]\n",
      "loss: 0.603200  [76864/90240]\n",
      "loss: 0.764107  [83264/90240]\n",
      "loss: 0.645675  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.683190 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.620562  [   64/90240]\n",
      "loss: 0.785370  [ 6464/90240]\n",
      "loss: 0.894022  [12864/90240]\n",
      "loss: 0.737985  [19264/90240]\n",
      "loss: 0.854900  [25664/90240]\n",
      "loss: 0.780223  [32064/90240]\n",
      "loss: 0.535635  [38464/90240]\n",
      "loss: 0.944446  [44864/90240]\n",
      "loss: 0.648769  [51264/90240]\n",
      "loss: 0.489837  [57664/90240]\n",
      "loss: 0.729214  [64064/90240]\n",
      "loss: 0.302534  [70464/90240]\n",
      "loss: 0.539605  [76864/90240]\n",
      "loss: 0.686587  [83264/90240]\n",
      "loss: 0.467537  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.598323 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.017207  [   64/90240]\n",
      "loss: 0.395745  [ 6464/90240]\n",
      "loss: 0.545859  [12864/90240]\n",
      "loss: 0.476549  [19264/90240]\n",
      "loss: 0.567431  [25664/90240]\n",
      "loss: 0.678135  [32064/90240]\n",
      "loss: 0.526276  [38464/90240]\n",
      "loss: 0.568916  [44864/90240]\n",
      "loss: 0.544268  [51264/90240]\n",
      "loss: 0.760815  [57664/90240]\n",
      "loss: 0.438564  [64064/90240]\n",
      "loss: 0.473005  [70464/90240]\n",
      "loss: 0.401002  [76864/90240]\n",
      "loss: 0.419892  [83264/90240]\n",
      "loss: 0.588229  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.563345 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.656909  [   64/90240]\n",
      "loss: 0.443622  [ 6464/90240]\n",
      "loss: 0.739032  [12864/90240]\n",
      "loss: 0.465906  [19264/90240]\n",
      "loss: 0.527138  [25664/90240]\n",
      "loss: 0.685560  [32064/90240]\n",
      "loss: 0.545244  [38464/90240]\n",
      "loss: 0.521177  [44864/90240]\n",
      "loss: 0.337701  [51264/90240]\n",
      "loss: 0.447530  [57664/90240]\n",
      "loss: 0.904265  [64064/90240]\n",
      "loss: 0.596343  [70464/90240]\n",
      "loss: 0.681965  [76864/90240]\n",
      "loss: 0.430567  [83264/90240]\n",
      "loss: 0.700316  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.547823 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.667727  [   64/90240]\n",
      "loss: 0.474817  [ 6464/90240]\n",
      "loss: 0.245827  [12864/90240]\n",
      "loss: 0.439090  [19264/90240]\n",
      "loss: 0.431078  [25664/90240]\n",
      "loss: 0.248208  [32064/90240]\n",
      "loss: 0.418114  [38464/90240]\n",
      "loss: 0.398951  [44864/90240]\n",
      "loss: 0.385209  [51264/90240]\n",
      "loss: 0.419167  [57664/90240]\n",
      "loss: 0.701433  [64064/90240]\n",
      "loss: 0.489152  [70464/90240]\n",
      "loss: 0.422660  [76864/90240]\n",
      "loss: 0.596146  [83264/90240]\n",
      "loss: 0.527792  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.506762 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.330411  [   64/90240]\n",
      "loss: 0.531579  [ 6464/90240]\n",
      "loss: 0.394085  [12864/90240]\n",
      "loss: 0.433012  [19264/90240]\n",
      "loss: 0.621939  [25664/90240]\n",
      "loss: 0.240699  [32064/90240]\n",
      "loss: 0.653229  [38464/90240]\n",
      "loss: 0.410445  [44864/90240]\n",
      "loss: 0.409346  [51264/90240]\n",
      "loss: 0.635518  [57664/90240]\n",
      "loss: 0.314096  [64064/90240]\n",
      "loss: 0.191026  [70464/90240]\n",
      "loss: 0.359971  [76864/90240]\n",
      "loss: 0.215157  [83264/90240]\n",
      "loss: 0.167835  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.482894 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.313855  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.676082  [ 6464/90240]\n",
      "loss: 0.333788  [12864/90240]\n",
      "loss: 0.767928  [19264/90240]\n",
      "loss: 0.399870  [25664/90240]\n",
      "loss: 0.429274  [32064/90240]\n",
      "loss: 0.315985  [38464/90240]\n",
      "loss: 0.337988  [44864/90240]\n",
      "loss: 0.429835  [51264/90240]\n",
      "loss: 0.283029  [57664/90240]\n",
      "loss: 0.673542  [64064/90240]\n",
      "loss: 0.536200  [70464/90240]\n",
      "loss: 0.384209  [76864/90240]\n",
      "loss: 0.689389  [83264/90240]\n",
      "loss: 0.520279  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.481758 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.371936  [   64/90240]\n",
      "loss: 0.422439  [ 6464/90240]\n",
      "loss: 0.561219  [12864/90240]\n",
      "loss: 0.415396  [19264/90240]\n",
      "loss: 0.475550  [25664/90240]\n",
      "loss: 0.437366  [32064/90240]\n",
      "loss: 0.388344  [38464/90240]\n",
      "loss: 0.455814  [44864/90240]\n",
      "loss: 0.343548  [51264/90240]\n",
      "loss: 0.332533  [57664/90240]\n",
      "loss: 0.408350  [64064/90240]\n",
      "loss: 0.388222  [70464/90240]\n",
      "loss: 0.461632  [76864/90240]\n",
      "loss: 0.329382  [83264/90240]\n",
      "loss: 0.403084  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.476818 \n",
      "\n",
      "Done!\n",
      "model : m13\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.860416  [   64/90240]\n",
      "loss: 3.841905  [ 6464/90240]\n",
      "loss: 3.837541  [12864/90240]\n",
      "loss: 3.788484  [19264/90240]\n",
      "loss: 3.752724  [25664/90240]\n",
      "loss: 3.026771  [32064/90240]\n",
      "loss: 1.804029  [38464/90240]\n",
      "loss: 1.481147  [44864/90240]\n",
      "loss: 1.253484  [51264/90240]\n",
      "loss: 1.291178  [57664/90240]\n",
      "loss: 1.086514  [64064/90240]\n",
      "loss: 1.320033  [70464/90240]\n",
      "loss: 1.175476  [76864/90240]\n",
      "loss: 1.044812  [83264/90240]\n",
      "loss: 1.189401  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 1.103668 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.145782  [   64/90240]\n",
      "loss: 0.805641  [ 6464/90240]\n",
      "loss: 1.107101  [12864/90240]\n",
      "loss: 1.057323  [19264/90240]\n",
      "loss: 1.053927  [25664/90240]\n",
      "loss: 0.739716  [32064/90240]\n",
      "loss: 1.003430  [38464/90240]\n",
      "loss: 0.935715  [44864/90240]\n",
      "loss: 0.946216  [51264/90240]\n",
      "loss: 0.729154  [57664/90240]\n",
      "loss: 1.133654  [64064/90240]\n",
      "loss: 0.767709  [70464/90240]\n",
      "loss: 0.725117  [76864/90240]\n",
      "loss: 1.120846  [83264/90240]\n",
      "loss: 0.538697  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.858928 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.603085  [   64/90240]\n",
      "loss: 1.092379  [ 6464/90240]\n",
      "loss: 0.835295  [12864/90240]\n",
      "loss: 0.831898  [19264/90240]\n",
      "loss: 0.842704  [25664/90240]\n",
      "loss: 0.930282  [32064/90240]\n",
      "loss: 0.892093  [38464/90240]\n",
      "loss: 0.641285  [44864/90240]\n",
      "loss: 0.823413  [51264/90240]\n",
      "loss: 0.564891  [57664/90240]\n",
      "loss: 0.680753  [64064/90240]\n",
      "loss: 1.082543  [70464/90240]\n",
      "loss: 0.706369  [76864/90240]\n",
      "loss: 0.806081  [83264/90240]\n",
      "loss: 0.788772  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.756705 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.574001  [   64/90240]\n",
      "loss: 0.789782  [ 6464/90240]\n",
      "loss: 0.618962  [12864/90240]\n",
      "loss: 0.853085  [19264/90240]\n",
      "loss: 0.600740  [25664/90240]\n",
      "loss: 1.045309  [32064/90240]\n",
      "loss: 0.729982  [38464/90240]\n",
      "loss: 1.021664  [44864/90240]\n",
      "loss: 0.687612  [51264/90240]\n",
      "loss: 1.026389  [57664/90240]\n",
      "loss: 0.960463  [64064/90240]\n",
      "loss: 0.903017  [70464/90240]\n",
      "loss: 0.680922  [76864/90240]\n",
      "loss: 0.768421  [83264/90240]\n",
      "loss: 0.669596  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.685874 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.847546  [   64/90240]\n",
      "loss: 0.726902  [ 6464/90240]\n",
      "loss: 0.799452  [12864/90240]\n",
      "loss: 1.039204  [19264/90240]\n",
      "loss: 0.676294  [25664/90240]\n",
      "loss: 0.468178  [32064/90240]\n",
      "loss: 0.819727  [38464/90240]\n",
      "loss: 0.545759  [44864/90240]\n",
      "loss: 0.530529  [51264/90240]\n",
      "loss: 0.888875  [57664/90240]\n",
      "loss: 0.737089  [64064/90240]\n",
      "loss: 0.626837  [70464/90240]\n",
      "loss: 0.520569  [76864/90240]\n",
      "loss: 0.710705  [83264/90240]\n",
      "loss: 0.642888  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.639158 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.605836  [   64/90240]\n",
      "loss: 0.840932  [ 6464/90240]\n",
      "loss: 0.606327  [12864/90240]\n",
      "loss: 0.604278  [19264/90240]\n",
      "loss: 0.549941  [25664/90240]\n",
      "loss: 0.953980  [32064/90240]\n",
      "loss: 0.534706  [38464/90240]\n",
      "loss: 0.740648  [44864/90240]\n",
      "loss: 0.558405  [51264/90240]\n",
      "loss: 0.766146  [57664/90240]\n",
      "loss: 0.715302  [64064/90240]\n",
      "loss: 0.799705  [70464/90240]\n",
      "loss: 0.586992  [76864/90240]\n",
      "loss: 0.699235  [83264/90240]\n",
      "loss: 0.391695  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.620476 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.541438  [   64/90240]\n",
      "loss: 0.609267  [ 6464/90240]\n",
      "loss: 0.523159  [12864/90240]\n",
      "loss: 0.417227  [19264/90240]\n",
      "loss: 0.637022  [25664/90240]\n",
      "loss: 0.521563  [32064/90240]\n",
      "loss: 0.448556  [38464/90240]\n",
      "loss: 0.311910  [44864/90240]\n",
      "loss: 0.877554  [51264/90240]\n",
      "loss: 0.318471  [57664/90240]\n",
      "loss: 0.651548  [64064/90240]\n",
      "loss: 0.657250  [70464/90240]\n",
      "loss: 0.536399  [76864/90240]\n",
      "loss: 0.545293  [83264/90240]\n",
      "loss: 0.741208  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.586105 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.664969  [   64/90240]\n",
      "loss: 0.413655  [ 6464/90240]\n",
      "loss: 0.315017  [12864/90240]\n",
      "loss: 0.550325  [19264/90240]\n",
      "loss: 0.421322  [25664/90240]\n",
      "loss: 0.422876  [32064/90240]\n",
      "loss: 0.537255  [38464/90240]\n",
      "loss: 0.567135  [44864/90240]\n",
      "loss: 0.471009  [51264/90240]\n",
      "loss: 0.536845  [57664/90240]\n",
      "loss: 0.546205  [64064/90240]\n",
      "loss: 0.404870  [70464/90240]\n",
      "loss: 0.521344  [76864/90240]\n",
      "loss: 0.304665  [83264/90240]\n",
      "loss: 0.353070  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.565351 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.391955  [   64/90240]\n",
      "loss: 0.374672  [ 6464/90240]\n",
      "loss: 0.517262  [12864/90240]\n",
      "loss: 0.510185  [19264/90240]\n",
      "loss: 0.327204  [25664/90240]\n",
      "loss: 0.646842  [32064/90240]\n",
      "loss: 0.355080  [38464/90240]\n",
      "loss: 0.616567  [44864/90240]\n",
      "loss: 0.413408  [51264/90240]\n",
      "loss: 0.390303  [57664/90240]\n",
      "loss: 0.343517  [64064/90240]\n",
      "loss: 0.485969  [70464/90240]\n",
      "loss: 0.329267  [76864/90240]\n",
      "loss: 0.447217  [83264/90240]\n",
      "loss: 0.459838  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.571419 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.673085  [   64/90240]\n",
      "loss: 0.629377  [ 6464/90240]\n",
      "loss: 0.543096  [12864/90240]\n",
      "loss: 0.599545  [19264/90240]\n",
      "loss: 0.659640  [25664/90240]\n",
      "loss: 0.458764  [32064/90240]\n",
      "loss: 0.339474  [38464/90240]\n",
      "loss: 0.542925  [44864/90240]\n",
      "loss: 0.486865  [51264/90240]\n",
      "loss: 0.933418  [57664/90240]\n",
      "loss: 0.451637  [64064/90240]\n",
      "loss: 0.532032  [70464/90240]\n",
      "loss: 0.438970  [76864/90240]\n",
      "loss: 0.461079  [83264/90240]\n",
      "loss: 0.499257  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.521498 \n",
      "\n",
      "Done!\n",
      "model : m13\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.845839  [   64/90240]\n",
      "loss: 3.860336  [ 6464/90240]\n",
      "loss: 3.857396  [12864/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.843036  [19264/90240]\n",
      "loss: 3.836754  [25664/90240]\n",
      "loss: 3.848691  [32064/90240]\n",
      "loss: 3.850735  [38464/90240]\n",
      "loss: 3.840464  [44864/90240]\n",
      "loss: 3.844495  [51264/90240]\n",
      "loss: 3.838019  [57664/90240]\n",
      "loss: 3.832778  [64064/90240]\n",
      "loss: 3.831410  [70464/90240]\n",
      "loss: 3.814784  [76864/90240]\n",
      "loss: 3.815760  [83264/90240]\n",
      "loss: 3.781234  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 14.3%, Avg loss: 3.732850 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.725870  [   64/90240]\n",
      "loss: 3.428892  [ 6464/90240]\n",
      "loss: 2.239135  [12864/90240]\n",
      "loss: 1.735730  [19264/90240]\n",
      "loss: 1.591455  [25664/90240]\n",
      "loss: 1.475150  [32064/90240]\n",
      "loss: 1.364905  [38464/90240]\n",
      "loss: 1.186426  [44864/90240]\n",
      "loss: 1.100769  [51264/90240]\n",
      "loss: 1.084319  [57664/90240]\n",
      "loss: 0.994866  [64064/90240]\n",
      "loss: 1.258549  [70464/90240]\n",
      "loss: 0.738833  [76864/90240]\n",
      "loss: 1.281558  [83264/90240]\n",
      "loss: 1.044710  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 1.003549 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.798957  [   64/90240]\n",
      "loss: 0.795506  [ 6464/90240]\n",
      "loss: 0.799853  [12864/90240]\n",
      "loss: 0.965867  [19264/90240]\n",
      "loss: 1.000959  [25664/90240]\n",
      "loss: 0.941193  [32064/90240]\n",
      "loss: 0.806619  [38464/90240]\n",
      "loss: 1.133917  [44864/90240]\n",
      "loss: 1.022194  [51264/90240]\n",
      "loss: 0.935630  [57664/90240]\n",
      "loss: 0.793146  [64064/90240]\n",
      "loss: 1.095075  [70464/90240]\n",
      "loss: 0.609245  [76864/90240]\n",
      "loss: 0.800148  [83264/90240]\n",
      "loss: 0.541045  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.802773 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.623021  [   64/90240]\n",
      "loss: 0.465213  [ 6464/90240]\n",
      "loss: 1.058239  [12864/90240]\n",
      "loss: 0.677301  [19264/90240]\n",
      "loss: 0.596628  [25664/90240]\n",
      "loss: 0.688737  [32064/90240]\n",
      "loss: 0.653530  [38464/90240]\n",
      "loss: 0.962939  [44864/90240]\n",
      "loss: 0.619078  [51264/90240]\n",
      "loss: 0.654949  [57664/90240]\n",
      "loss: 0.575570  [64064/90240]\n",
      "loss: 0.628733  [70464/90240]\n",
      "loss: 0.742620  [76864/90240]\n",
      "loss: 0.381329  [83264/90240]\n",
      "loss: 0.574061  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.721698 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.502182  [   64/90240]\n",
      "loss: 0.554572  [ 6464/90240]\n",
      "loss: 0.731557  [12864/90240]\n",
      "loss: 0.463031  [19264/90240]\n",
      "loss: 0.437596  [25664/90240]\n",
      "loss: 0.697417  [32064/90240]\n",
      "loss: 0.691067  [38464/90240]\n",
      "loss: 0.637722  [44864/90240]\n",
      "loss: 0.475428  [51264/90240]\n",
      "loss: 0.610123  [57664/90240]\n",
      "loss: 0.861171  [64064/90240]\n",
      "loss: 0.428433  [70464/90240]\n",
      "loss: 0.730636  [76864/90240]\n",
      "loss: 0.542575  [83264/90240]\n",
      "loss: 0.793099  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.653096 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.486223  [   64/90240]\n",
      "loss: 0.569587  [ 6464/90240]\n",
      "loss: 0.627964  [12864/90240]\n",
      "loss: 0.286596  [19264/90240]\n",
      "loss: 0.647599  [25664/90240]\n",
      "loss: 0.740561  [32064/90240]\n",
      "loss: 0.361077  [38464/90240]\n",
      "loss: 0.649459  [44864/90240]\n",
      "loss: 0.356378  [51264/90240]\n",
      "loss: 0.500114  [57664/90240]\n",
      "loss: 0.479168  [64064/90240]\n",
      "loss: 0.803566  [70464/90240]\n",
      "loss: 0.656916  [76864/90240]\n",
      "loss: 0.632196  [83264/90240]\n",
      "loss: 0.686338  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.615734 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.744417  [   64/90240]\n",
      "loss: 0.436084  [ 6464/90240]\n",
      "loss: 0.619209  [12864/90240]\n",
      "loss: 0.684704  [19264/90240]\n",
      "loss: 0.589518  [25664/90240]\n",
      "loss: 0.524210  [32064/90240]\n",
      "loss: 0.429561  [38464/90240]\n",
      "loss: 0.423332  [44864/90240]\n",
      "loss: 0.492526  [51264/90240]\n",
      "loss: 0.637051  [57664/90240]\n",
      "loss: 0.758910  [64064/90240]\n",
      "loss: 0.549157  [70464/90240]\n",
      "loss: 0.654632  [76864/90240]\n",
      "loss: 0.514106  [83264/90240]\n",
      "loss: 0.591756  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.608893 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.550298  [   64/90240]\n",
      "loss: 0.749731  [ 6464/90240]\n",
      "loss: 0.511237  [12864/90240]\n",
      "loss: 0.572991  [19264/90240]\n",
      "loss: 0.582944  [25664/90240]\n",
      "loss: 0.684723  [32064/90240]\n",
      "loss: 0.431598  [38464/90240]\n",
      "loss: 0.648484  [44864/90240]\n",
      "loss: 0.601188  [51264/90240]\n",
      "loss: 0.474982  [57664/90240]\n",
      "loss: 0.567791  [64064/90240]\n",
      "loss: 0.616826  [70464/90240]\n",
      "loss: 0.758744  [76864/90240]\n",
      "loss: 0.496019  [83264/90240]\n",
      "loss: 0.794087  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.589285 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.501504  [   64/90240]\n",
      "loss: 0.537832  [ 6464/90240]\n",
      "loss: 0.546109  [12864/90240]\n",
      "loss: 0.403863  [19264/90240]\n",
      "loss: 0.553765  [25664/90240]\n",
      "loss: 0.380707  [32064/90240]\n",
      "loss: 0.444911  [38464/90240]\n",
      "loss: 0.613049  [44864/90240]\n",
      "loss: 0.587701  [51264/90240]\n",
      "loss: 0.865655  [57664/90240]\n",
      "loss: 0.481211  [64064/90240]\n",
      "loss: 0.642311  [70464/90240]\n",
      "loss: 0.966147  [76864/90240]\n",
      "loss: 0.438773  [83264/90240]\n",
      "loss: 0.344093  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.559035 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.406290  [   64/90240]\n",
      "loss: 0.542595  [ 6464/90240]\n",
      "loss: 0.448959  [12864/90240]\n",
      "loss: 0.420564  [19264/90240]\n",
      "loss: 0.279476  [25664/90240]\n",
      "loss: 0.543733  [32064/90240]\n",
      "loss: 0.559711  [38464/90240]\n",
      "loss: 0.824269  [44864/90240]\n",
      "loss: 0.530120  [51264/90240]\n",
      "loss: 0.355898  [57664/90240]\n",
      "loss: 0.376330  [64064/90240]\n",
      "loss: 0.408664  [70464/90240]\n",
      "loss: 0.517329  [76864/90240]\n",
      "loss: 0.428238  [83264/90240]\n",
      "loss: 0.389212  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.554116 \n",
      "\n",
      "Done!\n",
      "model : m14\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=20000, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.942557  [   64/90240]\n",
      "loss: 4.085175  [ 6464/90240]\n",
      "loss: 4.021369  [12864/90240]\n",
      "loss: 3.970240  [19264/90240]\n",
      "loss: 3.910432  [25664/90240]\n",
      "loss: 3.918265  [32064/90240]\n",
      "loss: 3.902928  [38464/90240]\n",
      "loss: 3.898854  [44864/90240]\n",
      "loss: 3.875843  [51264/90240]\n",
      "loss: 3.884257  [57664/90240]\n",
      "loss: 3.927647  [64064/90240]\n",
      "loss: 3.914185  [70464/90240]\n",
      "loss: 3.910277  [76864/90240]\n",
      "loss: 3.929954  [83264/90240]\n",
      "loss: 3.934214  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 3.892979 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.847138  [   64/90240]\n",
      "loss: 3.889646  [ 6464/90240]\n",
      "loss: 3.904845  [12864/90240]\n",
      "loss: 3.923099  [19264/90240]\n",
      "loss: 3.966223  [25664/90240]\n",
      "loss: 3.899392  [32064/90240]\n",
      "loss: 3.888811  [38464/90240]\n",
      "loss: 3.876278  [44864/90240]\n",
      "loss: 3.842610  [51264/90240]\n",
      "loss: 3.852028  [57664/90240]\n",
      "loss: 3.885314  [64064/90240]\n",
      "loss: 3.896884  [70464/90240]\n",
      "loss: 3.860635  [76864/90240]\n",
      "loss: 3.868315  [83264/90240]\n",
      "loss: 3.861224  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.866519 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.900216  [   64/90240]\n",
      "loss: 3.833181  [ 6464/90240]\n",
      "loss: 3.874926  [12864/90240]\n",
      "loss: 3.873927  [19264/90240]\n",
      "loss: 3.852164  [25664/90240]\n",
      "loss: 3.857725  [32064/90240]\n",
      "loss: 3.864024  [38464/90240]\n",
      "loss: 3.870579  [44864/90240]\n",
      "loss: 3.867198  [51264/90240]\n",
      "loss: 3.875648  [57664/90240]\n",
      "loss: 3.865783  [64064/90240]\n",
      "loss: 3.861720  [70464/90240]\n",
      "loss: 3.899499  [76864/90240]\n",
      "loss: 3.849709  [83264/90240]\n",
      "loss: 3.814218  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 3.861828 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.867407  [   64/90240]\n",
      "loss: 3.862980  [ 6464/90240]\n",
      "loss: 3.898361  [12864/90240]\n",
      "loss: 3.839473  [19264/90240]\n",
      "loss: 3.845674  [25664/90240]\n",
      "loss: 3.908133  [32064/90240]\n",
      "loss: 3.851188  [38464/90240]\n",
      "loss: 3.855301  [44864/90240]\n",
      "loss: 3.898542  [51264/90240]\n",
      "loss: 3.874440  [57664/90240]\n",
      "loss: 3.868707  [64064/90240]\n",
      "loss: 3.851559  [70464/90240]\n",
      "loss: 3.851297  [76864/90240]\n",
      "loss: 3.838334  [83264/90240]\n",
      "loss: 3.859737  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.856640 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.842861  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.852610  [ 6464/90240]\n",
      "loss: 3.851996  [12864/90240]\n",
      "loss: 3.866667  [19264/90240]\n",
      "loss: 3.850793  [25664/90240]\n",
      "loss: 3.824185  [32064/90240]\n",
      "loss: 3.852479  [38464/90240]\n",
      "loss: 3.878209  [44864/90240]\n",
      "loss: 3.847456  [51264/90240]\n",
      "loss: 3.812359  [57664/90240]\n",
      "loss: 3.833672  [64064/90240]\n",
      "loss: 3.846052  [70464/90240]\n",
      "loss: 3.858180  [76864/90240]\n",
      "loss: 3.840712  [83264/90240]\n",
      "loss: 3.846241  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 3.845762 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.848810  [   64/90240]\n",
      "loss: 3.851531  [ 6464/90240]\n",
      "loss: 3.869916  [12864/90240]\n",
      "loss: 3.832977  [19264/90240]\n",
      "loss: 3.845240  [25664/90240]\n",
      "loss: 3.844140  [32064/90240]\n",
      "loss: 3.842181  [38464/90240]\n",
      "loss: 3.831448  [44864/90240]\n",
      "loss: 3.832907  [51264/90240]\n",
      "loss: 3.846127  [57664/90240]\n",
      "loss: 3.838003  [64064/90240]\n",
      "loss: 3.825027  [70464/90240]\n",
      "loss: 3.853901  [76864/90240]\n",
      "loss: 3.826537  [83264/90240]\n",
      "loss: 3.825386  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 3.833886 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.842602  [   64/90240]\n",
      "loss: 3.838561  [ 6464/90240]\n",
      "loss: 3.824589  [12864/90240]\n",
      "loss: 3.850081  [19264/90240]\n",
      "loss: 3.814205  [25664/90240]\n",
      "loss: 3.829942  [32064/90240]\n",
      "loss: 3.827838  [38464/90240]\n",
      "loss: 3.802580  [44864/90240]\n",
      "loss: 3.820100  [51264/90240]\n",
      "loss: 3.801826  [57664/90240]\n",
      "loss: 3.813009  [64064/90240]\n",
      "loss: 3.783054  [70464/90240]\n",
      "loss: 3.799247  [76864/90240]\n",
      "loss: 3.785568  [83264/90240]\n",
      "loss: 3.781101  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 11.5%, Avg loss: 3.795013 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.782729  [   64/90240]\n",
      "loss: 3.763275  [ 6464/90240]\n",
      "loss: 3.766037  [12864/90240]\n",
      "loss: 3.769414  [19264/90240]\n",
      "loss: 3.768872  [25664/90240]\n",
      "loss: 3.749846  [32064/90240]\n",
      "loss: 3.766631  [38464/90240]\n",
      "loss: 3.748047  [44864/90240]\n",
      "loss: 3.764413  [51264/90240]\n",
      "loss: 3.727066  [57664/90240]\n",
      "loss: 3.684896  [64064/90240]\n",
      "loss: 3.706244  [70464/90240]\n",
      "loss: 3.662544  [76864/90240]\n",
      "loss: 3.660582  [83264/90240]\n",
      "loss: 3.622550  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 22.5%, Avg loss: 3.613904 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.652134  [   64/90240]\n",
      "loss: 3.564404  [ 6464/90240]\n",
      "loss: 3.481576  [12864/90240]\n",
      "loss: 3.446064  [19264/90240]\n",
      "loss: 3.365688  [25664/90240]\n",
      "loss: 3.307282  [32064/90240]\n",
      "loss: 3.330129  [38464/90240]\n",
      "loss: 2.978418  [44864/90240]\n",
      "loss: 2.790303  [51264/90240]\n",
      "loss: 2.670817  [57664/90240]\n",
      "loss: 2.633521  [64064/90240]\n",
      "loss: 2.170868  [70464/90240]\n",
      "loss: 2.119976  [76864/90240]\n",
      "loss: 1.971092  [83264/90240]\n",
      "loss: 1.992545  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 53.7%, Avg loss: 1.817678 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.817916  [   64/90240]\n",
      "loss: 1.816638  [ 6464/90240]\n",
      "loss: 1.497723  [12864/90240]\n",
      "loss: 1.658902  [19264/90240]\n",
      "loss: 1.494176  [25664/90240]\n",
      "loss: 1.316890  [32064/90240]\n",
      "loss: 1.452466  [38464/90240]\n",
      "loss: 1.527781  [44864/90240]\n",
      "loss: 1.209305  [51264/90240]\n",
      "loss: 1.396927  [57664/90240]\n",
      "loss: 1.360901  [64064/90240]\n",
      "loss: 1.394006  [70464/90240]\n",
      "loss: 1.223337  [76864/90240]\n",
      "loss: 1.569286  [83264/90240]\n",
      "loss: 1.288808  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.371416 \n",
      "\n",
      "Done!\n",
      "model : m14\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.834815  [   64/90240]\n",
      "loss: 3.858732  [ 6464/90240]\n",
      "loss: 3.848351  [12864/90240]\n",
      "loss: 3.850842  [19264/90240]\n",
      "loss: 3.848249  [25664/90240]\n",
      "loss: 3.852182  [32064/90240]\n",
      "loss: 3.852090  [38464/90240]\n",
      "loss: 3.855699  [44864/90240]\n",
      "loss: 3.845828  [51264/90240]\n",
      "loss: 3.842500  [57664/90240]\n",
      "loss: 3.853325  [64064/90240]\n",
      "loss: 3.851681  [70464/90240]\n",
      "loss: 3.848201  [76864/90240]\n",
      "loss: 3.852783  [83264/90240]\n",
      "loss: 3.848910  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850659 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.848835  [   64/90240]\n",
      "loss: 3.845892  [ 6464/90240]\n",
      "loss: 3.848847  [12864/90240]\n",
      "loss: 3.851127  [19264/90240]\n",
      "loss: 3.850857  [25664/90240]\n",
      "loss: 3.845936  [32064/90240]\n",
      "loss: 3.854070  [38464/90240]\n",
      "loss: 3.849977  [44864/90240]\n",
      "loss: 3.853630  [51264/90240]\n",
      "loss: 3.839400  [57664/90240]\n",
      "loss: 3.849283  [64064/90240]\n",
      "loss: 3.848187  [70464/90240]\n",
      "loss: 3.851479  [76864/90240]\n",
      "loss: 3.851168  [83264/90240]\n",
      "loss: 3.848047  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850622 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.849720  [   64/90240]\n",
      "loss: 3.847493  [ 6464/90240]\n",
      "loss: 3.843175  [12864/90240]\n",
      "loss: 3.848421  [19264/90240]\n",
      "loss: 3.855491  [25664/90240]\n",
      "loss: 3.851255  [32064/90240]\n",
      "loss: 3.847582  [38464/90240]\n",
      "loss: 3.851122  [44864/90240]\n",
      "loss: 3.845720  [51264/90240]\n",
      "loss: 3.852182  [57664/90240]\n",
      "loss: 3.851971  [64064/90240]\n",
      "loss: 3.856583  [70464/90240]\n",
      "loss: 3.850667  [76864/90240]\n",
      "loss: 3.848907  [83264/90240]\n",
      "loss: 3.846718  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850626 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.845479  [   64/90240]\n",
      "loss: 3.851783  [ 6464/90240]\n",
      "loss: 3.847791  [12864/90240]\n",
      "loss: 3.846542  [19264/90240]\n",
      "loss: 3.851163  [25664/90240]\n",
      "loss: 3.851505  [32064/90240]\n",
      "loss: 3.851960  [38464/90240]\n",
      "loss: 3.852258  [44864/90240]\n",
      "loss: 3.849453  [51264/90240]\n",
      "loss: 3.848962  [57664/90240]\n",
      "loss: 3.851022  [64064/90240]\n",
      "loss: 3.849053  [70464/90240]\n",
      "loss: 3.851335  [76864/90240]\n",
      "loss: 3.850839  [83264/90240]\n",
      "loss: 3.853435  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850612 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.848361  [   64/90240]\n",
      "loss: 3.849582  [ 6464/90240]\n",
      "loss: 3.847548  [12864/90240]\n",
      "loss: 3.852494  [19264/90240]\n",
      "loss: 3.855577  [25664/90240]\n",
      "loss: 3.853084  [32064/90240]\n",
      "loss: 3.850701  [38464/90240]\n",
      "loss: 3.850770  [44864/90240]\n",
      "loss: 3.847509  [51264/90240]\n",
      "loss: 3.848540  [57664/90240]\n",
      "loss: 3.846555  [64064/90240]\n",
      "loss: 3.849456  [70464/90240]\n",
      "loss: 3.846923  [76864/90240]\n",
      "loss: 3.854190  [83264/90240]\n",
      "loss: 3.847031  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850606 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.845852  [   64/90240]\n",
      "loss: 3.848698  [ 6464/90240]\n",
      "loss: 3.849647  [12864/90240]\n",
      "loss: 3.850135  [19264/90240]\n",
      "loss: 3.849457  [25664/90240]\n",
      "loss: 3.849601  [32064/90240]\n",
      "loss: 3.848732  [38464/90240]\n",
      "loss: 3.852042  [44864/90240]\n",
      "loss: 3.848456  [51264/90240]\n",
      "loss: 3.849853  [57664/90240]\n",
      "loss: 3.852796  [64064/90240]\n",
      "loss: 3.850493  [70464/90240]\n",
      "loss: 3.851839  [76864/90240]\n",
      "loss: 3.849990  [83264/90240]\n",
      "loss: 3.851245  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850612 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.854379  [   64/90240]\n",
      "loss: 3.852761  [ 6464/90240]\n",
      "loss: 3.847631  [12864/90240]\n",
      "loss: 3.850447  [19264/90240]\n",
      "loss: 3.850337  [25664/90240]\n",
      "loss: 3.849667  [32064/90240]\n",
      "loss: 3.851653  [38464/90240]\n",
      "loss: 3.847964  [44864/90240]\n",
      "loss: 3.849066  [51264/90240]\n",
      "loss: 3.850535  [57664/90240]\n",
      "loss: 3.849485  [64064/90240]\n",
      "loss: 3.850576  [70464/90240]\n",
      "loss: 3.851162  [76864/90240]\n",
      "loss: 3.849219  [83264/90240]\n",
      "loss: 3.850045  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850626 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.850390  [   64/90240]\n",
      "loss: 3.848444  [ 6464/90240]\n",
      "loss: 3.851163  [12864/90240]\n",
      "loss: 3.850518  [19264/90240]\n",
      "loss: 3.850770  [25664/90240]\n",
      "loss: 3.850605  [32064/90240]\n",
      "loss: 3.852159  [38464/90240]\n",
      "loss: 3.850094  [44864/90240]\n",
      "loss: 3.851496  [51264/90240]\n",
      "loss: 3.849673  [57664/90240]\n",
      "loss: 3.852979  [64064/90240]\n",
      "loss: 3.848833  [70464/90240]\n",
      "loss: 3.847843  [76864/90240]\n",
      "loss: 3.852609  [83264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.853153  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850636 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.849287  [   64/90240]\n",
      "loss: 3.848103  [ 6464/90240]\n",
      "loss: 3.848505  [12864/90240]\n",
      "loss: 3.849607  [19264/90240]\n",
      "loss: 3.849761  [25664/90240]\n",
      "loss: 3.848536  [32064/90240]\n",
      "loss: 3.847403  [38464/90240]\n",
      "loss: 3.851289  [44864/90240]\n",
      "loss: 3.850852  [51264/90240]\n",
      "loss: 3.849901  [57664/90240]\n",
      "loss: 3.849787  [64064/90240]\n",
      "loss: 3.850382  [70464/90240]\n",
      "loss: 3.851377  [76864/90240]\n",
      "loss: 3.852283  [83264/90240]\n",
      "loss: 3.850726  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850649 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.851122  [   64/90240]\n",
      "loss: 3.848247  [ 6464/90240]\n",
      "loss: 3.853029  [12864/90240]\n",
      "loss: 3.851061  [19264/90240]\n",
      "loss: 3.851527  [25664/90240]\n",
      "loss: 3.848632  [32064/90240]\n",
      "loss: 3.848756  [38464/90240]\n",
      "loss: 3.847457  [44864/90240]\n",
      "loss: 3.849188  [51264/90240]\n",
      "loss: 3.849376  [57664/90240]\n",
      "loss: 3.851318  [64064/90240]\n",
      "loss: 3.847605  [70464/90240]\n",
      "loss: 3.851488  [76864/90240]\n",
      "loss: 3.852185  [83264/90240]\n",
      "loss: 3.850117  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850660 \n",
      "\n",
      "Done!\n",
      "model : m14\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.861245  [   64/90240]\n",
      "loss: 3.853889  [ 6464/90240]\n",
      "loss: 3.847486  [12864/90240]\n",
      "loss: 3.855787  [19264/90240]\n",
      "loss: 3.858010  [25664/90240]\n",
      "loss: 3.846756  [32064/90240]\n",
      "loss: 3.844164  [38464/90240]\n",
      "loss: 3.858288  [44864/90240]\n",
      "loss: 3.849499  [51264/90240]\n",
      "loss: 3.849218  [57664/90240]\n",
      "loss: 3.853998  [64064/90240]\n",
      "loss: 3.856402  [70464/90240]\n",
      "loss: 3.860641  [76864/90240]\n",
      "loss: 3.852424  [83264/90240]\n",
      "loss: 3.849645  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850814 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.847455  [   64/90240]\n",
      "loss: 3.850982  [ 6464/90240]\n",
      "loss: 3.853999  [12864/90240]\n",
      "loss: 3.852892  [19264/90240]\n",
      "loss: 3.850885  [25664/90240]\n",
      "loss: 3.846669  [32064/90240]\n",
      "loss: 3.849037  [38464/90240]\n",
      "loss: 3.845978  [44864/90240]\n",
      "loss: 3.851146  [51264/90240]\n",
      "loss: 3.841912  [57664/90240]\n",
      "loss: 3.850050  [64064/90240]\n",
      "loss: 3.848571  [70464/90240]\n",
      "loss: 3.847883  [76864/90240]\n",
      "loss: 3.851634  [83264/90240]\n",
      "loss: 3.848922  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850877 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.850837  [   64/90240]\n",
      "loss: 3.853365  [ 6464/90240]\n",
      "loss: 3.856752  [12864/90240]\n",
      "loss: 3.851404  [19264/90240]\n",
      "loss: 3.848073  [25664/90240]\n",
      "loss: 3.849177  [32064/90240]\n",
      "loss: 3.848883  [38464/90240]\n",
      "loss: 3.852342  [44864/90240]\n",
      "loss: 3.847996  [51264/90240]\n",
      "loss: 3.850276  [57664/90240]\n",
      "loss: 3.848487  [64064/90240]\n",
      "loss: 3.848091  [70464/90240]\n",
      "loss: 3.846644  [76864/90240]\n",
      "loss: 3.850309  [83264/90240]\n",
      "loss: 3.852010  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 3.850669 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.850629  [   64/90240]\n",
      "loss: 3.852726  [ 6464/90240]\n",
      "loss: 3.852720  [12864/90240]\n",
      "loss: 3.852260  [19264/90240]\n",
      "loss: 3.853082  [25664/90240]\n",
      "loss: 3.851933  [32064/90240]\n",
      "loss: 3.851155  [38464/90240]\n",
      "loss: 3.848084  [44864/90240]\n",
      "loss: 3.844904  [51264/90240]\n",
      "loss: 3.852146  [57664/90240]\n",
      "loss: 3.850123  [64064/90240]\n",
      "loss: 3.851842  [70464/90240]\n",
      "loss: 3.852334  [76864/90240]\n",
      "loss: 3.850595  [83264/90240]\n",
      "loss: 3.851018  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 3.850602 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.849646  [   64/90240]\n",
      "loss: 3.848728  [ 6464/90240]\n",
      "loss: 3.849938  [12864/90240]\n",
      "loss: 3.851102  [19264/90240]\n",
      "loss: 3.854272  [25664/90240]\n",
      "loss: 3.847274  [32064/90240]\n",
      "loss: 3.852358  [38464/90240]\n",
      "loss: 3.851020  [44864/90240]\n",
      "loss: 3.851691  [51264/90240]\n",
      "loss: 3.845427  [57664/90240]\n",
      "loss: 3.849348  [64064/90240]\n",
      "loss: 3.851793  [70464/90240]\n",
      "loss: 3.846442  [76864/90240]\n",
      "loss: 3.853729  [83264/90240]\n",
      "loss: 3.848965  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850746 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.849772  [   64/90240]\n",
      "loss: 3.849641  [ 6464/90240]\n",
      "loss: 3.852587  [12864/90240]\n",
      "loss: 3.850215  [19264/90240]\n",
      "loss: 3.846188  [25664/90240]\n",
      "loss: 3.852310  [32064/90240]\n",
      "loss: 3.851833  [38464/90240]\n",
      "loss: 3.848200  [44864/90240]\n",
      "loss: 3.850390  [51264/90240]\n",
      "loss: 3.848842  [57664/90240]\n",
      "loss: 3.851585  [64064/90240]\n",
      "loss: 3.850688  [70464/90240]\n",
      "loss: 3.852858  [76864/90240]\n",
      "loss: 3.850050  [83264/90240]\n",
      "loss: 3.849186  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850689 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.850915  [   64/90240]\n",
      "loss: 3.849331  [ 6464/90240]\n",
      "loss: 3.850076  [12864/90240]\n",
      "loss: 3.847238  [19264/90240]\n",
      "loss: 3.853052  [25664/90240]\n",
      "loss: 3.851634  [32064/90240]\n",
      "loss: 3.847233  [38464/90240]\n",
      "loss: 3.852525  [44864/90240]\n",
      "loss: 3.850086  [51264/90240]\n",
      "loss: 3.848574  [57664/90240]\n",
      "loss: 3.851394  [64064/90240]\n",
      "loss: 3.851824  [70464/90240]\n",
      "loss: 3.849879  [76864/90240]\n",
      "loss: 3.847446  [83264/90240]\n",
      "loss: 3.848768  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850735 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.852078  [   64/90240]\n",
      "loss: 3.848871  [ 6464/90240]\n",
      "loss: 3.849601  [12864/90240]\n",
      "loss: 3.850791  [19264/90240]\n",
      "loss: 3.851762  [25664/90240]\n",
      "loss: 3.849510  [32064/90240]\n",
      "loss: 3.850795  [38464/90240]\n",
      "loss: 3.848344  [44864/90240]\n",
      "loss: 3.850148  [51264/90240]\n",
      "loss: 3.847950  [57664/90240]\n",
      "loss: 3.849532  [64064/90240]\n",
      "loss: 3.849881  [70464/90240]\n",
      "loss: 3.850134  [76864/90240]\n",
      "loss: 3.852916  [83264/90240]\n",
      "loss: 3.849431  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850663 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.848264  [   64/90240]\n",
      "loss: 3.849139  [ 6464/90240]\n",
      "loss: 3.850360  [12864/90240]\n",
      "loss: 3.850591  [19264/90240]\n",
      "loss: 3.850364  [25664/90240]\n",
      "loss: 3.847892  [32064/90240]\n",
      "loss: 3.846129  [38464/90240]\n",
      "loss: 3.847707  [44864/90240]\n",
      "loss: 3.852409  [51264/90240]\n",
      "loss: 3.849332  [57664/90240]\n",
      "loss: 3.846787  [64064/90240]\n",
      "loss: 3.850360  [70464/90240]\n",
      "loss: 3.854857  [76864/90240]\n",
      "loss: 3.852987  [83264/90240]\n",
      "loss: 3.850671  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850778 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.845200  [   64/90240]\n",
      "loss: 3.852188  [ 6464/90240]\n",
      "loss: 3.850051  [12864/90240]\n",
      "loss: 3.850747  [19264/90240]\n",
      "loss: 3.849632  [25664/90240]\n",
      "loss: 3.849120  [32064/90240]\n",
      "loss: 3.848121  [38464/90240]\n",
      "loss: 3.850121  [44864/90240]\n",
      "loss: 3.849528  [51264/90240]\n",
      "loss: 3.852603  [57664/90240]\n",
      "loss: 3.847843  [64064/90240]\n",
      "loss: 3.851591  [70464/90240]\n",
      "loss: 3.850137  [76864/90240]\n",
      "loss: 3.855546  [83264/90240]\n",
      "loss: 3.851177  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850820 \n",
      "\n",
      "Done!\n",
      "model : m15\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=20000, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.009338  [   64/90240]\n",
      "loss: 1.151587  [ 6464/90240]\n",
      "loss: 0.569602  [12864/90240]\n",
      "loss: 0.759805  [19264/90240]\n",
      "loss: 0.869315  [25664/90240]\n",
      "loss: 0.676801  [32064/90240]\n",
      "loss: 0.901819  [38464/90240]\n",
      "loss: 0.585554  [44864/90240]\n",
      "loss: 0.367280  [51264/90240]\n",
      "loss: 0.701812  [57664/90240]\n",
      "loss: 0.646094  [64064/90240]\n",
      "loss: 0.462049  [70464/90240]\n",
      "loss: 0.715367  [76864/90240]\n",
      "loss: 0.381023  [83264/90240]\n",
      "loss: 0.418925  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.510918 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.407019  [   64/90240]\n",
      "loss: 0.390865  [ 6464/90240]\n",
      "loss: 0.398792  [12864/90240]\n",
      "loss: 0.446365  [19264/90240]\n",
      "loss: 0.609355  [25664/90240]\n",
      "loss: 0.379677  [32064/90240]\n",
      "loss: 0.643088  [38464/90240]\n",
      "loss: 0.395764  [44864/90240]\n",
      "loss: 0.411552  [51264/90240]\n",
      "loss: 0.343644  [57664/90240]\n",
      "loss: 0.406743  [64064/90240]\n",
      "loss: 0.467659  [70464/90240]\n",
      "loss: 0.446291  [76864/90240]\n",
      "loss: 0.467835  [83264/90240]\n",
      "loss: 0.535244  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.463036 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.355662  [   64/90240]\n",
      "loss: 0.493854  [ 6464/90240]\n",
      "loss: 0.406002  [12864/90240]\n",
      "loss: 0.274430  [19264/90240]\n",
      "loss: 0.844801  [25664/90240]\n",
      "loss: 0.506796  [32064/90240]\n",
      "loss: 0.384693  [38464/90240]\n",
      "loss: 0.545703  [44864/90240]\n",
      "loss: 0.484844  [51264/90240]\n",
      "loss: 0.387800  [57664/90240]\n",
      "loss: 0.603239  [64064/90240]\n",
      "loss: 0.593597  [70464/90240]\n",
      "loss: 0.335366  [76864/90240]\n",
      "loss: 0.411834  [83264/90240]\n",
      "loss: 0.339745  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.430663 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.455733  [   64/90240]\n",
      "loss: 0.367561  [ 6464/90240]\n",
      "loss: 0.338092  [12864/90240]\n",
      "loss: 0.573992  [19264/90240]\n",
      "loss: 0.485962  [25664/90240]\n",
      "loss: 0.294479  [32064/90240]\n",
      "loss: 0.371266  [38464/90240]\n",
      "loss: 0.537415  [44864/90240]\n",
      "loss: 0.468051  [51264/90240]\n",
      "loss: 0.337466  [57664/90240]\n",
      "loss: 0.405713  [64064/90240]\n",
      "loss: 0.343818  [70464/90240]\n",
      "loss: 0.414613  [76864/90240]\n",
      "loss: 0.288505  [83264/90240]\n",
      "loss: 0.371243  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.434894 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.334822  [   64/90240]\n",
      "loss: 0.190590  [ 6464/90240]\n",
      "loss: 0.339758  [12864/90240]\n",
      "loss: 0.274865  [19264/90240]\n",
      "loss: 0.241132  [25664/90240]\n",
      "loss: 0.299979  [32064/90240]\n",
      "loss: 0.384767  [38464/90240]\n",
      "loss: 0.321541  [44864/90240]\n",
      "loss: 0.190292  [51264/90240]\n",
      "loss: 0.310851  [57664/90240]\n",
      "loss: 0.441393  [64064/90240]\n",
      "loss: 0.400173  [70464/90240]\n",
      "loss: 0.547100  [76864/90240]\n",
      "loss: 0.347951  [83264/90240]\n",
      "loss: 0.425428  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.422117 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.241484  [   64/90240]\n",
      "loss: 0.269554  [ 6464/90240]\n",
      "loss: 0.681350  [12864/90240]\n",
      "loss: 0.274094  [19264/90240]\n",
      "loss: 0.362672  [25664/90240]\n",
      "loss: 0.253806  [32064/90240]\n",
      "loss: 0.255721  [38464/90240]\n",
      "loss: 0.250886  [44864/90240]\n",
      "loss: 0.288648  [51264/90240]\n",
      "loss: 0.281503  [57664/90240]\n",
      "loss: 0.376346  [64064/90240]\n",
      "loss: 0.252113  [70464/90240]\n",
      "loss: 0.554949  [76864/90240]\n",
      "loss: 0.325614  [83264/90240]\n",
      "loss: 0.225531  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.444400 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.333528  [   64/90240]\n",
      "loss: 0.349584  [ 6464/90240]\n",
      "loss: 0.277707  [12864/90240]\n",
      "loss: 0.275518  [19264/90240]\n",
      "loss: 0.450311  [25664/90240]\n",
      "loss: 0.238791  [32064/90240]\n",
      "loss: 0.162633  [38464/90240]\n",
      "loss: 0.338947  [44864/90240]\n",
      "loss: 0.197168  [51264/90240]\n",
      "loss: 0.331063  [57664/90240]\n",
      "loss: 0.399649  [64064/90240]\n",
      "loss: 0.300997  [70464/90240]\n",
      "loss: 0.332709  [76864/90240]\n",
      "loss: 0.324430  [83264/90240]\n",
      "loss: 0.261382  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.405018 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.204246  [   64/90240]\n",
      "loss: 0.440402  [ 6464/90240]\n",
      "loss: 0.249895  [12864/90240]\n",
      "loss: 0.279081  [19264/90240]\n",
      "loss: 0.345310  [25664/90240]\n",
      "loss: 0.259127  [32064/90240]\n",
      "loss: 0.298885  [38464/90240]\n",
      "loss: 0.187471  [44864/90240]\n",
      "loss: 0.323456  [51264/90240]\n",
      "loss: 0.211816  [57664/90240]\n",
      "loss: 0.254852  [64064/90240]\n",
      "loss: 0.210436  [70464/90240]\n",
      "loss: 0.462627  [76864/90240]\n",
      "loss: 0.314378  [83264/90240]\n",
      "loss: 0.205206  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.412575 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.234261  [   64/90240]\n",
      "loss: 0.484027  [ 6464/90240]\n",
      "loss: 0.224195  [12864/90240]\n",
      "loss: 0.216479  [19264/90240]\n",
      "loss: 0.281891  [25664/90240]\n",
      "loss: 0.194791  [32064/90240]\n",
      "loss: 0.283330  [38464/90240]\n",
      "loss: 0.211530  [44864/90240]\n",
      "loss: 0.242700  [51264/90240]\n",
      "loss: 0.138386  [57664/90240]\n",
      "loss: 0.245522  [64064/90240]\n",
      "loss: 0.124386  [70464/90240]\n",
      "loss: 0.220479  [76864/90240]\n",
      "loss: 0.242539  [83264/90240]\n",
      "loss: 0.300271  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.418928 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.443079  [   64/90240]\n",
      "loss: 0.233985  [ 6464/90240]\n",
      "loss: 0.300613  [12864/90240]\n",
      "loss: 0.183573  [19264/90240]\n",
      "loss: 0.237703  [25664/90240]\n",
      "loss: 0.207309  [32064/90240]\n",
      "loss: 0.393991  [38464/90240]\n",
      "loss: 0.324501  [44864/90240]\n",
      "loss: 0.503598  [51264/90240]\n",
      "loss: 0.324141  [57664/90240]\n",
      "loss: 0.165958  [64064/90240]\n",
      "loss: 0.164799  [70464/90240]\n",
      "loss: 0.200117  [76864/90240]\n",
      "loss: 0.174228  [83264/90240]\n",
      "loss: 0.164064  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.414147 \n",
      "\n",
      "Done!\n",
      "model : m15\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.831886  [   64/90240]\n",
      "loss: 1.865534  [ 6464/90240]\n",
      "loss: 1.025559  [12864/90240]\n",
      "loss: 1.238490  [19264/90240]\n",
      "loss: 0.670260  [25664/90240]\n",
      "loss: 0.730724  [32064/90240]\n",
      "loss: 0.858977  [38464/90240]\n",
      "loss: 0.510680  [44864/90240]\n",
      "loss: 0.511496  [51264/90240]\n",
      "loss: 0.574837  [57664/90240]\n",
      "loss: 0.502636  [64064/90240]\n",
      "loss: 0.777943  [70464/90240]\n",
      "loss: 0.537275  [76864/90240]\n",
      "loss: 0.614461  [83264/90240]\n",
      "loss: 0.392895  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.552979 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.428929  [   64/90240]\n",
      "loss: 0.483576  [ 6464/90240]\n",
      "loss: 0.468015  [12864/90240]\n",
      "loss: 0.540817  [19264/90240]\n",
      "loss: 0.588472  [25664/90240]\n",
      "loss: 0.473573  [32064/90240]\n",
      "loss: 0.609629  [38464/90240]\n",
      "loss: 0.550588  [44864/90240]\n",
      "loss: 0.589111  [51264/90240]\n",
      "loss: 0.582098  [57664/90240]\n",
      "loss: 0.475273  [64064/90240]\n",
      "loss: 0.745372  [70464/90240]\n",
      "loss: 0.695936  [76864/90240]\n",
      "loss: 0.359896  [83264/90240]\n",
      "loss: 0.464115  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.464327 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.264047  [   64/90240]\n",
      "loss: 0.508608  [ 6464/90240]\n",
      "loss: 0.491730  [12864/90240]\n",
      "loss: 0.293092  [19264/90240]\n",
      "loss: 0.544047  [25664/90240]\n",
      "loss: 0.561957  [32064/90240]\n",
      "loss: 0.668706  [38464/90240]\n",
      "loss: 0.409670  [44864/90240]\n",
      "loss: 0.277233  [51264/90240]\n",
      "loss: 0.357423  [57664/90240]\n",
      "loss: 0.381395  [64064/90240]\n",
      "loss: 0.205865  [70464/90240]\n",
      "loss: 0.355939  [76864/90240]\n",
      "loss: 0.325363  [83264/90240]\n",
      "loss: 0.359503  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.421024 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.270745  [   64/90240]\n",
      "loss: 0.702351  [ 6464/90240]\n",
      "loss: 0.446191  [12864/90240]\n",
      "loss: 0.331314  [19264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.228374  [25664/90240]\n",
      "loss: 0.233271  [32064/90240]\n",
      "loss: 0.309288  [38464/90240]\n",
      "loss: 0.351624  [44864/90240]\n",
      "loss: 0.366176  [51264/90240]\n",
      "loss: 0.219562  [57664/90240]\n",
      "loss: 0.340552  [64064/90240]\n",
      "loss: 0.156320  [70464/90240]\n",
      "loss: 0.585251  [76864/90240]\n",
      "loss: 0.331840  [83264/90240]\n",
      "loss: 0.326218  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.400867 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.389973  [   64/90240]\n",
      "loss: 0.350164  [ 6464/90240]\n",
      "loss: 0.205832  [12864/90240]\n",
      "loss: 0.326693  [19264/90240]\n",
      "loss: 0.338387  [25664/90240]\n",
      "loss: 0.445250  [32064/90240]\n",
      "loss: 0.408324  [38464/90240]\n",
      "loss: 0.178167  [44864/90240]\n",
      "loss: 0.210113  [51264/90240]\n",
      "loss: 0.256870  [57664/90240]\n",
      "loss: 0.379630  [64064/90240]\n",
      "loss: 0.256450  [70464/90240]\n",
      "loss: 0.497659  [76864/90240]\n",
      "loss: 0.344158  [83264/90240]\n",
      "loss: 0.213490  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.385223 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.197043  [   64/90240]\n",
      "loss: 0.257147  [ 6464/90240]\n",
      "loss: 0.181549  [12864/90240]\n",
      "loss: 0.353238  [19264/90240]\n",
      "loss: 0.328913  [25664/90240]\n",
      "loss: 0.160783  [32064/90240]\n",
      "loss: 0.260881  [38464/90240]\n",
      "loss: 0.556126  [44864/90240]\n",
      "loss: 0.222106  [51264/90240]\n",
      "loss: 0.283069  [57664/90240]\n",
      "loss: 0.322823  [64064/90240]\n",
      "loss: 0.381167  [70464/90240]\n",
      "loss: 0.310356  [76864/90240]\n",
      "loss: 0.256699  [83264/90240]\n",
      "loss: 0.327223  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.375953 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.291220  [   64/90240]\n",
      "loss: 0.383472  [ 6464/90240]\n",
      "loss: 0.360382  [12864/90240]\n",
      "loss: 0.553431  [19264/90240]\n",
      "loss: 0.229361  [25664/90240]\n",
      "loss: 0.310539  [32064/90240]\n",
      "loss: 0.306780  [38464/90240]\n",
      "loss: 0.151783  [44864/90240]\n",
      "loss: 0.346143  [51264/90240]\n",
      "loss: 0.366220  [57664/90240]\n",
      "loss: 0.301318  [64064/90240]\n",
      "loss: 0.390640  [70464/90240]\n",
      "loss: 0.129658  [76864/90240]\n",
      "loss: 0.251822  [83264/90240]\n",
      "loss: 0.427968  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.369366 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.212082  [   64/90240]\n",
      "loss: 0.443698  [ 6464/90240]\n",
      "loss: 0.303278  [12864/90240]\n",
      "loss: 0.302706  [19264/90240]\n",
      "loss: 0.177965  [25664/90240]\n",
      "loss: 0.290266  [32064/90240]\n",
      "loss: 0.317041  [38464/90240]\n",
      "loss: 0.323844  [44864/90240]\n",
      "loss: 0.261191  [51264/90240]\n",
      "loss: 0.437361  [57664/90240]\n",
      "loss: 0.365961  [64064/90240]\n",
      "loss: 0.222483  [70464/90240]\n",
      "loss: 0.288181  [76864/90240]\n",
      "loss: 0.209644  [83264/90240]\n",
      "loss: 0.293016  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.367853 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.145641  [   64/90240]\n",
      "loss: 0.297912  [ 6464/90240]\n",
      "loss: 0.294122  [12864/90240]\n",
      "loss: 0.415346  [19264/90240]\n",
      "loss: 0.118967  [25664/90240]\n",
      "loss: 0.284887  [32064/90240]\n",
      "loss: 0.248861  [38464/90240]\n",
      "loss: 0.205864  [44864/90240]\n",
      "loss: 0.228659  [51264/90240]\n",
      "loss: 0.307907  [57664/90240]\n",
      "loss: 0.158858  [64064/90240]\n",
      "loss: 0.234822  [70464/90240]\n",
      "loss: 0.226755  [76864/90240]\n",
      "loss: 0.175658  [83264/90240]\n",
      "loss: 0.131207  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.365321 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.320848  [   64/90240]\n",
      "loss: 0.253461  [ 6464/90240]\n",
      "loss: 0.239941  [12864/90240]\n",
      "loss: 0.194951  [19264/90240]\n",
      "loss: 0.113795  [25664/90240]\n",
      "loss: 0.287826  [32064/90240]\n",
      "loss: 0.144253  [38464/90240]\n",
      "loss: 0.273618  [44864/90240]\n",
      "loss: 0.318010  [51264/90240]\n",
      "loss: 0.261855  [57664/90240]\n",
      "loss: 0.423703  [64064/90240]\n",
      "loss: 0.170101  [70464/90240]\n",
      "loss: 0.305933  [76864/90240]\n",
      "loss: 0.236212  [83264/90240]\n",
      "loss: 0.283860  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.367139 \n",
      "\n",
      "Done!\n",
      "model : m15\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.842127  [   64/90240]\n",
      "loss: 3.326626  [ 6464/90240]\n",
      "loss: 2.021253  [12864/90240]\n",
      "loss: 1.356576  [19264/90240]\n",
      "loss: 0.856658  [25664/90240]\n",
      "loss: 1.317336  [32064/90240]\n",
      "loss: 0.777957  [38464/90240]\n",
      "loss: 1.160774  [44864/90240]\n",
      "loss: 0.704390  [51264/90240]\n",
      "loss: 0.783184  [57664/90240]\n",
      "loss: 0.735169  [64064/90240]\n",
      "loss: 0.811989  [70464/90240]\n",
      "loss: 0.614984  [76864/90240]\n",
      "loss: 0.429094  [83264/90240]\n",
      "loss: 0.666586  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.610062 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.585168  [   64/90240]\n",
      "loss: 0.539602  [ 6464/90240]\n",
      "loss: 0.483957  [12864/90240]\n",
      "loss: 0.505807  [19264/90240]\n",
      "loss: 0.497085  [25664/90240]\n",
      "loss: 0.562460  [32064/90240]\n",
      "loss: 0.442518  [38464/90240]\n",
      "loss: 0.523830  [44864/90240]\n",
      "loss: 0.586343  [51264/90240]\n",
      "loss: 0.620978  [57664/90240]\n",
      "loss: 0.466815  [64064/90240]\n",
      "loss: 0.625920  [70464/90240]\n",
      "loss: 0.566046  [76864/90240]\n",
      "loss: 0.623684  [83264/90240]\n",
      "loss: 0.464115  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.491764 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.401394  [   64/90240]\n",
      "loss: 0.455884  [ 6464/90240]\n",
      "loss: 0.280093  [12864/90240]\n",
      "loss: 0.427774  [19264/90240]\n",
      "loss: 0.342795  [25664/90240]\n",
      "loss: 0.591225  [32064/90240]\n",
      "loss: 0.349962  [38464/90240]\n",
      "loss: 0.310453  [44864/90240]\n",
      "loss: 0.410470  [51264/90240]\n",
      "loss: 0.502956  [57664/90240]\n",
      "loss: 0.295116  [64064/90240]\n",
      "loss: 0.439132  [70464/90240]\n",
      "loss: 0.318711  [76864/90240]\n",
      "loss: 0.241884  [83264/90240]\n",
      "loss: 0.303954  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.439818 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.559097  [   64/90240]\n",
      "loss: 0.449601  [ 6464/90240]\n",
      "loss: 0.409051  [12864/90240]\n",
      "loss: 0.307212  [19264/90240]\n",
      "loss: 0.204298  [25664/90240]\n",
      "loss: 0.558197  [32064/90240]\n",
      "loss: 0.400052  [38464/90240]\n",
      "loss: 0.383931  [44864/90240]\n",
      "loss: 0.338751  [51264/90240]\n",
      "loss: 0.546503  [57664/90240]\n",
      "loss: 0.485861  [64064/90240]\n",
      "loss: 0.478907  [70464/90240]\n",
      "loss: 0.302829  [76864/90240]\n",
      "loss: 0.376118  [83264/90240]\n",
      "loss: 0.520452  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.431059 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.462035  [   64/90240]\n",
      "loss: 0.358628  [ 6464/90240]\n",
      "loss: 0.483646  [12864/90240]\n",
      "loss: 0.464295  [19264/90240]\n",
      "loss: 0.506850  [25664/90240]\n",
      "loss: 0.384440  [32064/90240]\n",
      "loss: 0.337304  [38464/90240]\n",
      "loss: 0.632673  [44864/90240]\n",
      "loss: 0.306331  [51264/90240]\n",
      "loss: 0.545875  [57664/90240]\n",
      "loss: 0.345778  [64064/90240]\n",
      "loss: 0.433359  [70464/90240]\n",
      "loss: 0.461569  [76864/90240]\n",
      "loss: 0.344369  [83264/90240]\n",
      "loss: 0.318805  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.395211 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.315203  [   64/90240]\n",
      "loss: 0.379373  [ 6464/90240]\n",
      "loss: 0.375176  [12864/90240]\n",
      "loss: 0.313374  [19264/90240]\n",
      "loss: 0.324388  [25664/90240]\n",
      "loss: 0.346828  [32064/90240]\n",
      "loss: 0.774993  [38464/90240]\n",
      "loss: 0.290207  [44864/90240]\n",
      "loss: 0.289649  [51264/90240]\n",
      "loss: 0.185574  [57664/90240]\n",
      "loss: 0.353211  [64064/90240]\n",
      "loss: 0.391578  [70464/90240]\n",
      "loss: 0.510317  [76864/90240]\n",
      "loss: 0.205154  [83264/90240]\n",
      "loss: 0.421011  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.394449 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.667833  [   64/90240]\n",
      "loss: 0.347218  [ 6464/90240]\n",
      "loss: 0.363822  [12864/90240]\n",
      "loss: 0.263362  [19264/90240]\n",
      "loss: 0.333399  [25664/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.295330  [32064/90240]\n",
      "loss: 0.379550  [38464/90240]\n",
      "loss: 0.445946  [44864/90240]\n",
      "loss: 0.285062  [51264/90240]\n",
      "loss: 0.288835  [57664/90240]\n",
      "loss: 0.354178  [64064/90240]\n",
      "loss: 0.414160  [70464/90240]\n",
      "loss: 0.319154  [76864/90240]\n",
      "loss: 0.353686  [83264/90240]\n",
      "loss: 0.288672  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.376706 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.280225  [   64/90240]\n",
      "loss: 0.378583  [ 6464/90240]\n",
      "loss: 0.375156  [12864/90240]\n",
      "loss: 0.246207  [19264/90240]\n",
      "loss: 0.177443  [25664/90240]\n",
      "loss: 0.252555  [32064/90240]\n",
      "loss: 0.488995  [38464/90240]\n",
      "loss: 0.678994  [44864/90240]\n",
      "loss: 0.369879  [51264/90240]\n",
      "loss: 0.237766  [57664/90240]\n",
      "loss: 0.237894  [64064/90240]\n",
      "loss: 0.210136  [70464/90240]\n",
      "loss: 0.379763  [76864/90240]\n",
      "loss: 0.280754  [83264/90240]\n",
      "loss: 0.195913  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.379734 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.208677  [   64/90240]\n",
      "loss: 0.219522  [ 6464/90240]\n",
      "loss: 0.224371  [12864/90240]\n",
      "loss: 0.377816  [19264/90240]\n",
      "loss: 0.325307  [25664/90240]\n",
      "loss: 0.209604  [32064/90240]\n",
      "loss: 0.291699  [38464/90240]\n",
      "loss: 0.263561  [44864/90240]\n",
      "loss: 0.442159  [51264/90240]\n",
      "loss: 0.305809  [57664/90240]\n",
      "loss: 0.298188  [64064/90240]\n",
      "loss: 0.244304  [70464/90240]\n",
      "loss: 0.311540  [76864/90240]\n",
      "loss: 0.270599  [83264/90240]\n",
      "loss: 0.316800  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.365937 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.188137  [   64/90240]\n",
      "loss: 0.261967  [ 6464/90240]\n",
      "loss: 0.254508  [12864/90240]\n",
      "loss: 0.268944  [19264/90240]\n",
      "loss: 0.223352  [25664/90240]\n",
      "loss: 0.248929  [32064/90240]\n",
      "loss: 0.283813  [38464/90240]\n",
      "loss: 0.348263  [44864/90240]\n",
      "loss: 0.320876  [51264/90240]\n",
      "loss: 0.298755  [57664/90240]\n",
      "loss: 0.368749  [64064/90240]\n",
      "loss: 0.226463  [70464/90240]\n",
      "loss: 0.280167  [76864/90240]\n",
      "loss: 0.325176  [83264/90240]\n",
      "loss: 0.170357  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.357669 \n",
      "\n",
      "Done!\n",
      "model : m16\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Sigmoid()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Sigmoid()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=20000, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.961789  [   64/90240]\n",
      "loss: 3.134473  [ 6464/90240]\n",
      "loss: 2.356339  [12864/90240]\n",
      "loss: 2.014171  [19264/90240]\n",
      "loss: 1.572526  [25664/90240]\n",
      "loss: 1.520049  [32064/90240]\n",
      "loss: 1.423385  [38464/90240]\n",
      "loss: 1.248189  [44864/90240]\n",
      "loss: 1.284212  [51264/90240]\n",
      "loss: 1.387989  [57664/90240]\n",
      "loss: 1.388956  [64064/90240]\n",
      "loss: 0.955416  [70464/90240]\n",
      "loss: 1.306274  [76864/90240]\n",
      "loss: 1.288105  [83264/90240]\n",
      "loss: 1.133476  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 1.134085 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.260049  [   64/90240]\n",
      "loss: 0.725690  [ 6464/90240]\n",
      "loss: 1.153323  [12864/90240]\n",
      "loss: 1.035323  [19264/90240]\n",
      "loss: 0.946266  [25664/90240]\n",
      "loss: 0.895447  [32064/90240]\n",
      "loss: 1.080275  [38464/90240]\n",
      "loss: 0.883773  [44864/90240]\n",
      "loss: 1.047210  [51264/90240]\n",
      "loss: 0.737323  [57664/90240]\n",
      "loss: 0.539594  [64064/90240]\n",
      "loss: 0.760677  [70464/90240]\n",
      "loss: 0.678679  [76864/90240]\n",
      "loss: 0.778451  [83264/90240]\n",
      "loss: 0.711215  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.805026 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.875880  [   64/90240]\n",
      "loss: 0.521262  [ 6464/90240]\n",
      "loss: 0.762849  [12864/90240]\n",
      "loss: 0.546672  [19264/90240]\n",
      "loss: 0.699926  [25664/90240]\n",
      "loss: 0.752934  [32064/90240]\n",
      "loss: 0.600920  [38464/90240]\n",
      "loss: 0.842965  [44864/90240]\n",
      "loss: 0.527004  [51264/90240]\n",
      "loss: 0.833147  [57664/90240]\n",
      "loss: 0.577430  [64064/90240]\n",
      "loss: 0.855056  [70464/90240]\n",
      "loss: 0.674276  [76864/90240]\n",
      "loss: 0.959422  [83264/90240]\n",
      "loss: 0.526375  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.687049 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.716590  [   64/90240]\n",
      "loss: 0.629101  [ 6464/90240]\n",
      "loss: 0.591913  [12864/90240]\n",
      "loss: 0.895105  [19264/90240]\n",
      "loss: 0.612007  [25664/90240]\n",
      "loss: 0.758175  [32064/90240]\n",
      "loss: 0.624894  [38464/90240]\n",
      "loss: 0.570291  [44864/90240]\n",
      "loss: 0.526864  [51264/90240]\n",
      "loss: 0.989401  [57664/90240]\n",
      "loss: 0.672131  [64064/90240]\n",
      "loss: 0.451298  [70464/90240]\n",
      "loss: 0.706859  [76864/90240]\n",
      "loss: 0.645730  [83264/90240]\n",
      "loss: 0.692107  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.614041 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.384999  [   64/90240]\n",
      "loss: 0.587754  [ 6464/90240]\n",
      "loss: 0.479589  [12864/90240]\n",
      "loss: 0.482882  [19264/90240]\n",
      "loss: 0.454004  [25664/90240]\n",
      "loss: 0.704303  [32064/90240]\n",
      "loss: 0.557069  [38464/90240]\n",
      "loss: 0.431047  [44864/90240]\n",
      "loss: 0.528516  [51264/90240]\n",
      "loss: 0.516984  [57664/90240]\n",
      "loss: 0.751692  [64064/90240]\n",
      "loss: 0.272674  [70464/90240]\n",
      "loss: 0.432054  [76864/90240]\n",
      "loss: 0.445394  [83264/90240]\n",
      "loss: 0.604753  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.593838 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.573058  [   64/90240]\n",
      "loss: 0.456996  [ 6464/90240]\n",
      "loss: 0.381141  [12864/90240]\n",
      "loss: 0.647687  [19264/90240]\n",
      "loss: 0.744432  [25664/90240]\n",
      "loss: 0.457104  [32064/90240]\n",
      "loss: 0.563694  [38464/90240]\n",
      "loss: 0.721401  [44864/90240]\n",
      "loss: 0.725835  [51264/90240]\n",
      "loss: 0.606281  [57664/90240]\n",
      "loss: 0.262324  [64064/90240]\n",
      "loss: 0.578394  [70464/90240]\n",
      "loss: 0.797196  [76864/90240]\n",
      "loss: 0.423162  [83264/90240]\n",
      "loss: 0.439493  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.535473 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.678174  [   64/90240]\n",
      "loss: 0.413883  [ 6464/90240]\n",
      "loss: 0.914729  [12864/90240]\n",
      "loss: 0.495374  [19264/90240]\n",
      "loss: 0.390766  [25664/90240]\n",
      "loss: 0.437621  [32064/90240]\n",
      "loss: 0.297084  [38464/90240]\n",
      "loss: 0.603132  [44864/90240]\n",
      "loss: 0.338222  [51264/90240]\n",
      "loss: 0.673892  [57664/90240]\n",
      "loss: 0.497580  [64064/90240]\n",
      "loss: 0.626422  [70464/90240]\n",
      "loss: 0.407993  [76864/90240]\n",
      "loss: 0.321410  [83264/90240]\n",
      "loss: 0.571874  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.522101 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.525752  [   64/90240]\n",
      "loss: 0.459212  [ 6464/90240]\n",
      "loss: 0.330858  [12864/90240]\n",
      "loss: 0.457547  [19264/90240]\n",
      "loss: 0.592392  [25664/90240]\n",
      "loss: 0.628685  [32064/90240]\n",
      "loss: 0.276304  [38464/90240]\n",
      "loss: 0.627512  [44864/90240]\n",
      "loss: 0.607592  [51264/90240]\n",
      "loss: 0.432859  [57664/90240]\n",
      "loss: 0.593400  [64064/90240]\n",
      "loss: 0.620678  [70464/90240]\n",
      "loss: 0.492672  [76864/90240]\n",
      "loss: 0.758717  [83264/90240]\n",
      "loss: 0.590221  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.502008 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.433958  [   64/90240]\n",
      "loss: 0.363010  [ 6464/90240]\n",
      "loss: 0.416905  [12864/90240]\n",
      "loss: 0.490791  [19264/90240]\n",
      "loss: 0.363852  [25664/90240]\n",
      "loss: 0.827213  [32064/90240]\n",
      "loss: 0.678531  [38464/90240]\n",
      "loss: 0.578491  [44864/90240]\n",
      "loss: 0.534785  [51264/90240]\n",
      "loss: 0.383562  [57664/90240]\n",
      "loss: 0.299890  [64064/90240]\n",
      "loss: 0.484187  [70464/90240]\n",
      "loss: 0.316170  [76864/90240]\n",
      "loss: 0.413176  [83264/90240]\n",
      "loss: 0.646864  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.483990 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.573261  [   64/90240]\n",
      "loss: 0.254157  [ 6464/90240]\n",
      "loss: 0.402335  [12864/90240]\n",
      "loss: 0.373574  [19264/90240]\n",
      "loss: 0.476695  [25664/90240]\n",
      "loss: 0.656073  [32064/90240]\n",
      "loss: 0.498670  [38464/90240]\n",
      "loss: 0.419781  [44864/90240]\n",
      "loss: 0.429619  [51264/90240]\n",
      "loss: 0.401356  [57664/90240]\n",
      "loss: 0.195211  [64064/90240]\n",
      "loss: 0.490212  [70464/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.558844  [76864/90240]\n",
      "loss: 0.336027  [83264/90240]\n",
      "loss: 0.217411  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.472569 \n",
      "\n",
      "Done!\n",
      "model : m16\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Sigmoid()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Sigmoid()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.839724  [   64/90240]\n",
      "loss: 3.724980  [ 6464/90240]\n",
      "loss: 3.442937  [12864/90240]\n",
      "loss: 3.145961  [19264/90240]\n",
      "loss: 2.774400  [25664/90240]\n",
      "loss: 2.633941  [32064/90240]\n",
      "loss: 2.136669  [38464/90240]\n",
      "loss: 2.042811  [44864/90240]\n",
      "loss: 2.140750  [51264/90240]\n",
      "loss: 1.616118  [57664/90240]\n",
      "loss: 1.498270  [64064/90240]\n",
      "loss: 1.748030  [70464/90240]\n",
      "loss: 1.467168  [76864/90240]\n",
      "loss: 1.504427  [83264/90240]\n",
      "loss: 1.464919  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 1.350745 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.577161  [   64/90240]\n",
      "loss: 1.137128  [ 6464/90240]\n",
      "loss: 1.287052  [12864/90240]\n",
      "loss: 1.449328  [19264/90240]\n",
      "loss: 1.189837  [25664/90240]\n",
      "loss: 0.943402  [32064/90240]\n",
      "loss: 1.091791  [38464/90240]\n",
      "loss: 1.309390  [44864/90240]\n",
      "loss: 1.022850  [51264/90240]\n",
      "loss: 1.121951  [57664/90240]\n",
      "loss: 1.062748  [64064/90240]\n",
      "loss: 0.913310  [70464/90240]\n",
      "loss: 0.928892  [76864/90240]\n",
      "loss: 1.040260  [83264/90240]\n",
      "loss: 0.978803  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.882649 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.753994  [   64/90240]\n",
      "loss: 0.836668  [ 6464/90240]\n",
      "loss: 0.783859  [12864/90240]\n",
      "loss: 0.926909  [19264/90240]\n",
      "loss: 0.908327  [25664/90240]\n",
      "loss: 0.893434  [32064/90240]\n",
      "loss: 0.790120  [38464/90240]\n",
      "loss: 0.864443  [44864/90240]\n",
      "loss: 0.854799  [51264/90240]\n",
      "loss: 0.848703  [57664/90240]\n",
      "loss: 0.818828  [64064/90240]\n",
      "loss: 0.644914  [70464/90240]\n",
      "loss: 0.558607  [76864/90240]\n",
      "loss: 0.516492  [83264/90240]\n",
      "loss: 0.703835  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.726678 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.503394  [   64/90240]\n",
      "loss: 0.516317  [ 6464/90240]\n",
      "loss: 0.643704  [12864/90240]\n",
      "loss: 0.617054  [19264/90240]\n",
      "loss: 0.550258  [25664/90240]\n",
      "loss: 0.410279  [32064/90240]\n",
      "loss: 0.864310  [38464/90240]\n",
      "loss: 0.776482  [44864/90240]\n",
      "loss: 0.486284  [51264/90240]\n",
      "loss: 0.510075  [57664/90240]\n",
      "loss: 0.669461  [64064/90240]\n",
      "loss: 0.507163  [70464/90240]\n",
      "loss: 0.422061  [76864/90240]\n",
      "loss: 0.525697  [83264/90240]\n",
      "loss: 0.646430  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.642129 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.512923  [   64/90240]\n",
      "loss: 0.509882  [ 6464/90240]\n",
      "loss: 0.627308  [12864/90240]\n",
      "loss: 0.679893  [19264/90240]\n",
      "loss: 0.698141  [25664/90240]\n",
      "loss: 0.670658  [32064/90240]\n",
      "loss: 0.686884  [38464/90240]\n",
      "loss: 0.478177  [44864/90240]\n",
      "loss: 0.429972  [51264/90240]\n",
      "loss: 0.964459  [57664/90240]\n",
      "loss: 0.429475  [64064/90240]\n",
      "loss: 0.458465  [70464/90240]\n",
      "loss: 0.606838  [76864/90240]\n",
      "loss: 0.820986  [83264/90240]\n",
      "loss: 0.541604  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.586999 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.396977  [   64/90240]\n",
      "loss: 0.560713  [ 6464/90240]\n",
      "loss: 0.501957  [12864/90240]\n",
      "loss: 0.543166  [19264/90240]\n",
      "loss: 0.766241  [25664/90240]\n",
      "loss: 0.450030  [32064/90240]\n",
      "loss: 1.003908  [38464/90240]\n",
      "loss: 0.557953  [44864/90240]\n",
      "loss: 0.666496  [51264/90240]\n",
      "loss: 0.559603  [57664/90240]\n",
      "loss: 0.417298  [64064/90240]\n",
      "loss: 0.525333  [70464/90240]\n",
      "loss: 0.509095  [76864/90240]\n",
      "loss: 0.604704  [83264/90240]\n",
      "loss: 0.427859  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.568846 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.390052  [   64/90240]\n",
      "loss: 0.415086  [ 6464/90240]\n",
      "loss: 0.593743  [12864/90240]\n",
      "loss: 0.410355  [19264/90240]\n",
      "loss: 0.666364  [25664/90240]\n",
      "loss: 0.474636  [32064/90240]\n",
      "loss: 0.565354  [38464/90240]\n",
      "loss: 0.782063  [44864/90240]\n",
      "loss: 0.428289  [51264/90240]\n",
      "loss: 0.507447  [57664/90240]\n",
      "loss: 0.368054  [64064/90240]\n",
      "loss: 0.485839  [70464/90240]\n",
      "loss: 0.404981  [76864/90240]\n",
      "loss: 0.419409  [83264/90240]\n",
      "loss: 0.580308  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.543895 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.597781  [   64/90240]\n",
      "loss: 0.544056  [ 6464/90240]\n",
      "loss: 0.426540  [12864/90240]\n",
      "loss: 0.593263  [19264/90240]\n",
      "loss: 0.635593  [25664/90240]\n",
      "loss: 0.541447  [32064/90240]\n",
      "loss: 0.636531  [38464/90240]\n",
      "loss: 0.583428  [44864/90240]\n",
      "loss: 0.621858  [51264/90240]\n",
      "loss: 0.506248  [57664/90240]\n",
      "loss: 0.350328  [64064/90240]\n",
      "loss: 0.639843  [70464/90240]\n",
      "loss: 0.420978  [76864/90240]\n",
      "loss: 0.376463  [83264/90240]\n",
      "loss: 0.618115  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.512568 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.264232  [   64/90240]\n",
      "loss: 0.578313  [ 6464/90240]\n",
      "loss: 0.456954  [12864/90240]\n",
      "loss: 0.366050  [19264/90240]\n",
      "loss: 0.462182  [25664/90240]\n",
      "loss: 0.575578  [32064/90240]\n",
      "loss: 0.446933  [38464/90240]\n",
      "loss: 0.497202  [44864/90240]\n",
      "loss: 0.354671  [51264/90240]\n",
      "loss: 0.632966  [57664/90240]\n",
      "loss: 0.555616  [64064/90240]\n",
      "loss: 0.377857  [70464/90240]\n",
      "loss: 0.262062  [76864/90240]\n",
      "loss: 0.624234  [83264/90240]\n",
      "loss: 0.380041  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.493570 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.351821  [   64/90240]\n",
      "loss: 0.370782  [ 6464/90240]\n",
      "loss: 0.358402  [12864/90240]\n",
      "loss: 0.472743  [19264/90240]\n",
      "loss: 0.361243  [25664/90240]\n",
      "loss: 0.445881  [32064/90240]\n",
      "loss: 0.305027  [38464/90240]\n",
      "loss: 0.563639  [44864/90240]\n",
      "loss: 0.485175  [51264/90240]\n",
      "loss: 0.550148  [57664/90240]\n",
      "loss: 0.347978  [64064/90240]\n",
      "loss: 0.603313  [70464/90240]\n",
      "loss: 0.336961  [76864/90240]\n",
      "loss: 0.361442  [83264/90240]\n",
      "loss: 0.614132  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.474433 \n",
      "\n",
      "Done!\n",
      "model : m16\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Sigmoid()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Sigmoid()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.850914  [   64/90240]\n",
      "loss: 3.822806  [ 6464/90240]\n",
      "loss: 3.783138  [12864/90240]\n",
      "loss: 3.687323  [19264/90240]\n",
      "loss: 3.637134  [25664/90240]\n",
      "loss: 3.490063  [32064/90240]\n",
      "loss: 3.259656  [38464/90240]\n",
      "loss: 3.097699  [44864/90240]\n",
      "loss: 3.025011  [51264/90240]\n",
      "loss: 2.497721  [57664/90240]\n",
      "loss: 2.335900  [64064/90240]\n",
      "loss: 1.964979  [70464/90240]\n",
      "loss: 2.045630  [76864/90240]\n",
      "loss: 1.835753  [83264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.945535  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 1.761040 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.624039  [   64/90240]\n",
      "loss: 1.488411  [ 6464/90240]\n",
      "loss: 1.525923  [12864/90240]\n",
      "loss: 1.739876  [19264/90240]\n",
      "loss: 1.187538  [25664/90240]\n",
      "loss: 1.435221  [32064/90240]\n",
      "loss: 1.382772  [38464/90240]\n",
      "loss: 1.263776  [44864/90240]\n",
      "loss: 1.340253  [51264/90240]\n",
      "loss: 1.344524  [57664/90240]\n",
      "loss: 1.355792  [64064/90240]\n",
      "loss: 1.275700  [70464/90240]\n",
      "loss: 1.195393  [76864/90240]\n",
      "loss: 1.095150  [83264/90240]\n",
      "loss: 1.186083  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 1.151382 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.080376  [   64/90240]\n",
      "loss: 1.290964  [ 6464/90240]\n",
      "loss: 1.421315  [12864/90240]\n",
      "loss: 1.391378  [19264/90240]\n",
      "loss: 0.956792  [25664/90240]\n",
      "loss: 1.159442  [32064/90240]\n",
      "loss: 1.149573  [38464/90240]\n",
      "loss: 1.163491  [44864/90240]\n",
      "loss: 0.964483  [51264/90240]\n",
      "loss: 0.795572  [57664/90240]\n",
      "loss: 0.870495  [64064/90240]\n",
      "loss: 1.046828  [70464/90240]\n",
      "loss: 0.787864  [76864/90240]\n",
      "loss: 0.944406  [83264/90240]\n",
      "loss: 0.777579  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.821254 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.825188  [   64/90240]\n",
      "loss: 0.950850  [ 6464/90240]\n",
      "loss: 0.615295  [12864/90240]\n",
      "loss: 0.753479  [19264/90240]\n",
      "loss: 0.631692  [25664/90240]\n",
      "loss: 0.666112  [32064/90240]\n",
      "loss: 0.837777  [38464/90240]\n",
      "loss: 0.663694  [44864/90240]\n",
      "loss: 0.938016  [51264/90240]\n",
      "loss: 1.140354  [57664/90240]\n",
      "loss: 0.537585  [64064/90240]\n",
      "loss: 0.778423  [70464/90240]\n",
      "loss: 0.744058  [76864/90240]\n",
      "loss: 0.667737  [83264/90240]\n",
      "loss: 0.633467  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.676645 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.577334  [   64/90240]\n",
      "loss: 0.589182  [ 6464/90240]\n",
      "loss: 0.460460  [12864/90240]\n",
      "loss: 0.667294  [19264/90240]\n",
      "loss: 0.431722  [25664/90240]\n",
      "loss: 0.515303  [32064/90240]\n",
      "loss: 0.615097  [38464/90240]\n",
      "loss: 0.904489  [44864/90240]\n",
      "loss: 0.684138  [51264/90240]\n",
      "loss: 0.794487  [57664/90240]\n",
      "loss: 0.745582  [64064/90240]\n",
      "loss: 0.547065  [70464/90240]\n",
      "loss: 0.462625  [76864/90240]\n",
      "loss: 0.620717  [83264/90240]\n",
      "loss: 0.659918  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.607101 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.637453  [   64/90240]\n",
      "loss: 0.430054  [ 6464/90240]\n",
      "loss: 0.675353  [12864/90240]\n",
      "loss: 0.460364  [19264/90240]\n",
      "loss: 0.652446  [25664/90240]\n",
      "loss: 0.504086  [32064/90240]\n",
      "loss: 0.384519  [38464/90240]\n",
      "loss: 0.453863  [44864/90240]\n",
      "loss: 0.626308  [51264/90240]\n",
      "loss: 0.467700  [57664/90240]\n",
      "loss: 0.591934  [64064/90240]\n",
      "loss: 0.359807  [70464/90240]\n",
      "loss: 0.631558  [76864/90240]\n",
      "loss: 0.617548  [83264/90240]\n",
      "loss: 0.724090  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.557658 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.616049  [   64/90240]\n",
      "loss: 0.334582  [ 6464/90240]\n",
      "loss: 0.574477  [12864/90240]\n",
      "loss: 0.743068  [19264/90240]\n",
      "loss: 0.398601  [25664/90240]\n",
      "loss: 0.627941  [32064/90240]\n",
      "loss: 0.766994  [38464/90240]\n",
      "loss: 0.411206  [44864/90240]\n",
      "loss: 0.372769  [51264/90240]\n",
      "loss: 0.570769  [57664/90240]\n",
      "loss: 0.616550  [64064/90240]\n",
      "loss: 0.331634  [70464/90240]\n",
      "loss: 0.371786  [76864/90240]\n",
      "loss: 0.480486  [83264/90240]\n",
      "loss: 0.472402  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.551680 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.697821  [   64/90240]\n",
      "loss: 0.543652  [ 6464/90240]\n",
      "loss: 0.361127  [12864/90240]\n",
      "loss: 0.395551  [19264/90240]\n",
      "loss: 0.467972  [25664/90240]\n",
      "loss: 0.487635  [32064/90240]\n",
      "loss: 0.695698  [38464/90240]\n",
      "loss: 0.323990  [44864/90240]\n",
      "loss: 0.546293  [51264/90240]\n",
      "loss: 0.702181  [57664/90240]\n",
      "loss: 0.458511  [64064/90240]\n",
      "loss: 0.651431  [70464/90240]\n",
      "loss: 0.470902  [76864/90240]\n",
      "loss: 0.476316  [83264/90240]\n",
      "loss: 0.296515  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.498467 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.414850  [   64/90240]\n",
      "loss: 0.343615  [ 6464/90240]\n",
      "loss: 0.599047  [12864/90240]\n",
      "loss: 0.348220  [19264/90240]\n",
      "loss: 0.504528  [25664/90240]\n",
      "loss: 0.589777  [32064/90240]\n",
      "loss: 0.454531  [38464/90240]\n",
      "loss: 0.311562  [44864/90240]\n",
      "loss: 0.443951  [51264/90240]\n",
      "loss: 0.772407  [57664/90240]\n",
      "loss: 0.469887  [64064/90240]\n",
      "loss: 0.667818  [70464/90240]\n",
      "loss: 0.390678  [76864/90240]\n",
      "loss: 0.539733  [83264/90240]\n",
      "loss: 0.479274  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.494693 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.682707  [   64/90240]\n",
      "loss: 0.557390  [ 6464/90240]\n",
      "loss: 0.408628  [12864/90240]\n",
      "loss: 0.520120  [19264/90240]\n",
      "loss: 0.489107  [25664/90240]\n",
      "loss: 0.515788  [32064/90240]\n",
      "loss: 0.454770  [38464/90240]\n",
      "loss: 0.527671  [44864/90240]\n",
      "loss: 0.296441  [51264/90240]\n",
      "loss: 0.361456  [57664/90240]\n",
      "loss: 0.665879  [64064/90240]\n",
      "loss: 0.272749  [70464/90240]\n",
      "loss: 0.318523  [76864/90240]\n",
      "loss: 0.515291  [83264/90240]\n",
      "loss: 0.464542  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.471668 \n",
      "\n",
      "Done!\n",
      "model : m17\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=20000, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.845248  [   64/90240]\n",
      "loss: 2.416074  [ 6464/90240]\n",
      "loss: 1.646100  [12864/90240]\n",
      "loss: 1.723489  [19264/90240]\n",
      "loss: 1.367087  [25664/90240]\n",
      "loss: 1.259466  [32064/90240]\n",
      "loss: 1.670454  [38464/90240]\n",
      "loss: 1.471266  [44864/90240]\n",
      "loss: 1.547532  [51264/90240]\n",
      "loss: 1.311604  [57664/90240]\n",
      "loss: 1.085995  [64064/90240]\n",
      "loss: 1.232224  [70464/90240]\n",
      "loss: 1.183097  [76864/90240]\n",
      "loss: 1.264951  [83264/90240]\n",
      "loss: 1.311958  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.255187 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.435974  [   64/90240]\n",
      "loss: 1.446406  [ 6464/90240]\n",
      "loss: 1.411739  [12864/90240]\n",
      "loss: 1.315805  [19264/90240]\n",
      "loss: 0.930654  [25664/90240]\n",
      "loss: 1.125261  [32064/90240]\n",
      "loss: 1.131897  [38464/90240]\n",
      "loss: 1.111084  [44864/90240]\n",
      "loss: 1.051671  [51264/90240]\n",
      "loss: 1.033879  [57664/90240]\n",
      "loss: 0.873976  [64064/90240]\n",
      "loss: 0.727680  [70464/90240]\n",
      "loss: 0.968383  [76864/90240]\n",
      "loss: 0.991971  [83264/90240]\n",
      "loss: 0.881041  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.958703 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.806516  [   64/90240]\n",
      "loss: 0.883716  [ 6464/90240]\n",
      "loss: 0.888591  [12864/90240]\n",
      "loss: 0.861292  [19264/90240]\n",
      "loss: 0.843621  [25664/90240]\n",
      "loss: 0.880512  [32064/90240]\n",
      "loss: 0.931532  [38464/90240]\n",
      "loss: 0.918031  [44864/90240]\n",
      "loss: 0.621898  [51264/90240]\n",
      "loss: 0.645859  [57664/90240]\n",
      "loss: 0.931521  [64064/90240]\n",
      "loss: 0.662631  [70464/90240]\n",
      "loss: 0.838859  [76864/90240]\n",
      "loss: 0.705990  [83264/90240]\n",
      "loss: 0.834993  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.724615 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.719343  [   64/90240]\n",
      "loss: 0.644592  [ 6464/90240]\n",
      "loss: 0.563125  [12864/90240]\n",
      "loss: 0.657971  [19264/90240]\n",
      "loss: 0.386340  [25664/90240]\n",
      "loss: 0.473308  [32064/90240]\n",
      "loss: 0.554639  [38464/90240]\n",
      "loss: 0.714168  [44864/90240]\n",
      "loss: 0.627281  [51264/90240]\n",
      "loss: 0.414981  [57664/90240]\n",
      "loss: 0.859978  [64064/90240]\n",
      "loss: 0.511370  [70464/90240]\n",
      "loss: 0.651851  [76864/90240]\n",
      "loss: 0.460892  [83264/90240]\n",
      "loss: 0.650102  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.625750 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.664459  [   64/90240]\n",
      "loss: 0.651079  [ 6464/90240]\n",
      "loss: 0.818318  [12864/90240]\n",
      "loss: 0.492088  [19264/90240]\n",
      "loss: 0.553525  [25664/90240]\n",
      "loss: 0.552817  [32064/90240]\n",
      "loss: 0.488889  [38464/90240]\n",
      "loss: 0.578062  [44864/90240]\n",
      "loss: 0.715097  [51264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.697962  [57664/90240]\n",
      "loss: 0.609395  [64064/90240]\n",
      "loss: 0.756789  [70464/90240]\n",
      "loss: 0.966899  [76864/90240]\n",
      "loss: 0.661027  [83264/90240]\n",
      "loss: 0.439351  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.573855 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.377042  [   64/90240]\n",
      "loss: 0.498050  [ 6464/90240]\n",
      "loss: 0.711231  [12864/90240]\n",
      "loss: 0.543292  [19264/90240]\n",
      "loss: 0.718369  [25664/90240]\n",
      "loss: 0.567600  [32064/90240]\n",
      "loss: 0.400700  [38464/90240]\n",
      "loss: 0.726506  [44864/90240]\n",
      "loss: 0.322266  [51264/90240]\n",
      "loss: 0.508246  [57664/90240]\n",
      "loss: 0.548572  [64064/90240]\n",
      "loss: 0.864621  [70464/90240]\n",
      "loss: 0.318435  [76864/90240]\n",
      "loss: 0.427242  [83264/90240]\n",
      "loss: 0.414913  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.551287 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.408592  [   64/90240]\n",
      "loss: 0.423796  [ 6464/90240]\n",
      "loss: 0.497723  [12864/90240]\n",
      "loss: 0.454484  [19264/90240]\n",
      "loss: 0.539986  [25664/90240]\n",
      "loss: 0.430102  [32064/90240]\n",
      "loss: 0.605748  [38464/90240]\n",
      "loss: 0.355184  [44864/90240]\n",
      "loss: 0.539856  [51264/90240]\n",
      "loss: 0.784156  [57664/90240]\n",
      "loss: 0.435892  [64064/90240]\n",
      "loss: 0.686338  [70464/90240]\n",
      "loss: 0.604001  [76864/90240]\n",
      "loss: 0.593871  [83264/90240]\n",
      "loss: 0.322575  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.561706 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.465510  [   64/90240]\n",
      "loss: 0.410087  [ 6464/90240]\n",
      "loss: 0.327518  [12864/90240]\n",
      "loss: 0.622459  [19264/90240]\n",
      "loss: 0.666799  [25664/90240]\n",
      "loss: 0.426397  [32064/90240]\n",
      "loss: 0.338942  [38464/90240]\n",
      "loss: 0.537111  [44864/90240]\n",
      "loss: 0.739580  [51264/90240]\n",
      "loss: 0.545924  [57664/90240]\n",
      "loss: 0.378812  [64064/90240]\n",
      "loss: 0.370986  [70464/90240]\n",
      "loss: 0.333785  [76864/90240]\n",
      "loss: 0.492785  [83264/90240]\n",
      "loss: 0.695792  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.528458 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.819968  [   64/90240]\n",
      "loss: 0.401704  [ 6464/90240]\n",
      "loss: 0.756829  [12864/90240]\n",
      "loss: 0.851150  [19264/90240]\n",
      "loss: 0.354958  [25664/90240]\n",
      "loss: 0.373778  [32064/90240]\n",
      "loss: 0.705010  [38464/90240]\n",
      "loss: 0.406078  [44864/90240]\n",
      "loss: 0.442344  [51264/90240]\n",
      "loss: 0.300969  [57664/90240]\n",
      "loss: 0.427138  [64064/90240]\n",
      "loss: 0.357185  [70464/90240]\n",
      "loss: 0.536107  [76864/90240]\n",
      "loss: 0.573287  [83264/90240]\n",
      "loss: 0.324396  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.506640 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.507869  [   64/90240]\n",
      "loss: 0.398186  [ 6464/90240]\n",
      "loss: 0.547624  [12864/90240]\n",
      "loss: 0.791712  [19264/90240]\n",
      "loss: 0.548017  [25664/90240]\n",
      "loss: 0.318110  [32064/90240]\n",
      "loss: 0.351418  [38464/90240]\n",
      "loss: 0.331529  [44864/90240]\n",
      "loss: 0.482755  [51264/90240]\n",
      "loss: 0.393643  [57664/90240]\n",
      "loss: 0.536909  [64064/90240]\n",
      "loss: 0.379278  [70464/90240]\n",
      "loss: 0.553050  [76864/90240]\n",
      "loss: 0.494602  [83264/90240]\n",
      "loss: 0.381593  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.505279 \n",
      "\n",
      "Done!\n",
      "model : m17\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.853320  [   64/90240]\n",
      "loss: 3.833417  [ 6464/90240]\n",
      "loss: 3.786558  [12864/90240]\n",
      "loss: 3.543156  [19264/90240]\n",
      "loss: 1.946473  [25664/90240]\n",
      "loss: 1.943482  [32064/90240]\n",
      "loss: 1.584203  [38464/90240]\n",
      "loss: 1.371166  [44864/90240]\n",
      "loss: 1.300758  [51264/90240]\n",
      "loss: 1.680496  [57664/90240]\n",
      "loss: 1.136887  [64064/90240]\n",
      "loss: 1.092145  [70464/90240]\n",
      "loss: 1.094551  [76864/90240]\n",
      "loss: 1.259893  [83264/90240]\n",
      "loss: 1.009191  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 1.094563 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.300243  [   64/90240]\n",
      "loss: 0.989773  [ 6464/90240]\n",
      "loss: 0.685001  [12864/90240]\n",
      "loss: 1.082521  [19264/90240]\n",
      "loss: 1.072700  [25664/90240]\n",
      "loss: 0.711806  [32064/90240]\n",
      "loss: 0.854526  [38464/90240]\n",
      "loss: 1.096041  [44864/90240]\n",
      "loss: 0.831846  [51264/90240]\n",
      "loss: 0.636388  [57664/90240]\n",
      "loss: 0.840416  [64064/90240]\n",
      "loss: 0.796883  [70464/90240]\n",
      "loss: 0.882090  [76864/90240]\n",
      "loss: 0.650932  [83264/90240]\n",
      "loss: 0.920198  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.838180 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.069880  [   64/90240]\n",
      "loss: 0.523946  [ 6464/90240]\n",
      "loss: 0.819584  [12864/90240]\n",
      "loss: 0.852168  [19264/90240]\n",
      "loss: 0.617073  [25664/90240]\n",
      "loss: 0.521261  [32064/90240]\n",
      "loss: 0.711261  [38464/90240]\n",
      "loss: 0.840658  [44864/90240]\n",
      "loss: 0.701557  [51264/90240]\n",
      "loss: 0.721534  [57664/90240]\n",
      "loss: 0.739890  [64064/90240]\n",
      "loss: 1.034680  [70464/90240]\n",
      "loss: 0.776223  [76864/90240]\n",
      "loss: 0.509866  [83264/90240]\n",
      "loss: 0.607101  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.738223 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.779136  [   64/90240]\n",
      "loss: 0.515083  [ 6464/90240]\n",
      "loss: 0.635888  [12864/90240]\n",
      "loss: 0.654310  [19264/90240]\n",
      "loss: 0.791853  [25664/90240]\n",
      "loss: 0.748269  [32064/90240]\n",
      "loss: 0.844561  [38464/90240]\n",
      "loss: 0.645983  [44864/90240]\n",
      "loss: 0.447514  [51264/90240]\n",
      "loss: 0.473454  [57664/90240]\n",
      "loss: 0.639065  [64064/90240]\n",
      "loss: 0.703020  [70464/90240]\n",
      "loss: 0.670147  [76864/90240]\n",
      "loss: 0.718361  [83264/90240]\n",
      "loss: 0.752453  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.664153 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.607030  [   64/90240]\n",
      "loss: 0.626824  [ 6464/90240]\n",
      "loss: 0.730654  [12864/90240]\n",
      "loss: 0.643856  [19264/90240]\n",
      "loss: 0.706278  [25664/90240]\n",
      "loss: 0.641987  [32064/90240]\n",
      "loss: 0.647835  [38464/90240]\n",
      "loss: 0.413243  [44864/90240]\n",
      "loss: 0.580720  [51264/90240]\n",
      "loss: 0.507995  [57664/90240]\n",
      "loss: 0.514347  [64064/90240]\n",
      "loss: 0.673764  [70464/90240]\n",
      "loss: 0.314894  [76864/90240]\n",
      "loss: 0.775549  [83264/90240]\n",
      "loss: 1.165835  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.637102 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.350718  [   64/90240]\n",
      "loss: 0.640865  [ 6464/90240]\n",
      "loss: 0.557276  [12864/90240]\n",
      "loss: 0.697387  [19264/90240]\n",
      "loss: 0.523019  [25664/90240]\n",
      "loss: 0.462765  [32064/90240]\n",
      "loss: 0.868069  [38464/90240]\n",
      "loss: 0.522466  [44864/90240]\n",
      "loss: 0.480479  [51264/90240]\n",
      "loss: 0.735589  [57664/90240]\n",
      "loss: 0.536112  [64064/90240]\n",
      "loss: 0.469636  [70464/90240]\n",
      "loss: 0.643028  [76864/90240]\n",
      "loss: 0.441610  [83264/90240]\n",
      "loss: 0.746011  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.615364 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.471345  [   64/90240]\n",
      "loss: 0.534532  [ 6464/90240]\n",
      "loss: 0.474675  [12864/90240]\n",
      "loss: 0.514625  [19264/90240]\n",
      "loss: 0.638486  [25664/90240]\n",
      "loss: 0.829133  [32064/90240]\n",
      "loss: 0.553968  [38464/90240]\n",
      "loss: 0.436772  [44864/90240]\n",
      "loss: 0.507447  [51264/90240]\n",
      "loss: 0.636663  [57664/90240]\n",
      "loss: 0.511390  [64064/90240]\n",
      "loss: 0.422686  [70464/90240]\n",
      "loss: 0.662853  [76864/90240]\n",
      "loss: 0.320700  [83264/90240]\n",
      "loss: 0.552985  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.583366 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.450398  [   64/90240]\n",
      "loss: 0.673940  [ 6464/90240]\n",
      "loss: 0.607547  [12864/90240]\n",
      "loss: 0.675725  [19264/90240]\n",
      "loss: 0.641366  [25664/90240]\n",
      "loss: 0.538851  [32064/90240]\n",
      "loss: 0.654829  [38464/90240]\n",
      "loss: 0.609986  [44864/90240]\n",
      "loss: 0.464786  [51264/90240]\n",
      "loss: 0.400960  [57664/90240]\n",
      "loss: 0.481129  [64064/90240]\n",
      "loss: 0.739709  [70464/90240]\n",
      "loss: 0.355977  [76864/90240]\n",
      "loss: 0.463469  [83264/90240]\n",
      "loss: 0.506970  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.585109 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.398809  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.671842  [ 6464/90240]\n",
      "loss: 0.813805  [12864/90240]\n",
      "loss: 0.591623  [19264/90240]\n",
      "loss: 0.453418  [25664/90240]\n",
      "loss: 0.665765  [32064/90240]\n",
      "loss: 0.324596  [38464/90240]\n",
      "loss: 0.457147  [44864/90240]\n",
      "loss: 0.596559  [51264/90240]\n",
      "loss: 0.431413  [57664/90240]\n",
      "loss: 0.693267  [64064/90240]\n",
      "loss: 0.499134  [70464/90240]\n",
      "loss: 0.866542  [76864/90240]\n",
      "loss: 0.253127  [83264/90240]\n",
      "loss: 0.543743  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.554627 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.328479  [   64/90240]\n",
      "loss: 0.761809  [ 6464/90240]\n",
      "loss: 0.507105  [12864/90240]\n",
      "loss: 0.551383  [19264/90240]\n",
      "loss: 0.772326  [25664/90240]\n",
      "loss: 0.515402  [32064/90240]\n",
      "loss: 0.514649  [38464/90240]\n",
      "loss: 0.436725  [44864/90240]\n",
      "loss: 0.505106  [51264/90240]\n",
      "loss: 0.639517  [57664/90240]\n",
      "loss: 0.561028  [64064/90240]\n",
      "loss: 0.363901  [70464/90240]\n",
      "loss: 0.360510  [76864/90240]\n",
      "loss: 0.388719  [83264/90240]\n",
      "loss: 0.419414  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.546541 \n",
      "\n",
      "Done!\n",
      "model : m17\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.851549  [   64/90240]\n",
      "loss: 3.851448  [ 6464/90240]\n",
      "loss: 3.853407  [12864/90240]\n",
      "loss: 3.849007  [19264/90240]\n",
      "loss: 3.841476  [25664/90240]\n",
      "loss: 3.840187  [32064/90240]\n",
      "loss: 3.825586  [38464/90240]\n",
      "loss: 3.828875  [44864/90240]\n",
      "loss: 3.805593  [51264/90240]\n",
      "loss: 3.773710  [57664/90240]\n",
      "loss: 3.573333  [64064/90240]\n",
      "loss: 2.661005  [70464/90240]\n",
      "loss: 1.921417  [76864/90240]\n",
      "loss: 1.741757  [83264/90240]\n",
      "loss: 1.737708  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.471247 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.744180  [   64/90240]\n",
      "loss: 1.462659  [ 6464/90240]\n",
      "loss: 1.288933  [12864/90240]\n",
      "loss: 1.291241  [19264/90240]\n",
      "loss: 1.393345  [25664/90240]\n",
      "loss: 1.354327  [32064/90240]\n",
      "loss: 1.026197  [38464/90240]\n",
      "loss: 1.321076  [44864/90240]\n",
      "loss: 1.368474  [51264/90240]\n",
      "loss: 1.095497  [57664/90240]\n",
      "loss: 0.774403  [64064/90240]\n",
      "loss: 1.215525  [70464/90240]\n",
      "loss: 0.951155  [76864/90240]\n",
      "loss: 0.965757  [83264/90240]\n",
      "loss: 1.018788  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.931698 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.067814  [   64/90240]\n",
      "loss: 0.878347  [ 6464/90240]\n",
      "loss: 0.645843  [12864/90240]\n",
      "loss: 1.034430  [19264/90240]\n",
      "loss: 0.715355  [25664/90240]\n",
      "loss: 0.750689  [32064/90240]\n",
      "loss: 1.110722  [38464/90240]\n",
      "loss: 0.767449  [44864/90240]\n",
      "loss: 0.749719  [51264/90240]\n",
      "loss: 0.699652  [57664/90240]\n",
      "loss: 0.567139  [64064/90240]\n",
      "loss: 0.817894  [70464/90240]\n",
      "loss: 0.864281  [76864/90240]\n",
      "loss: 0.770343  [83264/90240]\n",
      "loss: 0.601795  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.781331 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.880997  [   64/90240]\n",
      "loss: 0.770275  [ 6464/90240]\n",
      "loss: 0.771035  [12864/90240]\n",
      "loss: 0.496693  [19264/90240]\n",
      "loss: 0.497137  [25664/90240]\n",
      "loss: 0.616111  [32064/90240]\n",
      "loss: 0.667414  [38464/90240]\n",
      "loss: 0.482677  [44864/90240]\n",
      "loss: 0.735337  [51264/90240]\n",
      "loss: 0.691847  [57664/90240]\n",
      "loss: 0.782344  [64064/90240]\n",
      "loss: 0.917871  [70464/90240]\n",
      "loss: 0.837997  [76864/90240]\n",
      "loss: 0.788427  [83264/90240]\n",
      "loss: 0.557896  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.687292 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.469608  [   64/90240]\n",
      "loss: 0.610758  [ 6464/90240]\n",
      "loss: 0.667448  [12864/90240]\n",
      "loss: 0.717286  [19264/90240]\n",
      "loss: 0.754745  [25664/90240]\n",
      "loss: 0.779757  [32064/90240]\n",
      "loss: 0.542442  [38464/90240]\n",
      "loss: 0.685997  [44864/90240]\n",
      "loss: 0.867845  [51264/90240]\n",
      "loss: 0.436868  [57664/90240]\n",
      "loss: 0.537684  [64064/90240]\n",
      "loss: 0.600820  [70464/90240]\n",
      "loss: 0.691393  [76864/90240]\n",
      "loss: 0.629793  [83264/90240]\n",
      "loss: 0.566449  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.657945 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.372570  [   64/90240]\n",
      "loss: 0.514853  [ 6464/90240]\n",
      "loss: 0.653643  [12864/90240]\n",
      "loss: 0.527129  [19264/90240]\n",
      "loss: 0.680259  [25664/90240]\n",
      "loss: 0.467678  [32064/90240]\n",
      "loss: 0.569445  [38464/90240]\n",
      "loss: 0.648571  [44864/90240]\n",
      "loss: 0.651895  [51264/90240]\n",
      "loss: 0.524577  [57664/90240]\n",
      "loss: 0.566347  [64064/90240]\n",
      "loss: 0.662317  [70464/90240]\n",
      "loss: 0.872208  [76864/90240]\n",
      "loss: 0.639500  [83264/90240]\n",
      "loss: 0.571258  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.620532 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.760344  [   64/90240]\n",
      "loss: 0.485370  [ 6464/90240]\n",
      "loss: 0.639330  [12864/90240]\n",
      "loss: 0.623936  [19264/90240]\n",
      "loss: 0.534548  [25664/90240]\n",
      "loss: 0.341166  [32064/90240]\n",
      "loss: 0.363007  [38464/90240]\n",
      "loss: 0.632828  [44864/90240]\n",
      "loss: 0.780583  [51264/90240]\n",
      "loss: 0.848964  [57664/90240]\n",
      "loss: 0.504089  [64064/90240]\n",
      "loss: 0.561440  [70464/90240]\n",
      "loss: 0.457470  [76864/90240]\n",
      "loss: 0.595655  [83264/90240]\n",
      "loss: 0.370628  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.601611 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.436485  [   64/90240]\n",
      "loss: 0.461149  [ 6464/90240]\n",
      "loss: 0.483771  [12864/90240]\n",
      "loss: 0.850380  [19264/90240]\n",
      "loss: 0.476617  [25664/90240]\n",
      "loss: 0.355800  [32064/90240]\n",
      "loss: 0.745849  [38464/90240]\n",
      "loss: 0.612786  [44864/90240]\n",
      "loss: 0.329840  [51264/90240]\n",
      "loss: 0.504912  [57664/90240]\n",
      "loss: 0.635524  [64064/90240]\n",
      "loss: 0.281985  [70464/90240]\n",
      "loss: 0.345038  [76864/90240]\n",
      "loss: 0.455480  [83264/90240]\n",
      "loss: 0.477196  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.584439 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.608032  [   64/90240]\n",
      "loss: 0.451980  [ 6464/90240]\n",
      "loss: 0.586165  [12864/90240]\n",
      "loss: 0.493017  [19264/90240]\n",
      "loss: 0.488916  [25664/90240]\n",
      "loss: 0.760406  [32064/90240]\n",
      "loss: 0.532323  [38464/90240]\n",
      "loss: 0.455867  [44864/90240]\n",
      "loss: 0.313949  [51264/90240]\n",
      "loss: 0.450658  [57664/90240]\n",
      "loss: 0.390695  [64064/90240]\n",
      "loss: 0.425071  [70464/90240]\n",
      "loss: 0.411177  [76864/90240]\n",
      "loss: 0.507448  [83264/90240]\n",
      "loss: 0.676526  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.573651 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.236946  [   64/90240]\n",
      "loss: 0.328937  [ 6464/90240]\n",
      "loss: 0.381807  [12864/90240]\n",
      "loss: 0.471781  [19264/90240]\n",
      "loss: 0.573619  [25664/90240]\n",
      "loss: 0.537910  [32064/90240]\n",
      "loss: 0.450643  [38464/90240]\n",
      "loss: 0.518983  [44864/90240]\n",
      "loss: 0.558817  [51264/90240]\n",
      "loss: 0.526737  [57664/90240]\n",
      "loss: 0.611998  [64064/90240]\n",
      "loss: 0.418760  [70464/90240]\n",
      "loss: 0.338850  [76864/90240]\n",
      "loss: 0.603979  [83264/90240]\n",
      "loss: 0.552857  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.563940 \n",
      "\n",
      "Done!\n",
      "model : m18\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): Sigmoid()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): Sigmoid()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=20000, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.895014  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.898603  [ 6464/90240]\n",
      "loss: 3.999300  [12864/90240]\n",
      "loss: 3.961722  [19264/90240]\n",
      "loss: 3.910121  [25664/90240]\n",
      "loss: 4.032895  [32064/90240]\n",
      "loss: 3.923111  [38464/90240]\n",
      "loss: 3.921949  [44864/90240]\n",
      "loss: 3.934369  [51264/90240]\n",
      "loss: 3.937514  [57664/90240]\n",
      "loss: 3.982511  [64064/90240]\n",
      "loss: 3.942177  [70464/90240]\n",
      "loss: 3.947566  [76864/90240]\n",
      "loss: 3.907722  [83264/90240]\n",
      "loss: 3.875135  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 3.914687 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.904274  [   64/90240]\n",
      "loss: 3.878700  [ 6464/90240]\n",
      "loss: 3.917818  [12864/90240]\n",
      "loss: 3.851348  [19264/90240]\n",
      "loss: 3.926718  [25664/90240]\n",
      "loss: 3.882827  [32064/90240]\n",
      "loss: 3.877845  [38464/90240]\n",
      "loss: 3.920619  [44864/90240]\n",
      "loss: 3.903133  [51264/90240]\n",
      "loss: 3.890511  [57664/90240]\n",
      "loss: 3.882761  [64064/90240]\n",
      "loss: 3.828876  [70464/90240]\n",
      "loss: 3.853672  [76864/90240]\n",
      "loss: 3.860408  [83264/90240]\n",
      "loss: 3.865506  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.880795 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.853006  [   64/90240]\n",
      "loss: 3.829016  [ 6464/90240]\n",
      "loss: 3.864701  [12864/90240]\n",
      "loss: 3.916351  [19264/90240]\n",
      "loss: 3.872328  [25664/90240]\n",
      "loss: 3.869477  [32064/90240]\n",
      "loss: 3.877190  [38464/90240]\n",
      "loss: 3.860277  [44864/90240]\n",
      "loss: 3.885761  [51264/90240]\n",
      "loss: 3.839262  [57664/90240]\n",
      "loss: 3.833301  [64064/90240]\n",
      "loss: 3.821619  [70464/90240]\n",
      "loss: 3.834851  [76864/90240]\n",
      "loss: 3.864438  [83264/90240]\n",
      "loss: 3.841673  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.865364 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.860927  [   64/90240]\n",
      "loss: 3.862932  [ 6464/90240]\n",
      "loss: 3.861030  [12864/90240]\n",
      "loss: 3.856044  [19264/90240]\n",
      "loss: 3.884091  [25664/90240]\n",
      "loss: 3.860921  [32064/90240]\n",
      "loss: 3.853218  [38464/90240]\n",
      "loss: 3.860415  [44864/90240]\n",
      "loss: 3.840371  [51264/90240]\n",
      "loss: 3.833476  [57664/90240]\n",
      "loss: 3.896260  [64064/90240]\n",
      "loss: 3.893794  [70464/90240]\n",
      "loss: 3.869619  [76864/90240]\n",
      "loss: 3.853373  [83264/90240]\n",
      "loss: 3.853192  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.857071 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.852004  [   64/90240]\n",
      "loss: 3.845980  [ 6464/90240]\n",
      "loss: 3.843937  [12864/90240]\n",
      "loss: 3.862469  [19264/90240]\n",
      "loss: 3.858359  [25664/90240]\n",
      "loss: 3.866262  [32064/90240]\n",
      "loss: 3.886725  [38464/90240]\n",
      "loss: 3.862855  [44864/90240]\n",
      "loss: 3.860147  [51264/90240]\n",
      "loss: 3.845747  [57664/90240]\n",
      "loss: 3.895818  [64064/90240]\n",
      "loss: 3.872610  [70464/90240]\n",
      "loss: 3.858428  [76864/90240]\n",
      "loss: 3.895107  [83264/90240]\n",
      "loss: 3.873310  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850906 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.840858  [   64/90240]\n",
      "loss: 3.830112  [ 6464/90240]\n",
      "loss: 3.841354  [12864/90240]\n",
      "loss: 3.862382  [19264/90240]\n",
      "loss: 3.846401  [25664/90240]\n",
      "loss: 3.846879  [32064/90240]\n",
      "loss: 3.848985  [38464/90240]\n",
      "loss: 3.805837  [44864/90240]\n",
      "loss: 3.869791  [51264/90240]\n",
      "loss: 3.838248  [57664/90240]\n",
      "loss: 3.840537  [64064/90240]\n",
      "loss: 3.833404  [70464/90240]\n",
      "loss: 3.844403  [76864/90240]\n",
      "loss: 3.836905  [83264/90240]\n",
      "loss: 3.839754  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 3.845796 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.841792  [   64/90240]\n",
      "loss: 3.846759  [ 6464/90240]\n",
      "loss: 3.840903  [12864/90240]\n",
      "loss: 3.843482  [19264/90240]\n",
      "loss: 3.830057  [25664/90240]\n",
      "loss: 3.853219  [32064/90240]\n",
      "loss: 3.844515  [38464/90240]\n",
      "loss: 3.848511  [44864/90240]\n",
      "loss: 3.834513  [51264/90240]\n",
      "loss: 3.827892  [57664/90240]\n",
      "loss: 3.839622  [64064/90240]\n",
      "loss: 3.823394  [70464/90240]\n",
      "loss: 3.821423  [76864/90240]\n",
      "loss: 3.814770  [83264/90240]\n",
      "loss: 3.858261  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 3.7%, Avg loss: 3.824468 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.799554  [   64/90240]\n",
      "loss: 3.830596  [ 6464/90240]\n",
      "loss: 3.812770  [12864/90240]\n",
      "loss: 3.802696  [19264/90240]\n",
      "loss: 3.814309  [25664/90240]\n",
      "loss: 3.809108  [32064/90240]\n",
      "loss: 3.793753  [38464/90240]\n",
      "loss: 3.794458  [44864/90240]\n",
      "loss: 3.775496  [51264/90240]\n",
      "loss: 3.788954  [57664/90240]\n",
      "loss: 3.750881  [64064/90240]\n",
      "loss: 3.753888  [70464/90240]\n",
      "loss: 3.778098  [76864/90240]\n",
      "loss: 3.743627  [83264/90240]\n",
      "loss: 3.698812  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 13.5%, Avg loss: 3.716919 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.711581  [   64/90240]\n",
      "loss: 3.717267  [ 6464/90240]\n",
      "loss: 3.719535  [12864/90240]\n",
      "loss: 3.633761  [19264/90240]\n",
      "loss: 3.512685  [25664/90240]\n",
      "loss: 3.498856  [32064/90240]\n",
      "loss: 3.384763  [38464/90240]\n",
      "loss: 3.262631  [44864/90240]\n",
      "loss: 3.030603  [51264/90240]\n",
      "loss: 2.895261  [57664/90240]\n",
      "loss: 2.633441  [64064/90240]\n",
      "loss: 2.448426  [70464/90240]\n",
      "loss: 2.275467  [76864/90240]\n",
      "loss: 2.145377  [83264/90240]\n",
      "loss: 1.769395  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 1.953256 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.874238  [   64/90240]\n",
      "loss: 1.624605  [ 6464/90240]\n",
      "loss: 1.807291  [12864/90240]\n",
      "loss: 1.656046  [19264/90240]\n",
      "loss: 1.756591  [25664/90240]\n",
      "loss: 1.380849  [32064/90240]\n",
      "loss: 1.439341  [38464/90240]\n",
      "loss: 1.491731  [44864/90240]\n",
      "loss: 1.562476  [51264/90240]\n",
      "loss: 1.395934  [57664/90240]\n",
      "loss: 1.734146  [64064/90240]\n",
      "loss: 1.337003  [70464/90240]\n",
      "loss: 1.287134  [76864/90240]\n",
      "loss: 1.396014  [83264/90240]\n",
      "loss: 1.271859  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.433572 \n",
      "\n",
      "Done!\n",
      "model : m18\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): Sigmoid()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): Sigmoid()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.857113  [   64/90240]\n",
      "loss: 3.855869  [ 6464/90240]\n",
      "loss: 3.852950  [12864/90240]\n",
      "loss: 3.847538  [19264/90240]\n",
      "loss: 3.846129  [25664/90240]\n",
      "loss: 3.848111  [32064/90240]\n",
      "loss: 3.854677  [38464/90240]\n",
      "loss: 3.858278  [44864/90240]\n",
      "loss: 3.852390  [51264/90240]\n",
      "loss: 3.843837  [57664/90240]\n",
      "loss: 3.848495  [64064/90240]\n",
      "loss: 3.847058  [70464/90240]\n",
      "loss: 3.850495  [76864/90240]\n",
      "loss: 3.850299  [83264/90240]\n",
      "loss: 3.849461  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850851 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.853603  [   64/90240]\n",
      "loss: 3.850817  [ 6464/90240]\n",
      "loss: 3.854403  [12864/90240]\n",
      "loss: 3.846094  [19264/90240]\n",
      "loss: 3.855106  [25664/90240]\n",
      "loss: 3.846429  [32064/90240]\n",
      "loss: 3.845661  [38464/90240]\n",
      "loss: 3.849257  [44864/90240]\n",
      "loss: 3.841805  [51264/90240]\n",
      "loss: 3.851041  [57664/90240]\n",
      "loss: 3.849754  [64064/90240]\n",
      "loss: 3.850414  [70464/90240]\n",
      "loss: 3.844882  [76864/90240]\n",
      "loss: 3.849281  [83264/90240]\n",
      "loss: 3.852911  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850782 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.852133  [   64/90240]\n",
      "loss: 3.850382  [ 6464/90240]\n",
      "loss: 3.852530  [12864/90240]\n",
      "loss: 3.846423  [19264/90240]\n",
      "loss: 3.852391  [25664/90240]\n",
      "loss: 3.857925  [32064/90240]\n",
      "loss: 3.848651  [38464/90240]\n",
      "loss: 3.847863  [44864/90240]\n",
      "loss: 3.854304  [51264/90240]\n",
      "loss: 3.856039  [57664/90240]\n",
      "loss: 3.850539  [64064/90240]\n",
      "loss: 3.846902  [70464/90240]\n",
      "loss: 3.858535  [76864/90240]\n",
      "loss: 3.851901  [83264/90240]\n",
      "loss: 3.852039  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850729 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.854058  [   64/90240]\n",
      "loss: 3.846011  [ 6464/90240]\n",
      "loss: 3.848151  [12864/90240]\n",
      "loss: 3.850023  [19264/90240]\n",
      "loss: 3.851313  [25664/90240]\n",
      "loss: 3.848228  [32064/90240]\n",
      "loss: 3.847809  [38464/90240]\n",
      "loss: 3.842072  [44864/90240]\n",
      "loss: 3.852937  [51264/90240]\n",
      "loss: 3.847310  [57664/90240]\n",
      "loss: 3.851578  [64064/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.851672  [70464/90240]\n",
      "loss: 3.849992  [76864/90240]\n",
      "loss: 3.852983  [83264/90240]\n",
      "loss: 3.846804  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850698 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.851759  [   64/90240]\n",
      "loss: 3.844622  [ 6464/90240]\n",
      "loss: 3.849528  [12864/90240]\n",
      "loss: 3.853304  [19264/90240]\n",
      "loss: 3.848101  [25664/90240]\n",
      "loss: 3.849650  [32064/90240]\n",
      "loss: 3.847253  [38464/90240]\n",
      "loss: 3.853300  [44864/90240]\n",
      "loss: 3.852580  [51264/90240]\n",
      "loss: 3.853409  [57664/90240]\n",
      "loss: 3.850188  [64064/90240]\n",
      "loss: 3.854152  [70464/90240]\n",
      "loss: 3.851191  [76864/90240]\n",
      "loss: 3.850533  [83264/90240]\n",
      "loss: 3.848834  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850690 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.852628  [   64/90240]\n",
      "loss: 3.849560  [ 6464/90240]\n",
      "loss: 3.848205  [12864/90240]\n",
      "loss: 3.848927  [19264/90240]\n",
      "loss: 3.847137  [25664/90240]\n",
      "loss: 3.849407  [32064/90240]\n",
      "loss: 3.848469  [38464/90240]\n",
      "loss: 3.848256  [44864/90240]\n",
      "loss: 3.850706  [51264/90240]\n",
      "loss: 3.850185  [57664/90240]\n",
      "loss: 3.849831  [64064/90240]\n",
      "loss: 3.847403  [70464/90240]\n",
      "loss: 3.851701  [76864/90240]\n",
      "loss: 3.848910  [83264/90240]\n",
      "loss: 3.851460  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850672 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.848408  [   64/90240]\n",
      "loss: 3.851471  [ 6464/90240]\n",
      "loss: 3.850702  [12864/90240]\n",
      "loss: 3.849853  [19264/90240]\n",
      "loss: 3.849192  [25664/90240]\n",
      "loss: 3.850816  [32064/90240]\n",
      "loss: 3.847408  [38464/90240]\n",
      "loss: 3.851525  [44864/90240]\n",
      "loss: 3.848328  [51264/90240]\n",
      "loss: 3.847620  [57664/90240]\n",
      "loss: 3.848137  [64064/90240]\n",
      "loss: 3.851368  [70464/90240]\n",
      "loss: 3.850462  [76864/90240]\n",
      "loss: 3.852367  [83264/90240]\n",
      "loss: 3.848645  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850675 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.849031  [   64/90240]\n",
      "loss: 3.848018  [ 6464/90240]\n",
      "loss: 3.850638  [12864/90240]\n",
      "loss: 3.848602  [19264/90240]\n",
      "loss: 3.851691  [25664/90240]\n",
      "loss: 3.847400  [32064/90240]\n",
      "loss: 3.847614  [38464/90240]\n",
      "loss: 3.849710  [44864/90240]\n",
      "loss: 3.849154  [51264/90240]\n",
      "loss: 3.848229  [57664/90240]\n",
      "loss: 3.848520  [64064/90240]\n",
      "loss: 3.849883  [70464/90240]\n",
      "loss: 3.850137  [76864/90240]\n",
      "loss: 3.848954  [83264/90240]\n",
      "loss: 3.847877  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850674 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.851236  [   64/90240]\n",
      "loss: 3.848103  [ 6464/90240]\n",
      "loss: 3.847466  [12864/90240]\n",
      "loss: 3.849699  [19264/90240]\n",
      "loss: 3.849941  [25664/90240]\n",
      "loss: 3.851827  [32064/90240]\n",
      "loss: 3.852356  [38464/90240]\n",
      "loss: 3.851486  [44864/90240]\n",
      "loss: 3.851694  [51264/90240]\n",
      "loss: 3.849539  [57664/90240]\n",
      "loss: 3.852095  [64064/90240]\n",
      "loss: 3.847560  [70464/90240]\n",
      "loss: 3.853306  [76864/90240]\n",
      "loss: 3.850011  [83264/90240]\n",
      "loss: 3.848588  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850680 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.849823  [   64/90240]\n",
      "loss: 3.853635  [ 6464/90240]\n",
      "loss: 3.850463  [12864/90240]\n",
      "loss: 3.848830  [19264/90240]\n",
      "loss: 3.850048  [25664/90240]\n",
      "loss: 3.850432  [32064/90240]\n",
      "loss: 3.850194  [38464/90240]\n",
      "loss: 3.849422  [44864/90240]\n",
      "loss: 3.852565  [51264/90240]\n",
      "loss: 3.850649  [57664/90240]\n",
      "loss: 3.848013  [64064/90240]\n",
      "loss: 3.851460  [70464/90240]\n",
      "loss: 3.852663  [76864/90240]\n",
      "loss: 3.848039  [83264/90240]\n",
      "loss: 3.850518  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850687 \n",
      "\n",
      "Done!\n",
      "model : m18\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (5): Sigmoid()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (9): Sigmoid()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.838960  [   64/90240]\n",
      "loss: 3.834418  [ 6464/90240]\n",
      "loss: 3.845720  [12864/90240]\n",
      "loss: 3.853300  [19264/90240]\n",
      "loss: 3.851132  [25664/90240]\n",
      "loss: 3.857026  [32064/90240]\n",
      "loss: 3.854242  [38464/90240]\n",
      "loss: 3.842572  [44864/90240]\n",
      "loss: 3.846600  [51264/90240]\n",
      "loss: 3.847432  [57664/90240]\n",
      "loss: 3.850291  [64064/90240]\n",
      "loss: 3.841319  [70464/90240]\n",
      "loss: 3.853923  [76864/90240]\n",
      "loss: 3.853905  [83264/90240]\n",
      "loss: 3.856237  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.851389 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.849859  [   64/90240]\n",
      "loss: 3.843157  [ 6464/90240]\n",
      "loss: 3.853843  [12864/90240]\n",
      "loss: 3.846802  [19264/90240]\n",
      "loss: 3.852001  [25664/90240]\n",
      "loss: 3.844330  [32064/90240]\n",
      "loss: 3.849619  [38464/90240]\n",
      "loss: 3.856304  [44864/90240]\n",
      "loss: 3.849514  [51264/90240]\n",
      "loss: 3.849465  [57664/90240]\n",
      "loss: 3.854319  [64064/90240]\n",
      "loss: 3.855297  [70464/90240]\n",
      "loss: 3.843854  [76864/90240]\n",
      "loss: 3.855475  [83264/90240]\n",
      "loss: 3.850560  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.851495 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.847326  [   64/90240]\n",
      "loss: 3.856517  [ 6464/90240]\n",
      "loss: 3.846831  [12864/90240]\n",
      "loss: 3.853217  [19264/90240]\n",
      "loss: 3.849061  [25664/90240]\n",
      "loss: 3.847852  [32064/90240]\n",
      "loss: 3.847817  [38464/90240]\n",
      "loss: 3.851023  [44864/90240]\n",
      "loss: 3.849530  [51264/90240]\n",
      "loss: 3.850480  [57664/90240]\n",
      "loss: 3.851288  [64064/90240]\n",
      "loss: 3.846220  [70464/90240]\n",
      "loss: 3.850356  [76864/90240]\n",
      "loss: 3.850817  [83264/90240]\n",
      "loss: 3.848917  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.851177 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.852254  [   64/90240]\n",
      "loss: 3.851044  [ 6464/90240]\n",
      "loss: 3.849297  [12864/90240]\n",
      "loss: 3.849928  [19264/90240]\n",
      "loss: 3.847296  [25664/90240]\n",
      "loss: 3.847255  [32064/90240]\n",
      "loss: 3.850005  [38464/90240]\n",
      "loss: 3.850701  [44864/90240]\n",
      "loss: 3.848856  [51264/90240]\n",
      "loss: 3.851409  [57664/90240]\n",
      "loss: 3.850402  [64064/90240]\n",
      "loss: 3.851972  [70464/90240]\n",
      "loss: 3.850732  [76864/90240]\n",
      "loss: 3.849818  [83264/90240]\n",
      "loss: 3.852513  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.851127 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.851898  [   64/90240]\n",
      "loss: 3.854771  [ 6464/90240]\n",
      "loss: 3.855575  [12864/90240]\n",
      "loss: 3.850454  [19264/90240]\n",
      "loss: 3.855893  [25664/90240]\n",
      "loss: 3.851264  [32064/90240]\n",
      "loss: 3.849911  [38464/90240]\n",
      "loss: 3.851296  [44864/90240]\n",
      "loss: 3.850888  [51264/90240]\n",
      "loss: 3.851640  [57664/90240]\n",
      "loss: 3.852165  [64064/90240]\n",
      "loss: 3.849377  [70464/90240]\n",
      "loss: 3.848776  [76864/90240]\n",
      "loss: 3.847156  [83264/90240]\n",
      "loss: 3.851145  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850964 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.854375  [   64/90240]\n",
      "loss: 3.849633  [ 6464/90240]\n",
      "loss: 3.852805  [12864/90240]\n",
      "loss: 3.851768  [19264/90240]\n",
      "loss: 3.848169  [25664/90240]\n",
      "loss: 3.849809  [32064/90240]\n",
      "loss: 3.852380  [38464/90240]\n",
      "loss: 3.852067  [44864/90240]\n",
      "loss: 3.844285  [51264/90240]\n",
      "loss: 3.851721  [57664/90240]\n",
      "loss: 3.853498  [64064/90240]\n",
      "loss: 3.846134  [70464/90240]\n",
      "loss: 3.851225  [76864/90240]\n",
      "loss: 3.845807  [83264/90240]\n",
      "loss: 3.851986  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850763 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.851124  [   64/90240]\n",
      "loss: 3.850409  [ 6464/90240]\n",
      "loss: 3.854195  [12864/90240]\n",
      "loss: 3.851243  [19264/90240]\n",
      "loss: 3.851328  [25664/90240]\n",
      "loss: 3.852003  [32064/90240]\n",
      "loss: 3.848055  [38464/90240]\n",
      "loss: 3.853196  [44864/90240]\n",
      "loss: 3.845145  [51264/90240]\n",
      "loss: 3.847682  [57664/90240]\n",
      "loss: 3.847120  [64064/90240]\n",
      "loss: 3.846406  [70464/90240]\n",
      "loss: 3.852355  [76864/90240]\n",
      "loss: 3.849030  [83264/90240]\n",
      "loss: 3.854218  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850821 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.852237  [   64/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.851193  [ 6464/90240]\n",
      "loss: 3.850986  [12864/90240]\n",
      "loss: 3.850680  [19264/90240]\n",
      "loss: 3.852086  [25664/90240]\n",
      "loss: 3.850168  [32064/90240]\n",
      "loss: 3.848461  [38464/90240]\n",
      "loss: 3.852034  [44864/90240]\n",
      "loss: 3.849358  [51264/90240]\n",
      "loss: 3.850230  [57664/90240]\n",
      "loss: 3.849494  [64064/90240]\n",
      "loss: 3.851035  [70464/90240]\n",
      "loss: 3.851588  [76864/90240]\n",
      "loss: 3.851459  [83264/90240]\n",
      "loss: 3.853495  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850768 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.847795  [   64/90240]\n",
      "loss: 3.849084  [ 6464/90240]\n",
      "loss: 3.849089  [12864/90240]\n",
      "loss: 3.848649  [19264/90240]\n",
      "loss: 3.851988  [25664/90240]\n",
      "loss: 3.846301  [32064/90240]\n",
      "loss: 3.850222  [38464/90240]\n",
      "loss: 3.848677  [44864/90240]\n",
      "loss: 3.849674  [51264/90240]\n",
      "loss: 3.852036  [57664/90240]\n",
      "loss: 3.850032  [64064/90240]\n",
      "loss: 3.850000  [70464/90240]\n",
      "loss: 3.852061  [76864/90240]\n",
      "loss: 3.851491  [83264/90240]\n",
      "loss: 3.850711  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850831 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.848639  [   64/90240]\n",
      "loss: 3.849145  [ 6464/90240]\n",
      "loss: 3.849855  [12864/90240]\n",
      "loss: 3.850521  [19264/90240]\n",
      "loss: 3.850279  [25664/90240]\n",
      "loss: 3.851551  [32064/90240]\n",
      "loss: 3.851234  [38464/90240]\n",
      "loss: 3.848200  [44864/90240]\n",
      "loss: 3.850107  [51264/90240]\n",
      "loss: 3.850786  [57664/90240]\n",
      "loss: 3.849168  [64064/90240]\n",
      "loss: 3.848175  [70464/90240]\n",
      "loss: 3.848561  [76864/90240]\n",
      "loss: 3.851457  [83264/90240]\n",
      "loss: 3.851767  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850806 \n",
      "\n",
      "Done!\n",
      "model : m19\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.2, inplace=False)\n",
      "    (10): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=20000, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.911358  [   64/90240]\n",
      "loss: 1.258310  [ 6464/90240]\n",
      "loss: 1.401208  [12864/90240]\n",
      "loss: 1.242474  [19264/90240]\n",
      "loss: 1.052485  [25664/90240]\n",
      "loss: 0.699562  [32064/90240]\n",
      "loss: 0.901407  [38464/90240]\n",
      "loss: 0.973781  [44864/90240]\n",
      "loss: 0.936673  [51264/90240]\n",
      "loss: 0.730753  [57664/90240]\n",
      "loss: 0.843610  [64064/90240]\n",
      "loss: 0.547410  [70464/90240]\n",
      "loss: 0.718591  [76864/90240]\n",
      "loss: 0.727865  [83264/90240]\n",
      "loss: 1.199487  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.701018 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.553618  [   64/90240]\n",
      "loss: 0.976935  [ 6464/90240]\n",
      "loss: 0.953714  [12864/90240]\n",
      "loss: 0.452763  [19264/90240]\n",
      "loss: 0.495850  [25664/90240]\n",
      "loss: 0.595223  [32064/90240]\n",
      "loss: 0.509740  [38464/90240]\n",
      "loss: 0.746075  [44864/90240]\n",
      "loss: 0.736846  [51264/90240]\n",
      "loss: 0.419026  [57664/90240]\n",
      "loss: 0.613861  [64064/90240]\n",
      "loss: 0.707574  [70464/90240]\n",
      "loss: 0.519914  [76864/90240]\n",
      "loss: 0.582949  [83264/90240]\n",
      "loss: 0.449705  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.590018 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.375599  [   64/90240]\n",
      "loss: 0.391602  [ 6464/90240]\n",
      "loss: 0.546989  [12864/90240]\n",
      "loss: 0.615848  [19264/90240]\n",
      "loss: 0.603883  [25664/90240]\n",
      "loss: 0.467741  [32064/90240]\n",
      "loss: 0.389215  [38464/90240]\n",
      "loss: 0.532873  [44864/90240]\n",
      "loss: 0.189962  [51264/90240]\n",
      "loss: 0.930543  [57664/90240]\n",
      "loss: 0.498257  [64064/90240]\n",
      "loss: 0.486677  [70464/90240]\n",
      "loss: 0.644348  [76864/90240]\n",
      "loss: 0.689279  [83264/90240]\n",
      "loss: 0.560331  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.512536 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.440800  [   64/90240]\n",
      "loss: 0.478147  [ 6464/90240]\n",
      "loss: 0.503337  [12864/90240]\n",
      "loss: 0.501542  [19264/90240]\n",
      "loss: 0.464080  [25664/90240]\n",
      "loss: 0.585867  [32064/90240]\n",
      "loss: 0.228125  [38464/90240]\n",
      "loss: 0.607322  [44864/90240]\n",
      "loss: 0.451363  [51264/90240]\n",
      "loss: 0.665775  [57664/90240]\n",
      "loss: 0.378025  [64064/90240]\n",
      "loss: 0.451222  [70464/90240]\n",
      "loss: 0.467397  [76864/90240]\n",
      "loss: 0.548523  [83264/90240]\n",
      "loss: 0.650872  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.516035 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.467129  [   64/90240]\n",
      "loss: 0.218564  [ 6464/90240]\n",
      "loss: 0.936288  [12864/90240]\n",
      "loss: 0.507003  [19264/90240]\n",
      "loss: 0.815573  [25664/90240]\n",
      "loss: 0.381806  [32064/90240]\n",
      "loss: 0.278143  [38464/90240]\n",
      "loss: 0.556988  [44864/90240]\n",
      "loss: 0.418201  [51264/90240]\n",
      "loss: 0.318767  [57664/90240]\n",
      "loss: 0.396371  [64064/90240]\n",
      "loss: 0.437017  [70464/90240]\n",
      "loss: 0.477805  [76864/90240]\n",
      "loss: 0.404218  [83264/90240]\n",
      "loss: 0.708173  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.481920 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.609259  [   64/90240]\n",
      "loss: 0.550319  [ 6464/90240]\n",
      "loss: 0.323687  [12864/90240]\n",
      "loss: 0.629600  [19264/90240]\n",
      "loss: 0.388462  [25664/90240]\n",
      "loss: 0.402442  [32064/90240]\n",
      "loss: 0.588829  [38464/90240]\n",
      "loss: 0.594328  [44864/90240]\n",
      "loss: 0.385382  [51264/90240]\n",
      "loss: 0.518648  [57664/90240]\n",
      "loss: 0.305783  [64064/90240]\n",
      "loss: 0.355813  [70464/90240]\n",
      "loss: 0.393501  [76864/90240]\n",
      "loss: 0.403821  [83264/90240]\n",
      "loss: 0.499153  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.461156 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.407703  [   64/90240]\n",
      "loss: 0.358272  [ 6464/90240]\n",
      "loss: 0.395008  [12864/90240]\n",
      "loss: 0.414362  [19264/90240]\n",
      "loss: 0.196629  [25664/90240]\n",
      "loss: 0.418987  [32064/90240]\n",
      "loss: 0.358412  [38464/90240]\n",
      "loss: 0.240599  [44864/90240]\n",
      "loss: 0.471981  [51264/90240]\n",
      "loss: 0.441996  [57664/90240]\n",
      "loss: 0.205865  [64064/90240]\n",
      "loss: 0.534110  [70464/90240]\n",
      "loss: 0.573232  [76864/90240]\n",
      "loss: 0.381111  [83264/90240]\n",
      "loss: 0.317709  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.448744 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.463711  [   64/90240]\n",
      "loss: 0.288249  [ 6464/90240]\n",
      "loss: 0.305742  [12864/90240]\n",
      "loss: 0.412280  [19264/90240]\n",
      "loss: 0.779323  [25664/90240]\n",
      "loss: 0.251833  [32064/90240]\n",
      "loss: 0.331636  [38464/90240]\n",
      "loss: 0.356905  [44864/90240]\n",
      "loss: 0.803467  [51264/90240]\n",
      "loss: 0.382533  [57664/90240]\n",
      "loss: 0.332216  [64064/90240]\n",
      "loss: 0.488941  [70464/90240]\n",
      "loss: 0.431363  [76864/90240]\n",
      "loss: 0.212189  [83264/90240]\n",
      "loss: 0.383300  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.438106 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.321173  [   64/90240]\n",
      "loss: 0.471542  [ 6464/90240]\n",
      "loss: 0.350046  [12864/90240]\n",
      "loss: 0.574801  [19264/90240]\n",
      "loss: 0.438437  [25664/90240]\n",
      "loss: 0.343763  [32064/90240]\n",
      "loss: 0.402679  [38464/90240]\n",
      "loss: 0.275299  [44864/90240]\n",
      "loss: 0.289258  [51264/90240]\n",
      "loss: 0.447050  [57664/90240]\n",
      "loss: 0.534860  [64064/90240]\n",
      "loss: 0.302089  [70464/90240]\n",
      "loss: 0.154600  [76864/90240]\n",
      "loss: 0.563489  [83264/90240]\n",
      "loss: 0.291020  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.450041 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.550498  [   64/90240]\n",
      "loss: 0.330244  [ 6464/90240]\n",
      "loss: 0.493954  [12864/90240]\n",
      "loss: 0.406702  [19264/90240]\n",
      "loss: 0.324778  [25664/90240]\n",
      "loss: 0.258351  [32064/90240]\n",
      "loss: 0.314161  [38464/90240]\n",
      "loss: 0.443605  [44864/90240]\n",
      "loss: 0.481008  [51264/90240]\n",
      "loss: 0.435065  [57664/90240]\n",
      "loss: 0.226333  [64064/90240]\n",
      "loss: 0.251692  [70464/90240]\n",
      "loss: 0.369670  [76864/90240]\n",
      "loss: 0.423343  [83264/90240]\n",
      "loss: 0.533251  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.429337 \n",
      "\n",
      "Done!\n",
      "model : m19\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.2, inplace=False)\n",
      "    (10): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.878273  [   64/90240]\n",
      "loss: 1.731951  [ 6464/90240]\n",
      "loss: 1.478165  [12864/90240]\n",
      "loss: 1.509896  [19264/90240]\n",
      "loss: 1.123194  [25664/90240]\n",
      "loss: 0.936262  [32064/90240]\n",
      "loss: 1.231381  [38464/90240]\n",
      "loss: 0.834683  [44864/90240]\n",
      "loss: 0.967022  [51264/90240]\n",
      "loss: 0.781742  [57664/90240]\n",
      "loss: 0.835847  [64064/90240]\n",
      "loss: 0.857731  [70464/90240]\n",
      "loss: 0.720942  [76864/90240]\n",
      "loss: 0.775943  [83264/90240]\n",
      "loss: 0.498083  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.742556 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.605921  [   64/90240]\n",
      "loss: 0.781792  [ 6464/90240]\n",
      "loss: 0.543697  [12864/90240]\n",
      "loss: 0.583540  [19264/90240]\n",
      "loss: 1.007243  [25664/90240]\n",
      "loss: 0.890692  [32064/90240]\n",
      "loss: 0.725682  [38464/90240]\n",
      "loss: 0.620046  [44864/90240]\n",
      "loss: 0.834694  [51264/90240]\n",
      "loss: 0.667426  [57664/90240]\n",
      "loss: 0.347997  [64064/90240]\n",
      "loss: 0.364744  [70464/90240]\n",
      "loss: 0.729218  [76864/90240]\n",
      "loss: 0.576692  [83264/90240]\n",
      "loss: 0.462604  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.541170 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.843696  [   64/90240]\n",
      "loss: 0.409298  [ 6464/90240]\n",
      "loss: 0.541316  [12864/90240]\n",
      "loss: 0.491482  [19264/90240]\n",
      "loss: 0.681806  [25664/90240]\n",
      "loss: 0.351764  [32064/90240]\n",
      "loss: 0.481994  [38464/90240]\n",
      "loss: 0.485757  [44864/90240]\n",
      "loss: 0.224886  [51264/90240]\n",
      "loss: 0.947412  [57664/90240]\n",
      "loss: 0.389944  [64064/90240]\n",
      "loss: 0.514355  [70464/90240]\n",
      "loss: 0.508354  [76864/90240]\n",
      "loss: 0.656370  [83264/90240]\n",
      "loss: 0.406376  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.467382 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.437038  [   64/90240]\n",
      "loss: 0.307805  [ 6464/90240]\n",
      "loss: 0.329924  [12864/90240]\n",
      "loss: 0.366845  [19264/90240]\n",
      "loss: 0.576699  [25664/90240]\n",
      "loss: 0.403827  [32064/90240]\n",
      "loss: 0.614285  [38464/90240]\n",
      "loss: 0.656460  [44864/90240]\n",
      "loss: 0.499857  [51264/90240]\n",
      "loss: 0.417326  [57664/90240]\n",
      "loss: 0.415670  [64064/90240]\n",
      "loss: 0.352589  [70464/90240]\n",
      "loss: 0.357547  [76864/90240]\n",
      "loss: 0.308737  [83264/90240]\n",
      "loss: 0.374741  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.436598 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.507267  [   64/90240]\n",
      "loss: 0.424955  [ 6464/90240]\n",
      "loss: 0.386309  [12864/90240]\n",
      "loss: 0.279863  [19264/90240]\n",
      "loss: 0.556957  [25664/90240]\n",
      "loss: 0.329269  [32064/90240]\n",
      "loss: 0.490574  [38464/90240]\n",
      "loss: 0.285891  [44864/90240]\n",
      "loss: 0.318777  [51264/90240]\n",
      "loss: 0.406282  [57664/90240]\n",
      "loss: 0.353418  [64064/90240]\n",
      "loss: 0.362270  [70464/90240]\n",
      "loss: 0.353813  [76864/90240]\n",
      "loss: 0.301034  [83264/90240]\n",
      "loss: 0.286062  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.415079 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.347098  [   64/90240]\n",
      "loss: 0.279022  [ 6464/90240]\n",
      "loss: 0.545914  [12864/90240]\n",
      "loss: 0.193092  [19264/90240]\n",
      "loss: 0.565424  [25664/90240]\n",
      "loss: 0.231103  [32064/90240]\n",
      "loss: 0.629627  [38464/90240]\n",
      "loss: 0.321992  [44864/90240]\n",
      "loss: 0.759086  [51264/90240]\n",
      "loss: 0.317011  [57664/90240]\n",
      "loss: 0.306464  [64064/90240]\n",
      "loss: 0.373646  [70464/90240]\n",
      "loss: 0.483141  [76864/90240]\n",
      "loss: 0.412031  [83264/90240]\n",
      "loss: 0.631480  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.413384 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.332371  [   64/90240]\n",
      "loss: 0.353108  [ 6464/90240]\n",
      "loss: 0.328411  [12864/90240]\n",
      "loss: 0.287307  [19264/90240]\n",
      "loss: 0.267732  [25664/90240]\n",
      "loss: 0.571854  [32064/90240]\n",
      "loss: 0.290445  [38464/90240]\n",
      "loss: 0.334519  [44864/90240]\n",
      "loss: 0.528775  [51264/90240]\n",
      "loss: 0.283113  [57664/90240]\n",
      "loss: 0.427205  [64064/90240]\n",
      "loss: 0.755294  [70464/90240]\n",
      "loss: 0.445050  [76864/90240]\n",
      "loss: 0.549057  [83264/90240]\n",
      "loss: 0.241084  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.400327 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.387568  [   64/90240]\n",
      "loss: 0.173900  [ 6464/90240]\n",
      "loss: 0.480822  [12864/90240]\n",
      "loss: 0.288775  [19264/90240]\n",
      "loss: 0.274356  [25664/90240]\n",
      "loss: 0.324610  [32064/90240]\n",
      "loss: 0.296567  [38464/90240]\n",
      "loss: 0.382249  [44864/90240]\n",
      "loss: 0.389802  [51264/90240]\n",
      "loss: 0.350120  [57664/90240]\n",
      "loss: 0.195533  [64064/90240]\n",
      "loss: 0.336968  [70464/90240]\n",
      "loss: 0.192362  [76864/90240]\n",
      "loss: 0.271350  [83264/90240]\n",
      "loss: 0.370463  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.405621 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.452954  [   64/90240]\n",
      "loss: 0.428465  [ 6464/90240]\n",
      "loss: 0.412095  [12864/90240]\n",
      "loss: 0.324563  [19264/90240]\n",
      "loss: 0.134836  [25664/90240]\n",
      "loss: 0.331434  [32064/90240]\n",
      "loss: 0.233933  [38464/90240]\n",
      "loss: 0.347533  [44864/90240]\n",
      "loss: 0.493189  [51264/90240]\n",
      "loss: 0.399465  [57664/90240]\n",
      "loss: 0.343046  [64064/90240]\n",
      "loss: 0.385893  [70464/90240]\n",
      "loss: 0.426657  [76864/90240]\n",
      "loss: 0.473576  [83264/90240]\n",
      "loss: 0.299050  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.389698 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.285870  [   64/90240]\n",
      "loss: 0.222843  [ 6464/90240]\n",
      "loss: 0.287920  [12864/90240]\n",
      "loss: 0.289021  [19264/90240]\n",
      "loss: 0.577151  [25664/90240]\n",
      "loss: 0.411263  [32064/90240]\n",
      "loss: 0.345334  [38464/90240]\n",
      "loss: 0.353074  [44864/90240]\n",
      "loss: 0.153365  [51264/90240]\n",
      "loss: 0.301767  [57664/90240]\n",
      "loss: 0.538380  [64064/90240]\n",
      "loss: 0.210045  [70464/90240]\n",
      "loss: 0.435093  [76864/90240]\n",
      "loss: 0.262364  [83264/90240]\n",
      "loss: 0.309075  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.389349 \n",
      "\n",
      "Done!\n",
      "model : m19\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.2, inplace=False)\n",
      "    (10): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.846708  [   64/90240]\n",
      "loss: 3.616455  [ 6464/90240]\n",
      "loss: 2.606462  [12864/90240]\n",
      "loss: 1.811010  [19264/90240]\n",
      "loss: 1.683179  [25664/90240]\n",
      "loss: 1.384566  [32064/90240]\n",
      "loss: 1.061204  [38464/90240]\n",
      "loss: 1.164362  [44864/90240]\n",
      "loss: 1.285441  [51264/90240]\n",
      "loss: 1.042483  [57664/90240]\n",
      "loss: 0.766157  [64064/90240]\n",
      "loss: 0.806132  [70464/90240]\n",
      "loss: 1.187746  [76864/90240]\n",
      "loss: 0.805114  [83264/90240]\n",
      "loss: 0.644919  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.818813 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.709375  [   64/90240]\n",
      "loss: 0.414539  [ 6464/90240]\n",
      "loss: 0.937310  [12864/90240]\n",
      "loss: 0.526979  [19264/90240]\n",
      "loss: 0.652510  [25664/90240]\n",
      "loss: 0.788007  [32064/90240]\n",
      "loss: 0.599622  [38464/90240]\n",
      "loss: 0.899899  [44864/90240]\n",
      "loss: 0.751339  [51264/90240]\n",
      "loss: 0.856892  [57664/90240]\n",
      "loss: 0.595935  [64064/90240]\n",
      "loss: 0.484570  [70464/90240]\n",
      "loss: 0.472571  [76864/90240]\n",
      "loss: 0.661351  [83264/90240]\n",
      "loss: 0.629654  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.580850 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.403883  [   64/90240]\n",
      "loss: 0.581162  [ 6464/90240]\n",
      "loss: 0.535577  [12864/90240]\n",
      "loss: 0.574891  [19264/90240]\n",
      "loss: 0.584624  [25664/90240]\n",
      "loss: 0.496783  [32064/90240]\n",
      "loss: 0.522822  [38464/90240]\n",
      "loss: 0.385146  [44864/90240]\n",
      "loss: 0.328074  [51264/90240]\n",
      "loss: 0.503998  [57664/90240]\n",
      "loss: 0.491900  [64064/90240]\n",
      "loss: 0.383845  [70464/90240]\n",
      "loss: 0.365670  [76864/90240]\n",
      "loss: 0.718229  [83264/90240]\n",
      "loss: 0.442624  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.508154 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.395755  [   64/90240]\n",
      "loss: 0.395832  [ 6464/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.540694  [12864/90240]\n",
      "loss: 0.314966  [19264/90240]\n",
      "loss: 0.490240  [25664/90240]\n",
      "loss: 0.285727  [32064/90240]\n",
      "loss: 0.429467  [38464/90240]\n",
      "loss: 0.618256  [44864/90240]\n",
      "loss: 0.368041  [51264/90240]\n",
      "loss: 0.524434  [57664/90240]\n",
      "loss: 0.385937  [64064/90240]\n",
      "loss: 0.368771  [70464/90240]\n",
      "loss: 0.404005  [76864/90240]\n",
      "loss: 0.406859  [83264/90240]\n",
      "loss: 0.313688  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.466924 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.253960  [   64/90240]\n",
      "loss: 0.762718  [ 6464/90240]\n",
      "loss: 0.397932  [12864/90240]\n",
      "loss: 0.310016  [19264/90240]\n",
      "loss: 0.482574  [25664/90240]\n",
      "loss: 0.364454  [32064/90240]\n",
      "loss: 0.302287  [38464/90240]\n",
      "loss: 0.361377  [44864/90240]\n",
      "loss: 0.340507  [51264/90240]\n",
      "loss: 0.350190  [57664/90240]\n",
      "loss: 0.429091  [64064/90240]\n",
      "loss: 0.312810  [70464/90240]\n",
      "loss: 0.432684  [76864/90240]\n",
      "loss: 0.325393  [83264/90240]\n",
      "loss: 0.298893  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.438506 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.432840  [   64/90240]\n",
      "loss: 0.443371  [ 6464/90240]\n",
      "loss: 0.501743  [12864/90240]\n",
      "loss: 0.351612  [19264/90240]\n",
      "loss: 0.341139  [25664/90240]\n",
      "loss: 0.207179  [32064/90240]\n",
      "loss: 0.414014  [38464/90240]\n",
      "loss: 0.503833  [44864/90240]\n",
      "loss: 0.354374  [51264/90240]\n",
      "loss: 0.327830  [57664/90240]\n",
      "loss: 0.786446  [64064/90240]\n",
      "loss: 0.236581  [70464/90240]\n",
      "loss: 0.299541  [76864/90240]\n",
      "loss: 0.393194  [83264/90240]\n",
      "loss: 0.321800  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.429680 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.358625  [   64/90240]\n",
      "loss: 0.547975  [ 6464/90240]\n",
      "loss: 0.350328  [12864/90240]\n",
      "loss: 0.511697  [19264/90240]\n",
      "loss: 0.304185  [25664/90240]\n",
      "loss: 0.317438  [32064/90240]\n",
      "loss: 0.318549  [38464/90240]\n",
      "loss: 0.449544  [44864/90240]\n",
      "loss: 0.312338  [51264/90240]\n",
      "loss: 0.239353  [57664/90240]\n",
      "loss: 0.310120  [64064/90240]\n",
      "loss: 0.429176  [70464/90240]\n",
      "loss: 0.460235  [76864/90240]\n",
      "loss: 0.487343  [83264/90240]\n",
      "loss: 0.536217  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.425338 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.236675  [   64/90240]\n",
      "loss: 0.323068  [ 6464/90240]\n",
      "loss: 0.476641  [12864/90240]\n",
      "loss: 0.227629  [19264/90240]\n",
      "loss: 0.366356  [25664/90240]\n",
      "loss: 0.513712  [32064/90240]\n",
      "loss: 0.253101  [38464/90240]\n",
      "loss: 0.672065  [44864/90240]\n",
      "loss: 0.475141  [51264/90240]\n",
      "loss: 0.365051  [57664/90240]\n",
      "loss: 0.423930  [64064/90240]\n",
      "loss: 0.380146  [70464/90240]\n",
      "loss: 0.388938  [76864/90240]\n",
      "loss: 0.389572  [83264/90240]\n",
      "loss: 0.278357  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.414480 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.378428  [   64/90240]\n",
      "loss: 0.315864  [ 6464/90240]\n",
      "loss: 0.477535  [12864/90240]\n",
      "loss: 0.726523  [19264/90240]\n",
      "loss: 0.489218  [25664/90240]\n",
      "loss: 0.229787  [32064/90240]\n",
      "loss: 0.398840  [38464/90240]\n",
      "loss: 0.186030  [44864/90240]\n",
      "loss: 0.550489  [51264/90240]\n",
      "loss: 0.476872  [57664/90240]\n",
      "loss: 0.453543  [64064/90240]\n",
      "loss: 0.416132  [70464/90240]\n",
      "loss: 0.370624  [76864/90240]\n",
      "loss: 0.263413  [83264/90240]\n",
      "loss: 0.395021  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.398971 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.418608  [   64/90240]\n",
      "loss: 0.319257  [ 6464/90240]\n",
      "loss: 0.409417  [12864/90240]\n",
      "loss: 0.271547  [19264/90240]\n",
      "loss: 0.250184  [25664/90240]\n",
      "loss: 0.399202  [32064/90240]\n",
      "loss: 0.330315  [38464/90240]\n",
      "loss: 0.199241  [44864/90240]\n",
      "loss: 0.399252  [51264/90240]\n",
      "loss: 0.553174  [57664/90240]\n",
      "loss: 0.518492  [64064/90240]\n",
      "loss: 0.288017  [70464/90240]\n",
      "loss: 0.846134  [76864/90240]\n",
      "loss: 0.305203  [83264/90240]\n",
      "loss: 0.289310  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.390090 \n",
      "\n",
      "Done!\n",
      "model : m20\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.2, inplace=False)\n",
      "    (10): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (11): Sigmoid()\n",
      "    (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=20000, out_features=47, bias=True)\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.870196  [   64/90240]\n",
      "loss: 3.971713  [ 6464/90240]\n",
      "loss: 3.953053  [12864/90240]\n",
      "loss: 3.897329  [19264/90240]\n",
      "loss: 3.958798  [25664/90240]\n",
      "loss: 3.856338  [32064/90240]\n",
      "loss: 3.843496  [38464/90240]\n",
      "loss: 3.732594  [44864/90240]\n",
      "loss: 3.476720  [51264/90240]\n",
      "loss: 3.090656  [57664/90240]\n",
      "loss: 2.635790  [64064/90240]\n",
      "loss: 2.262993  [70464/90240]\n",
      "loss: 2.073546  [76864/90240]\n",
      "loss: 1.835767  [83264/90240]\n",
      "loss: 1.545908  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 1.735070 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.590885  [   64/90240]\n",
      "loss: 1.595453  [ 6464/90240]\n",
      "loss: 1.640340  [12864/90240]\n",
      "loss: 1.485530  [19264/90240]\n",
      "loss: 1.396723  [25664/90240]\n",
      "loss: 1.533050  [32064/90240]\n",
      "loss: 1.364128  [38464/90240]\n",
      "loss: 1.060283  [44864/90240]\n",
      "loss: 1.510916  [51264/90240]\n",
      "loss: 1.193503  [57664/90240]\n",
      "loss: 1.320861  [64064/90240]\n",
      "loss: 1.208068  [70464/90240]\n",
      "loss: 1.424256  [76864/90240]\n",
      "loss: 1.387608  [83264/90240]\n",
      "loss: 1.185557  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 1.333441 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.523191  [   64/90240]\n",
      "loss: 1.337333  [ 6464/90240]\n",
      "loss: 1.059020  [12864/90240]\n",
      "loss: 1.222677  [19264/90240]\n",
      "loss: 1.273691  [25664/90240]\n",
      "loss: 1.537154  [32064/90240]\n",
      "loss: 1.055532  [38464/90240]\n",
      "loss: 1.378689  [44864/90240]\n",
      "loss: 0.964775  [51264/90240]\n",
      "loss: 1.051012  [57664/90240]\n",
      "loss: 1.563053  [64064/90240]\n",
      "loss: 1.482258  [70464/90240]\n",
      "loss: 1.497060  [76864/90240]\n",
      "loss: 0.973134  [83264/90240]\n",
      "loss: 1.415597  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.240945 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.361885  [   64/90240]\n",
      "loss: 1.431663  [ 6464/90240]\n",
      "loss: 1.906134  [12864/90240]\n",
      "loss: 1.100725  [19264/90240]\n",
      "loss: 1.210179  [25664/90240]\n",
      "loss: 1.376269  [32064/90240]\n",
      "loss: 1.282446  [38464/90240]\n",
      "loss: 1.189964  [44864/90240]\n",
      "loss: 1.229015  [51264/90240]\n",
      "loss: 1.019473  [57664/90240]\n",
      "loss: 1.268053  [64064/90240]\n",
      "loss: 1.396871  [70464/90240]\n",
      "loss: 1.038213  [76864/90240]\n",
      "loss: 1.279269  [83264/90240]\n",
      "loss: 1.192513  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.186432 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.188141  [   64/90240]\n",
      "loss: 1.060554  [ 6464/90240]\n",
      "loss: 1.108743  [12864/90240]\n",
      "loss: 1.000487  [19264/90240]\n",
      "loss: 1.336973  [25664/90240]\n",
      "loss: 1.327947  [32064/90240]\n",
      "loss: 1.546301  [38464/90240]\n",
      "loss: 1.108136  [44864/90240]\n",
      "loss: 1.511653  [51264/90240]\n",
      "loss: 1.654577  [57664/90240]\n",
      "loss: 1.183385  [64064/90240]\n",
      "loss: 0.844057  [70464/90240]\n",
      "loss: 1.321255  [76864/90240]\n",
      "loss: 0.850175  [83264/90240]\n",
      "loss: 1.408785  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 1.158365 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.045500  [   64/90240]\n",
      "loss: 0.917480  [ 6464/90240]\n",
      "loss: 1.506519  [12864/90240]\n",
      "loss: 1.335398  [19264/90240]\n",
      "loss: 1.074811  [25664/90240]\n",
      "loss: 1.217453  [32064/90240]\n",
      "loss: 0.981446  [38464/90240]\n",
      "loss: 1.149704  [44864/90240]\n",
      "loss: 0.938265  [51264/90240]\n",
      "loss: 1.342155  [57664/90240]\n",
      "loss: 1.316193  [64064/90240]\n",
      "loss: 1.036505  [70464/90240]\n",
      "loss: 1.100108  [76864/90240]\n",
      "loss: 1.105438  [83264/90240]\n",
      "loss: 1.026634  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.118622 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.083933  [   64/90240]\n",
      "loss: 1.024077  [ 6464/90240]\n",
      "loss: 1.277999  [12864/90240]\n",
      "loss: 1.460658  [19264/90240]\n",
      "loss: 1.129416  [25664/90240]\n",
      "loss: 1.182186  [32064/90240]\n",
      "loss: 1.228231  [38464/90240]\n",
      "loss: 0.881999  [44864/90240]\n",
      "loss: 1.072235  [51264/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.007458  [57664/90240]\n",
      "loss: 0.827089  [64064/90240]\n",
      "loss: 1.077443  [70464/90240]\n",
      "loss: 0.998195  [76864/90240]\n",
      "loss: 1.006852  [83264/90240]\n",
      "loss: 1.393023  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 1.071256 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.992256  [   64/90240]\n",
      "loss: 1.484512  [ 6464/90240]\n",
      "loss: 1.325822  [12864/90240]\n",
      "loss: 1.279499  [19264/90240]\n",
      "loss: 1.227628  [25664/90240]\n",
      "loss: 0.931488  [32064/90240]\n",
      "loss: 1.200961  [38464/90240]\n",
      "loss: 1.185438  [44864/90240]\n",
      "loss: 1.047861  [51264/90240]\n",
      "loss: 0.868288  [57664/90240]\n",
      "loss: 1.216162  [64064/90240]\n",
      "loss: 0.880341  [70464/90240]\n",
      "loss: 1.065763  [76864/90240]\n",
      "loss: 1.340122  [83264/90240]\n",
      "loss: 0.792003  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1.062527 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.925328  [   64/90240]\n",
      "loss: 0.890785  [ 6464/90240]\n",
      "loss: 1.393939  [12864/90240]\n",
      "loss: 1.053075  [19264/90240]\n",
      "loss: 0.991723  [25664/90240]\n",
      "loss: 0.697260  [32064/90240]\n",
      "loss: 0.962241  [38464/90240]\n",
      "loss: 0.849807  [44864/90240]\n",
      "loss: 1.260862  [51264/90240]\n",
      "loss: 0.909033  [57664/90240]\n",
      "loss: 1.014995  [64064/90240]\n",
      "loss: 1.418545  [70464/90240]\n",
      "loss: 1.070975  [76864/90240]\n",
      "loss: 1.152739  [83264/90240]\n",
      "loss: 0.763890  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 1.010367 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.101898  [   64/90240]\n",
      "loss: 1.056758  [ 6464/90240]\n",
      "loss: 0.843212  [12864/90240]\n",
      "loss: 1.189252  [19264/90240]\n",
      "loss: 1.393862  [25664/90240]\n",
      "loss: 0.974091  [32064/90240]\n",
      "loss: 0.802160  [38464/90240]\n",
      "loss: 0.922997  [44864/90240]\n",
      "loss: 0.890689  [51264/90240]\n",
      "loss: 0.936625  [57664/90240]\n",
      "loss: 1.035240  [64064/90240]\n",
      "loss: 0.888561  [70464/90240]\n",
      "loss: 1.141586  [76864/90240]\n",
      "loss: 0.956512  [83264/90240]\n",
      "loss: 0.927105  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.990822 \n",
      "\n",
      "Done!\n",
      "model : m20\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.2, inplace=False)\n",
      "    (10): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (11): Sigmoid()\n",
      "    (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.842604  [   64/90240]\n",
      "loss: 3.865927  [ 6464/90240]\n",
      "loss: 3.835199  [12864/90240]\n",
      "loss: 3.840207  [19264/90240]\n",
      "loss: 3.849274  [25664/90240]\n",
      "loss: 3.851113  [32064/90240]\n",
      "loss: 3.846947  [38464/90240]\n",
      "loss: 3.857132  [44864/90240]\n",
      "loss: 3.859402  [51264/90240]\n",
      "loss: 3.848940  [57664/90240]\n",
      "loss: 3.857206  [64064/90240]\n",
      "loss: 3.852359  [70464/90240]\n",
      "loss: 3.854935  [76864/90240]\n",
      "loss: 3.846546  [83264/90240]\n",
      "loss: 3.852776  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850584 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.852886  [   64/90240]\n",
      "loss: 3.858310  [ 6464/90240]\n",
      "loss: 3.859447  [12864/90240]\n",
      "loss: 3.850696  [19264/90240]\n",
      "loss: 3.849905  [25664/90240]\n",
      "loss: 3.850968  [32064/90240]\n",
      "loss: 3.846511  [38464/90240]\n",
      "loss: 3.851057  [44864/90240]\n",
      "loss: 3.852731  [51264/90240]\n",
      "loss: 3.850306  [57664/90240]\n",
      "loss: 3.850044  [64064/90240]\n",
      "loss: 3.847648  [70464/90240]\n",
      "loss: 3.851623  [76864/90240]\n",
      "loss: 3.848090  [83264/90240]\n",
      "loss: 3.851182  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 3.850522 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.851480  [   64/90240]\n",
      "loss: 3.851509  [ 6464/90240]\n",
      "loss: 3.850867  [12864/90240]\n",
      "loss: 3.850736  [19264/90240]\n",
      "loss: 3.848900  [25664/90240]\n",
      "loss: 3.852051  [32064/90240]\n",
      "loss: 3.848486  [38464/90240]\n",
      "loss: 3.847016  [44864/90240]\n",
      "loss: 3.848761  [51264/90240]\n",
      "loss: 3.847607  [57664/90240]\n",
      "loss: 3.850965  [64064/90240]\n",
      "loss: 3.851860  [70464/90240]\n",
      "loss: 3.850484  [76864/90240]\n",
      "loss: 3.849632  [83264/90240]\n",
      "loss: 3.847677  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850492 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.852128  [   64/90240]\n",
      "loss: 3.850840  [ 6464/90240]\n",
      "loss: 3.848766  [12864/90240]\n",
      "loss: 3.852445  [19264/90240]\n",
      "loss: 3.850030  [25664/90240]\n",
      "loss: 3.849513  [32064/90240]\n",
      "loss: 3.850132  [38464/90240]\n",
      "loss: 3.855756  [44864/90240]\n",
      "loss: 3.849833  [51264/90240]\n",
      "loss: 3.852579  [57664/90240]\n",
      "loss: 3.852000  [64064/90240]\n",
      "loss: 3.850114  [70464/90240]\n",
      "loss: 3.854932  [76864/90240]\n",
      "loss: 3.848418  [83264/90240]\n",
      "loss: 3.844344  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850485 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.848974  [   64/90240]\n",
      "loss: 3.852546  [ 6464/90240]\n",
      "loss: 3.849750  [12864/90240]\n",
      "loss: 3.851924  [19264/90240]\n",
      "loss: 3.851895  [25664/90240]\n",
      "loss: 3.846285  [32064/90240]\n",
      "loss: 3.851240  [38464/90240]\n",
      "loss: 3.854146  [44864/90240]\n",
      "loss: 3.848030  [51264/90240]\n",
      "loss: 3.852459  [57664/90240]\n",
      "loss: 3.845973  [64064/90240]\n",
      "loss: 3.850371  [70464/90240]\n",
      "loss: 3.851726  [76864/90240]\n",
      "loss: 3.851728  [83264/90240]\n",
      "loss: 3.851304  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850486 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.851131  [   64/90240]\n",
      "loss: 3.847882  [ 6464/90240]\n",
      "loss: 3.853617  [12864/90240]\n",
      "loss: 3.855902  [19264/90240]\n",
      "loss: 3.853545  [25664/90240]\n",
      "loss: 3.846533  [32064/90240]\n",
      "loss: 3.851695  [38464/90240]\n",
      "loss: 3.850299  [44864/90240]\n",
      "loss: 3.848661  [51264/90240]\n",
      "loss: 3.853994  [57664/90240]\n",
      "loss: 3.849240  [64064/90240]\n",
      "loss: 3.849307  [70464/90240]\n",
      "loss: 3.847785  [76864/90240]\n",
      "loss: 3.852564  [83264/90240]\n",
      "loss: 3.853910  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850496 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.855102  [   64/90240]\n",
      "loss: 3.850274  [ 6464/90240]\n",
      "loss: 3.851462  [12864/90240]\n",
      "loss: 3.853039  [19264/90240]\n",
      "loss: 3.848835  [25664/90240]\n",
      "loss: 3.849128  [32064/90240]\n",
      "loss: 3.849304  [38464/90240]\n",
      "loss: 3.853089  [44864/90240]\n",
      "loss: 3.849416  [51264/90240]\n",
      "loss: 3.850865  [57664/90240]\n",
      "loss: 3.847784  [64064/90240]\n",
      "loss: 3.849391  [70464/90240]\n",
      "loss: 3.849652  [76864/90240]\n",
      "loss: 3.851636  [83264/90240]\n",
      "loss: 3.850820  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850512 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.849361  [   64/90240]\n",
      "loss: 3.853976  [ 6464/90240]\n",
      "loss: 3.851543  [12864/90240]\n",
      "loss: 3.851073  [19264/90240]\n",
      "loss: 3.851594  [25664/90240]\n",
      "loss: 3.848918  [32064/90240]\n",
      "loss: 3.851369  [38464/90240]\n",
      "loss: 3.848505  [44864/90240]\n",
      "loss: 3.852942  [51264/90240]\n",
      "loss: 3.849663  [57664/90240]\n",
      "loss: 3.848992  [64064/90240]\n",
      "loss: 3.848288  [70464/90240]\n",
      "loss: 3.847315  [76864/90240]\n",
      "loss: 3.850372  [83264/90240]\n",
      "loss: 3.849796  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850545 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.849063  [   64/90240]\n",
      "loss: 3.850052  [ 6464/90240]\n",
      "loss: 3.848850  [12864/90240]\n",
      "loss: 3.850537  [19264/90240]\n",
      "loss: 3.851918  [25664/90240]\n",
      "loss: 3.848587  [32064/90240]\n",
      "loss: 3.853743  [38464/90240]\n",
      "loss: 3.852482  [44864/90240]\n",
      "loss: 3.850197  [51264/90240]\n",
      "loss: 3.852264  [57664/90240]\n",
      "loss: 3.851830  [64064/90240]\n",
      "loss: 3.849656  [70464/90240]\n",
      "loss: 3.849424  [76864/90240]\n",
      "loss: 3.851435  [83264/90240]\n",
      "loss: 3.848999  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850563 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.852456  [   64/90240]\n",
      "loss: 3.848920  [ 6464/90240]\n",
      "loss: 3.852918  [12864/90240]\n",
      "loss: 3.851458  [19264/90240]\n",
      "loss: 3.850656  [25664/90240]\n",
      "loss: 3.851656  [32064/90240]\n",
      "loss: 3.848516  [38464/90240]\n",
      "loss: 3.851617  [44864/90240]\n",
      "loss: 3.850489  [51264/90240]\n",
      "loss: 3.848965  [57664/90240]\n",
      "loss: 3.848765  [64064/90240]\n",
      "loss: 3.849983  [70464/90240]\n",
      "loss: 3.849978  [76864/90240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.850828  [83264/90240]\n",
      "loss: 3.850492  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850579 \n",
      "\n",
      "Done!\n",
      "model : m20\n",
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Sigmoid()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.2, inplace=False)\n",
      "    (10): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (11): Sigmoid()\n",
      "    (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=20000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=47, bias=True)\n",
      "  )\n",
      ")\n",
      "learning rate:  0.001\n",
      "momentum:  0.8\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.875198  [   64/90240]\n",
      "loss: 3.870779  [ 6464/90240]\n",
      "loss: 3.851073  [12864/90240]\n",
      "loss: 3.848544  [19264/90240]\n",
      "loss: 3.851038  [25664/90240]\n",
      "loss: 3.856847  [32064/90240]\n",
      "loss: 3.853958  [38464/90240]\n",
      "loss: 3.851437  [44864/90240]\n",
      "loss: 3.856361  [51264/90240]\n",
      "loss: 3.839530  [57664/90240]\n",
      "loss: 3.845976  [64064/90240]\n",
      "loss: 3.855215  [70464/90240]\n",
      "loss: 3.859948  [76864/90240]\n",
      "loss: 3.855475  [83264/90240]\n",
      "loss: 3.845486  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 3.850977 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.852877  [   64/90240]\n",
      "loss: 3.841231  [ 6464/90240]\n",
      "loss: 3.848016  [12864/90240]\n",
      "loss: 3.862696  [19264/90240]\n",
      "loss: 3.848809  [25664/90240]\n",
      "loss: 3.846826  [32064/90240]\n",
      "loss: 3.844738  [38464/90240]\n",
      "loss: 3.847590  [44864/90240]\n",
      "loss: 3.849908  [51264/90240]\n",
      "loss: 3.854055  [57664/90240]\n",
      "loss: 3.845659  [64064/90240]\n",
      "loss: 3.852643  [70464/90240]\n",
      "loss: 3.846283  [76864/90240]\n",
      "loss: 3.852164  [83264/90240]\n",
      "loss: 3.844962  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.850759 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.855051  [   64/90240]\n",
      "loss: 3.848468  [ 6464/90240]\n",
      "loss: 3.852653  [12864/90240]\n",
      "loss: 3.851937  [19264/90240]\n",
      "loss: 3.848639  [25664/90240]\n",
      "loss: 3.844008  [32064/90240]\n",
      "loss: 3.855629  [38464/90240]\n",
      "loss: 3.847147  [44864/90240]\n",
      "loss: 3.848792  [51264/90240]\n",
      "loss: 3.849057  [57664/90240]\n",
      "loss: 3.848172  [64064/90240]\n",
      "loss: 3.853111  [70464/90240]\n",
      "loss: 3.847515  [76864/90240]\n",
      "loss: 3.851617  [83264/90240]\n",
      "loss: 3.856036  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.5%, Avg loss: 3.850255 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.847081  [   64/90240]\n",
      "loss: 3.848947  [ 6464/90240]\n",
      "loss: 3.847334  [12864/90240]\n",
      "loss: 3.851984  [19264/90240]\n",
      "loss: 3.850437  [25664/90240]\n",
      "loss: 3.848084  [32064/90240]\n",
      "loss: 3.845439  [38464/90240]\n",
      "loss: 3.849419  [44864/90240]\n",
      "loss: 3.847744  [51264/90240]\n",
      "loss: 3.847364  [57664/90240]\n",
      "loss: 3.850188  [64064/90240]\n",
      "loss: 3.853822  [70464/90240]\n",
      "loss: 3.854925  [76864/90240]\n",
      "loss: 3.841375  [83264/90240]\n",
      "loss: 3.850567  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 3.849696 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 3.846163  [   64/90240]\n",
      "loss: 3.850610  [ 6464/90240]\n",
      "loss: 3.851160  [12864/90240]\n",
      "loss: 3.849266  [19264/90240]\n",
      "loss: 3.847815  [25664/90240]\n",
      "loss: 3.845489  [32064/90240]\n",
      "loss: 3.847516  [38464/90240]\n",
      "loss: 3.851258  [44864/90240]\n",
      "loss: 3.842744  [51264/90240]\n",
      "loss: 3.848554  [57664/90240]\n",
      "loss: 3.848578  [64064/90240]\n",
      "loss: 3.854936  [70464/90240]\n",
      "loss: 3.849384  [76864/90240]\n",
      "loss: 3.848231  [83264/90240]\n",
      "loss: 3.852432  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.8%, Avg loss: 3.849052 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.848652  [   64/90240]\n",
      "loss: 3.846636  [ 6464/90240]\n",
      "loss: 3.846607  [12864/90240]\n",
      "loss: 3.846411  [19264/90240]\n",
      "loss: 3.847893  [25664/90240]\n",
      "loss: 3.843482  [32064/90240]\n",
      "loss: 3.850347  [38464/90240]\n",
      "loss: 3.844532  [44864/90240]\n",
      "loss: 3.848926  [51264/90240]\n",
      "loss: 3.847374  [57664/90240]\n",
      "loss: 3.843051  [64064/90240]\n",
      "loss: 3.843246  [70464/90240]\n",
      "loss: 3.847392  [76864/90240]\n",
      "loss: 3.842877  [83264/90240]\n",
      "loss: 3.842447  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 3.846757 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 3.845798  [   64/90240]\n",
      "loss: 3.844056  [ 6464/90240]\n",
      "loss: 3.841694  [12864/90240]\n",
      "loss: 3.843106  [19264/90240]\n",
      "loss: 3.846318  [25664/90240]\n",
      "loss: 3.838247  [32064/90240]\n",
      "loss: 3.849051  [38464/90240]\n",
      "loss: 3.842360  [44864/90240]\n",
      "loss: 3.842646  [51264/90240]\n",
      "loss: 3.836804  [57664/90240]\n",
      "loss: 3.846323  [64064/90240]\n",
      "loss: 3.832062  [70464/90240]\n",
      "loss: 3.840739  [76864/90240]\n",
      "loss: 3.839609  [83264/90240]\n",
      "loss: 3.828926  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 4.1%, Avg loss: 3.835908 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 3.838379  [   64/90240]\n",
      "loss: 3.822526  [ 6464/90240]\n",
      "loss: 3.828283  [12864/90240]\n",
      "loss: 3.823847  [19264/90240]\n",
      "loss: 3.817387  [25664/90240]\n",
      "loss: 3.822228  [32064/90240]\n",
      "loss: 3.812772  [38464/90240]\n",
      "loss: 3.806096  [44864/90240]\n",
      "loss: 3.781595  [51264/90240]\n",
      "loss: 3.774634  [57664/90240]\n",
      "loss: 3.751782  [64064/90240]\n",
      "loss: 3.695374  [70464/90240]\n",
      "loss: 3.664238  [76864/90240]\n",
      "loss: 3.680045  [83264/90240]\n",
      "loss: 3.597549  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 6.9%, Avg loss: 3.583188 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.615974  [   64/90240]\n",
      "loss: 3.625835  [ 6464/90240]\n",
      "loss: 3.432344  [12864/90240]\n",
      "loss: 3.460706  [19264/90240]\n",
      "loss: 3.374090  [25664/90240]\n",
      "loss: 3.222734  [32064/90240]\n",
      "loss: 3.369711  [38464/90240]\n",
      "loss: 3.221442  [44864/90240]\n",
      "loss: 3.205711  [51264/90240]\n",
      "loss: 3.216363  [57664/90240]\n",
      "loss: 3.148818  [64064/90240]\n",
      "loss: 2.884413  [70464/90240]\n",
      "loss: 2.763669  [76864/90240]\n",
      "loss: 3.104385  [83264/90240]\n",
      "loss: 2.787110  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 27.3%, Avg loss: 2.723533 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.756474  [   64/90240]\n",
      "loss: 2.609376  [ 6464/90240]\n",
      "loss: 2.415386  [12864/90240]\n",
      "loss: 2.562079  [19264/90240]\n",
      "loss: 2.218332  [25664/90240]\n",
      "loss: 2.191540  [32064/90240]\n",
      "loss: 2.091377  [38464/90240]\n",
      "loss: 2.058192  [44864/90240]\n",
      "loss: 2.076161  [51264/90240]\n",
      "loss: 1.967294  [57664/90240]\n",
      "loss: 2.079897  [64064/90240]\n",
      "loss: 1.891931  [70464/90240]\n",
      "loss: 1.631069  [76864/90240]\n",
      "loss: 1.689695  [83264/90240]\n",
      "loss: 1.898453  [89664/90240]\n",
      "Test Error: \n",
      " Accuracy: 51.9%, Avg loss: 1.712789 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# define which models to train/test\n",
    "# run train/test loop\n",
    "\n",
    "# try all model architectures\n",
    "models = ['m1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10']\n",
    "\n",
    "for m in models:\n",
    "    for fc in [1, 2, 3]:\n",
    "        net = CNN(m, model_code, fc)\n",
    "        for lr in [-3]:\n",
    "            learning_rate = 10 ** lr\n",
    "            for momentum in [0.8]:\n",
    "                epochs = 10\n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "                optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "                #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                print('model :', m)\n",
    "                print(net)\n",
    "                print('learning rate: ', learning_rate)\n",
    "                print('momentum: ', momentum)\n",
    "                for t in range(epochs):\n",
    "                    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "                    train_loop(train_loader, net, loss_fn, optimizer)\n",
    "                    test_loop(val_loader, net, loss_fn)\n",
    "                print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c98b0",
   "metadata": {},
   "source": [
    "The results from training the 10 models is the following (cols = number of fully-connected layers on the output: 1, 2, 3):\n",
    "\n",
    "fc:    1     2     3\n",
    "m1:  73.6, 81.1, 80.9     (1 hidden layer, relu activation, max pooling)\n",
    "m2:  82.6, 85.2, 85.2     (1 hidden layer, batch normalization, relu activation, max pooling)\n",
    "m3:  83.6, 82.0, 81.8     (2 hidden layers, relu activation, max pooling)\n",
    "m4:  85.3, 86.5, 86.4     (2 hidden layers, batch normalization, relu activation, max pooling)\n",
    "m5:  81.8, 81.5, 81.2     (2 hidden layers, relu activation, max pooling, dropout)\n",
    "m6:  84.7, 86.3, 86.3     (2 hidden layers, batch normalization, relu activation, max pooling, dropout)\n",
    "m7:  84.5, 82.8, 81.6     (3 hidden layers, relu activation, max pooling)\n",
    "m8:  86.2, 87.2, 87.4     (3 hidden layers, batch normalization, relu activation, max pooling)\n",
    "m9:  84.0, 81.7, 81.2     (3 hidden layers, relu activation, max pooling, dropout)\n",
    "m10: 85.6, 86.5, 86.0     (3 hidden layers, batch normalization, relu activation, max pooling, dropout)\n",
    "\n",
    "Notice that adding a 3rd fully-connected layer on the output generally did not improve the model. All of the odd-numbered models (those without batch normalization) perform worse than their corresponding even-numbered counterparts. Also, including dropout did not improve the model compared to its no-dropout counterpart. The best model is m8 with 3 fully-connected layers on the output, though this is marginally better than the 2 fully-connected layer version. The second best model is a tie between m4 and m10 with 2 fully-connected layers on the output. We will move forward with hyperparameter tuning on these three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7294b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try only best models, but fine tune hyperparameters\n",
    "# define which models to train/test\n",
    "# run train/test loop\n",
    "models = ['m8','m4','m10']\n",
    "\n",
    "for m in models:\n",
    "    for fc in [2]:\n",
    "        net = CNN(m, model_code, fc)\n",
    "        for lr in [-2, -2.5, -3, -3.5, -4]:\n",
    "            learning_rate = 10 ** lr\n",
    "            for momentum in [0.9, 0.8]:\n",
    "                epochs = 100\n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "                optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "                #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                print('model :', m)\n",
    "                print(net)\n",
    "                print('learning rate: ', learning_rate)\n",
    "                print('momentum: ', momentum)\n",
    "                for t in range(epochs):\n",
    "                    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "                    train_loop(train_loader, net, loss_fn, optimizer)\n",
    "                    test_loop(val_loader, net, loss_fn)\n",
    "                print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
